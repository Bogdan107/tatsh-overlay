diff --git a/advanced/01-pihole.conf b/advanced/01-pihole.conf
index e243e91a..a2a23195 100644
--- a/advanced/01-pihole.conf
+++ b/advanced/01-pihole.conf
@@ -18,8 +18,8 @@
 #                    WITHIN /etc/dnsmasq.d/yourname.conf                      #
 ###############################################################################
 
-addn-hosts=/etc/pihole/local.list
-addn-hosts=/etc/pihole/custom.list
+addn-hosts==@EPREFIX@/etc/pihole/local.list
+addn-hosts==@EPREFIX@/etc/pihole/custom.list
 
 domain-needed
 
@@ -37,7 +37,7 @@ interface=@INT@
 cache-size=@CACHE_SIZE@
 
 log-queries
-log-facility=/var/log/pihole.log
+log-facility=@EPREFIX@/var/log/pihole.log
 
 local-ttl=2
 
diff --git a/advanced/Scripts/chronometer.sh b/advanced/Scripts/chronometer.sh
index 4f9ea59a..76bf4e40 100755
--- a/advanced/Scripts/chronometer.sh
+++ b/advanced/Scripts/chronometer.sh
@@ -15,9 +15,9 @@ LC_NUMERIC=C
 pihole-FTL() {
     local ftl_port LINE
     ftl_port=$(cat /run/pihole-FTL.port 2> /dev/null)
-    if [[ -n "$ftl_port" ]]; then
+    if [[ -n $ftl_port ]]; then
         # Open connection to FTL
-        exec 3<>"/dev/tcp/127.0.0.1/$ftl_port"
+        exec 3<> "/dev/tcp/127.0.0.1/$ftl_port"
 
         # Test if connection is open
         if { "true" >&3; } 2> /dev/null; then
@@ -27,7 +27,7 @@ pihole-FTL() {
             # Read input until we received an empty string and the connection is
             # closed
             read -r -t 1 LINE <&3
-            until [[ -z "${LINE}" ]] && [[ ! -t 3 ]]; do
+            until [[ -z ${LINE} ]] && [[ ! -t 3 ]]; do
                 echo "$LINE" >&1
                 read -r -t 1 LINE <&3
             done
@@ -50,61 +50,61 @@ printFunc() {
 
     text_main="$2"
     text_main_nocol="$text_main"
-    if [[ "${text_main:0:1}" == "" ]]; then
+    if [[ ${text_main:0:1} == "" ]]; then
         text_main_nocol=$(sed 's/\[[0-9;]\{1,5\}m//g' <<< "$text_main")
     fi
     text_main_len="${#text_main_nocol}"
 
     text_addn="$3"
-    if [[ "$text_addn" == "last" ]]; then
+    if [[ $text_addn == "last" ]]; then
         text_addn=""
         text_last="true"
     fi
 
     # If there is additional text, define max length of text_main
-    if [[ -n "$text_addn" ]]; then
+    if [[ -n $text_addn ]]; then
         case "$scr_cols" in
-            [0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-4]) text_main_max_len="9";;
-            4[5-9]) text_main_max_len="14";;
-            *) text_main_max_len="19";;
+            [0-9] | 1[0-9] | 2[0-9] | 3[0-9] | 4[0-4]) text_main_max_len="9" ;;
+            4[5-9]) text_main_max_len="14" ;;
+            *) text_main_max_len="19" ;;
         esac
     fi
 
-    [[ -z "$text_addn" ]] && text_main_max_len="$(( scr_cols - title_len ))"
+    [[ -z $text_addn ]] && text_main_max_len="$((scr_cols - title_len))"
 
     # Remove excess characters from main text
-    if [[ "$text_main_len" -gt "$text_main_max_len" ]]; then
+    if [[ $text_main_len -gt $text_main_max_len ]]; then
         # Trim text without colors
-        text_main_trim="${text_main_nocol:0:$text_main_max_len}"
+        text_main_trim="${text_main_nocol:0:text_main_max_len}"
         # Replace with trimmed text
         text_main="${text_main/$text_main_nocol/$text_main_trim}"
     fi
 
     # Determine amount of spaces for each line
-    if [[ -n "$text_last" ]]; then
+    if [[ -n $text_last ]]; then
         # Move cursor to end of screen
-        spc_num=$(( scr_cols - ( title_len + text_main_len ) ))
+        spc_num=$((scr_cols - (title_len + text_main_len)))
     else
-        spc_num=$(( text_main_max_len - text_main_len ))
+        spc_num=$((text_main_max_len - text_main_len))
     fi
 
-    [[ "$spc_num" -le 0 ]] && spc_num="0"
+    [[ $spc_num -le 0 ]] && spc_num="0"
     spc=$(printf "%${spc_num}s")
     #spc="${spc// /.}" # Debug: Visualize spaces
 
     printf "%s%s$spc" "$title" "$text_main"
 
-    if [[ -n "$text_addn" ]]; then
-        printf "%s(%s)%s\\n" "$COL_NC$COL_DARK_GRAY" "$text_addn" "$COL_NC"
+    if [[ -n $text_addn ]]; then
+        printf '%s(%s)%s\n' "$COL_NC$COL_DARK_GRAY" "$text_addn" "$COL_NC"
     else
         # Do not print trailing newline on final line
-        [[ -z "$text_last" ]] && printf "%s\\n" "$COL_NC"
+        [[ -z $text_last ]] && printf '%s\n' "$COL_NC"
     fi
 }
 
 # Perform on first Chrono run (not for JSON formatted string)
 get_init_stats() {
-    calcFunc(){ awk "BEGIN {print $*}" 2> /dev/null; }
+    calcFunc() { awk "BEGIN {print $*}" 2> /dev/null; }
 
     # Convert bytes to human-readable format
     hrBytes() {
@@ -121,21 +121,23 @@ get_init_stats() {
                 }
             printf "%.0f " type[i+2], yyy*sss
             }
-        }' <<< "$1";
+        }' <<< "$1"
     }
 
     # Convert seconds to human-readable format
     hrSecs() {
-        day=$(( $1/60/60/24 )); hrs=$(( $1/3600%24 ))
-        mins=$(( ($1%3600)/60 )); secs=$(( $1%60 ))
-        [[ "$day" -ge "2" ]] && plu="s"
-        [[ "$day" -ge "1" ]] && days="$day day${plu}, " || days=""
-        printf "%s%02d:%02d:%02d\\n" "$days" "$hrs" "$mins" "$secs"
+        day=$(($1 / 60 / 60 / 24))
+        hrs=$(($1 / 3600 % 24))
+        mins=$((($1 % 3600) / 60))
+        secs=$(($1 % 60))
+        [[ $day -ge "2" ]] && plu="s"
+        [[ $day -ge "1" ]] && days="$day day${plu}, " || days=""
+        printf '%s%02d:%02d:%02d\n' "$days" "$hrs" "$mins" "$secs"
     }
 
     # Set Color Codes
-    coltable="/opt/pihole/COL_TABLE"
-    if [[ -f "${coltable}" ]]; then
+    coltable="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
+    if [[ -f ${coltable} ]]; then
         source ${coltable}
     else
         COL_NC="[0m"
@@ -153,37 +155,40 @@ get_init_stats() {
         local sys_throttle_raw
         local sys_rev_raw
 
-        sys_throttle_raw=$(vgt=$(sudo vcgencmd get_throttled); echo "${vgt##*x}")
+        sys_throttle_raw=$(
+            vgt=$(sudo vcgencmd get_throttled)
+            echo "${vgt##*x}"
+        )
 
         # Active Throttle Notice: https://bit.ly/2gnunOo
-        if [[ "$sys_throttle_raw" != "0" ]]; then
+        if [[ $sys_throttle_raw != "0" ]]; then
             case "$sys_throttle_raw" in
-                *0001) thr_type="${COL_YELLOW}Under Voltage";;
-                *0002) thr_type="${COL_LIGHT_BLUE}Arm Freq Cap";;
-                *0003) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_BLUE}AFC";;
-                *0004) thr_type="${COL_LIGHT_RED}Throttled";;
-                *0005) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT";;
-                *0006) thr_type="${COL_LIGHT_BLUE}AFC${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT";;
-                *0007) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_BLUE}AFC${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT";;
+                *0001) thr_type="${COL_YELLOW}Under Voltage" ;;
+                *0002) thr_type="${COL_LIGHT_BLUE}Arm Freq Cap" ;;
+                *0003) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_BLUE}AFC" ;;
+                *0004) thr_type="${COL_LIGHT_RED}Throttled" ;;
+                *0005) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT" ;;
+                *0006) thr_type="${COL_LIGHT_BLUE}AFC${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT" ;;
+                *0007) thr_type="${COL_YELLOW}UV${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_BLUE}AFC${COL_DARK_GRAY},${COL_NC} ${COL_LIGHT_RED}TT" ;;
             esac
-        [[ -n "$thr_type" ]] && sys_throttle="$thr_type${COL_DARK_GRAY}"
+            [[ -n $thr_type ]] && sys_throttle="$thr_type${COL_DARK_GRAY}"
         fi
 
         sys_rev_raw=$(awk '/Revision/ {print $3}' < /proc/cpuinfo)
         case "$sys_rev_raw" in
-            000[2-6]) sys_model=" 1, Model B";; # 256MB
-            000[7-9]) sys_model=" 1, Model A";; # 256MB
-            000d|000e|000f) sys_model=" 1, Model B";; # 512MB
-            0010|0013) sys_model=" 1, Model B+";; # 512MB
-            0012|0015) sys_model=" 1, Model A+";; # 256MB
-            a0104[0-1]|a21041|a22042) sys_model=" 2, Model B";; # 1GB
-            900021) sys_model=" 1, Model A+";; # 512MB
-            900032) sys_model=" 1, Model B+";; # 512MB
-            90009[2-3]|920093) sys_model=" Zero";; # 512MB
-            9000c1) sys_model=" Zero W";; # 512MB
-            a02082|a[2-3]2082) sys_model=" 3, Model B";; # 1GB
-            a020d3) sys_model=" 3, Model B+";; # 1GB
-            *) sys_model="";;
+            000[2-6]) sys_model=" 1, Model B" ;;                     # 256MB
+            000[7-9]) sys_model=" 1, Model A" ;;                     # 256MB
+            000d | 000e | 000f) sys_model=" 1, Model B" ;;           # 512MB
+            0010 | 0013) sys_model=" 1, Model B+" ;;                 # 512MB
+            0012 | 0015) sys_model=" 1, Model A+" ;;                 # 256MB
+            a0104[0-1] | a21041 | a22042) sys_model=" 2, Model B" ;; # 1GB
+            900021) sys_model=" 1, Model A+" ;;                      # 512MB
+            900032) sys_model=" 1, Model B+" ;;                      # 512MB
+            90009[2-3] | 920093) sys_model=" Zero" ;;                # 512MB
+            9000c1) sys_model=" Zero W" ;;                           # 512MB
+            a02082 | a[2-3]2082) sys_model=" 3, Model B" ;;          # 1GB
+            a020d3) sys_model=" 3, Model B+" ;;                      # 1GB
+            *) sys_model="" ;;
         esac
         sys_type="Raspberry Pi$sys_model"
     else
@@ -210,8 +215,8 @@ get_init_stats() {
     fi
 
     # Test existence of setupVars config
-    if [[ -f "/etc/pihole/setupVars.conf" ]]; then
-        setupVars="/etc/pihole/setupVars.conf"
+    if [[ -f "@EPREFIX@/etc/pihole/setupVars.conf" ]]; then
+        setupVars="@EPREFIX@/etc/pihole/setupVars.conf"
     fi
 }
 
@@ -222,13 +227,13 @@ get_sys_stats() {
     local disk_raw
 
     # Update every 12 refreshes (Def: every 60s)
-    count=$((count+1))
-    if [[ "$count" == "1" ]] || (( "$count" % 12 == 0 )); then
+    count=$((count + 1))
+    if [[ $count == "1" ]] || (("$count" % 12 == 0)); then
         # Do not source setupVars if file does not exist
-        [[ -n "$setupVars" ]] && source "$setupVars"
+        [[ -n $setupVars ]] && source "$setupVars"
 
         mapfile -t ph_ver_raw < <(pihole -v -c 2> /dev/null | sed -n 's/^.* v/v/p')
-        if [[ -n "${ph_ver_raw[0]}" ]]; then
+        if [[ -n ${ph_ver_raw[0]} ]]; then
             ph_core_ver="${ph_ver_raw[0]}"
             if [[ ${#ph_ver_raw[@]} -eq 2 ]]; then
                 # AdminLTE not installed
@@ -244,7 +249,7 @@ get_sys_stats() {
 
         sys_name=$(hostname)
 
-        [[ -n "$TEMPERATUREUNIT" ]] && temp_unit="${TEMPERATUREUNIT^^}" || temp_unit="C"
+        [[ -n $TEMPERATUREUNIT ]] && temp_unit="${TEMPERATUREUNIT^^}" || temp_unit="C"
 
         # Get storage stats for partition mounted on /
         read -r -a disk_raw <<< "$(df -B1 / 2> /dev/null | awk 'END{ print $3,$2,$5 }')"
@@ -255,40 +260,40 @@ get_sys_stats() {
         net_gateway=$(ip route | grep default | cut -d ' ' -f 3 | head -n 1)
 
         # Get DHCP stats, if feature is enabled
-        if [[ "$DHCP_ACTIVE" == "true" ]]; then
-            ph_dhcp_max=$(( ${DHCP_END##*.} - ${DHCP_START##*.} + 1 ))
+        if [[ $DHCP_ACTIVE == "true" ]]; then
+            ph_dhcp_max=$((${DHCP_END##*.} - ${DHCP_START##*.} + 1))
         fi
 
         # Get DNS server count
         dns_count="0"
-        [[ -n "${PIHOLE_DNS_1}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_2}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_3}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_4}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_5}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_6}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_7}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_8}" ]] && dns_count=$((dns_count+1))
-        [[ -n "${PIHOLE_DNS_9}" ]] && dns_count="$dns_count+"
+        [[ -n ${PIHOLE_DNS_1} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_2} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_3} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_4} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_5} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_6} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_7} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_8} ]] && dns_count=$((dns_count + 1))
+        [[ -n ${PIHOLE_DNS_9} ]] && dns_count="$dns_count+"
     fi
 
     # Get screen size
-    read -r -a scr_size <<< "$(stty size 2>/dev/null || echo 24 80)"
+    read -r -a scr_size <<< "$(stty size 2> /dev/null || echo 24 80)"
     scr_lines="${scr_size[0]}"
     scr_cols="${scr_size[1]}"
 
     # Determine Chronometer size behavior
-    if [[ "$scr_cols" -ge 58 ]]; then
+    if [[ $scr_cols -ge 58 ]]; then
         chrono_width="large"
-    elif [[ "$scr_cols" -gt 40 ]]; then
+    elif [[ $scr_cols -gt 40 ]]; then
         chrono_width="medium"
     else
         chrono_width="small"
     fi
 
     # Determine max length of divider string
-    scr_line_len=$(( scr_cols - 2 ))
-    [[ "$scr_line_len" -ge 58 ]] && scr_line_len="58"
+    scr_line_len=$((scr_cols - 2))
+    [[ $scr_line_len -ge 58 ]] && scr_line_len="58"
     scr_line_str=$(printf "%${scr_line_len}s")
     scr_line_str="${scr_line_str// /—}"
 
@@ -303,50 +308,50 @@ get_sys_stats() {
     cpu_perc=$(awk '{sum+=$1} END {printf "%.0f\n", sum/'"$sys_cores"'}' <<< "$cpu_raw")
 
     # Get CPU clock speed
-    if [[ -n "$scaling_freq_file" ]]; then
-        cpu_mhz=$(( $(< /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq) / 1000 ))
+    if [[ -n $scaling_freq_file ]]; then
+        cpu_mhz=$(($(< /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq) / 1000))
     else
         cpu_mhz=$(lscpu | awk -F ":" '/MHz/ {print $2;exit}')
         cpu_mhz=$(printf "%.0f" "${cpu_mhz//[[:space:]]/}")
     fi
 
     # Determine whether to display CPU clock speed as MHz or GHz
-    if [[ -n "$cpu_mhz" ]]; then
-        [[ "$cpu_mhz" -le "999" ]] && cpu_freq="$cpu_mhz MHz" || cpu_freq="$(printf "%.1f" $(calcFunc "$cpu_mhz"/1000)) GHz"
-        [[ "${cpu_freq}" == *".0"* ]] && cpu_freq="${cpu_freq/.0/}"
+    if [[ -n $cpu_mhz ]]; then
+        [[ $cpu_mhz -le "999" ]] && cpu_freq="$cpu_mhz MHz" || cpu_freq="$(printf "%.1f" $(calcFunc "$cpu_mhz"/1000)) GHz"
+        [[ ${cpu_freq} == *".0"* ]] && cpu_freq="${cpu_freq/.0/}"
     fi
 
     # Determine color for temperature
-    if [[ -n "$temp_file" ]]; then
-        if [[ "$temp_unit" == "C" ]]; then
-            cpu_temp=$(printf "%.0fc\\n" "$(calcFunc "$(< $temp_file) / 1000")")
+    if [[ -n $temp_file ]]; then
+        if [[ $temp_unit == "C" ]]; then
+            cpu_temp=$(printf '%.0fc\n' "$(calcFunc "$(< $temp_file) / 1000")")
 
             case "${cpu_temp::-1}" in
-                -*|[0-9]|[1-3][0-9]) cpu_col="$COL_LIGHT_BLUE";;
-                4[0-9]) cpu_col="";;
-                5[0-9]) cpu_col="$COL_YELLOW";;
-                6[0-9]) cpu_col="$COL_LIGHT_RED";;
-                *) cpu_col="$COL_URG_RED";;
+                -* | [0-9] | [1-3][0-9]) cpu_col="$COL_LIGHT_BLUE" ;;
+                4[0-9]) cpu_col="" ;;
+                5[0-9]) cpu_col="$COL_YELLOW" ;;
+                6[0-9]) cpu_col="$COL_LIGHT_RED" ;;
+                *) cpu_col="$COL_URG_RED" ;;
             esac
 
-        # $COL_NC$COL_DARK_GRAY is needed for $COL_URG_RED
-        cpu_temp_str=" @ $cpu_col$cpu_temp$COL_NC$COL_DARK_GRAY"
+            # $COL_NC$COL_DARK_GRAY is needed for $COL_URG_RED
+            cpu_temp_str=" @ $cpu_col$cpu_temp$COL_NC$COL_DARK_GRAY"
 
-        elif [[ "$temp_unit" == "F" ]]; then
-            cpu_temp=$(printf "%.0ff\\n" "$(calcFunc "($(< $temp_file) / 1000) * 9 / 5 + 32")")
+        elif [[ $temp_unit == "F" ]]; then
+            cpu_temp=$(printf '%.0ff\n' "$(calcFunc "($(< $temp_file) / 1000) * 9 / 5 + 32")")
 
             case "${cpu_temp::-1}" in
-                -*|[0-9]|[0-9][0-9]) cpu_col="$COL_LIGHT_BLUE";;
-                1[0-1][0-9]) cpu_col="";;
-                1[2-3][0-9]) cpu_col="$COL_YELLOW";;
-                1[4-5][0-9]) cpu_col="$COL_LIGHT_RED";;
-                *) cpu_col="$COL_URG_RED";;
+                -* | [0-9] | [0-9][0-9]) cpu_col="$COL_LIGHT_BLUE" ;;
+                1[0-1][0-9]) cpu_col="" ;;
+                1[2-3][0-9]) cpu_col="$COL_YELLOW" ;;
+                1[4-5][0-9]) cpu_col="$COL_LIGHT_RED" ;;
+                *) cpu_col="$COL_URG_RED" ;;
             esac
 
             cpu_temp_str=" @ $cpu_col$cpu_temp$COL_NC$COL_DARK_GRAY"
 
         else
-            cpu_temp_str=$(printf " @ %.0fk\\n" "$(calcFunc "($(< $temp_file) / 1000) + 273.15")")
+            cpu_temp_str=$(printf ' @ %.0fk\n' "$(calcFunc "($(< $temp_file) / 1000) + 273.15")")
         fi
     else
         cpu_temp_str=""
@@ -363,14 +368,14 @@ get_sys_stats() {
         ph_status="${COL_LIGHT_RED}Offline"
     fi
 
-    if [[ "$DHCP_ACTIVE" == "true" ]]; then
+    if [[ $DHCP_ACTIVE == "true" ]]; then
         local ph_dhcp_range
 
         ph_dhcp_range=$(seq -s "|" -f "${DHCP_START%.*}.%g" "${DHCP_START##*.}" "${DHCP_END##*.}")
 
         # Count dynamic leases from available range, and not static leases
         ph_dhcp_num=$(grep -cE "$ph_dhcp_range" "/etc/pihole/dhcp.leases")
-        ph_dhcp_percent=$(( ph_dhcp_num * 100 / ph_dhcp_max ))
+        ph_dhcp_percent=$((ph_dhcp_num * 100 / ph_dhcp_max))
     fi
 }
 
@@ -386,16 +391,16 @@ get_ftl_stats() {
     queries_cached_raw="${stats_raw[6]#* }"
 
     # Only retrieve these stats when not called from jsonFunc
-    if [[ -z "$1" ]]; then
+    if [[ -z $1 ]]; then
         local top_ad_raw
         local top_domain_raw
         local top_client_raw
 
-        domains_being_blocked=$(printf "%.0f\\n" "${domains_being_blocked_raw}" 2> /dev/null)
-        dns_queries_today=$(printf "%.0f\\n" "${dns_queries_today_raw}")
-        ads_blocked_today=$(printf "%.0f\\n" "${ads_blocked_today_raw}")
+        domains_being_blocked=$(printf '%.0f\n' "${domains_being_blocked_raw}" 2> /dev/null)
+        dns_queries_today=$(printf '%.0f\n' "${dns_queries_today_raw}")
+        ads_blocked_today=$(printf '%.0f\n' "${ads_blocked_today_raw}")
         ads_percentage_today=$(printf "%'.0f\\n" "${ads_percentage_today_raw}")
-        queries_cached_percentage=$(printf "%.0f\\n" "$(calcFunc "$queries_cached_raw * 100 / ( $queries_forwarded_raw + $queries_cached_raw )")")
+        queries_cached_percentage=$(printf '%.0f\n' "$(calcFunc "$queries_cached_raw * 100 / ( $queries_forwarded_raw + $queries_cached_raw )")")
         recent_blocked=$(pihole-FTL recentBlocked)
         read -r -a top_ad_raw <<< "$(pihole-FTL "top-ads (1)")"
         read -r -a top_domain_raw <<< "$(pihole-FTL "top-domains (1)")"
@@ -413,7 +418,7 @@ get_ftl_stats() {
 
 get_strings() {
     # Expand or contract strings depending on screen size
-    if [[ "$chrono_width" == "large" ]]; then
+    if [[ $chrono_width == "large" ]]; then
         phc_str="        ${COL_DARK_GRAY}Core"
         lte_str="        ${COL_DARK_GRAY}Web"
         ftl_str="        ${COL_DARK_GRAY}FTL"
@@ -437,7 +442,7 @@ get_strings() {
         ph_info="$domains_being_blocked blocked"
     fi
 
-    [[ "$sys_cores" -ne 1 ]] && sys_cores_txt="${sys_cores}x "
+    [[ $sys_cores -ne 1 ]] && sys_cores_txt="${sys_cores}x "
     cpu_info="$sys_cores_txt$cpu_freq$cpu_temp_str"
     ram_info="$used_str$(hrBytes "$ram_used") of $(hrBytes "$ram_total")"
     disk_info="$used_str$(hrBytes "$disk_used") of $(hrBytes "$disk_total")"
@@ -445,10 +450,10 @@ get_strings() {
     lan_info="Gateway: $net_gateway"
     dhcp_info="$leased_str$ph_dhcp_num of $ph_dhcp_max"
 
-      ads_info="$total_str$ads_blocked_today of $dns_queries_today"
+    ads_info="$total_str$ads_blocked_today of $dns_queries_today"
     dns_info="$dns_count DNS servers"
 
-    [[ "$recent_blocked" == "0" ]] && recent_blocked="${COL_LIGHT_RED}FTL offline${COL_NC}"
+    [[ $recent_blocked == "0" ]] && recent_blocked="${COL_LIGHT_RED}FTL offline${COL_NC}"
 }
 
 chronoFunc() {
@@ -463,7 +468,7 @@ chronoFunc() {
         get_strings
 
         # Strip excess development version numbers
-        if [[ "$ph_core_ver" != "-1" ]]; then
+        if [[ $ph_core_ver != "-1" ]]; then
             phc_ver_str="$phc_str: ${ph_core_ver%-*}${COL_NC}"
             lte_ver_str="$lte_str: ${ph_lte_ver%-*}${COL_NC}"
             ftl_ver_str="$ftl_str: ${ph_ftl_ver%-*}${COL_NC}"
@@ -472,7 +477,7 @@ chronoFunc() {
         fi
 
         # Get refresh number
-        if [[ "${extra_arg}" = "refresh" ]]; then
+        if [[ ${extra_arg} == "refresh" ]]; then
             num="${extra_value}"
             num_str="Refresh set for every $num seconds"
         else
@@ -482,13 +487,13 @@ chronoFunc() {
         clear
 
         # Remove exit message heading on third refresh
-        if [[ "$count" -le 2 ]] && [[ "${extra_arg}" != "exit" ]]; then
+        if [[ $count -le 2 ]] && [[ ${extra_arg} != "exit" ]]; then
             echo -e " ${COL_LIGHT_GREEN}Pi-hole Chronometer${COL_NC}
             $num_str
             ${COL_LIGHT_RED}Press Ctrl-C to exit${COL_NC}
             ${COL_DARK_GRAY}$scr_line_str${COL_NC}"
         else
-        echo -e "[0;1;31;91m|¯[0;1;33;93m¯[0;1;32;92m¯[0;1;32;92m(¯[0;1;36;96m)[0;1;34;94m_[0;1;35;95m|[0;1;33;93m¯[0;1;31;91m|_  [0;1;32;92m__[0;1;36;96m_|[0;1;31;91m¯[0;1;34;94m|[0;1;35;95m__[0;1;31;91m_[0m$phc_ver_str\\n[0;1;33;93m| ¯[0;1;32;92m_[0;1;36;96m/¯[0;1;34;94m|[0;1;35;95m_[0;1;31;91m| [0;1;33;93m' [0;1;32;92m\\/ [0;1;36;96m_ [0;1;34;94m\\ [0;1;35;95m/ [0;1;31;91m-[0;1;33;93m_)[0m$lte_ver_str\\n[0;1;32;92m|_[0;1;36;96m| [0;1;34;94m|_[0;1;35;95m| [0;1;33;93m|_[0;1;32;92m||[0;1;36;96m_\\[0;1;34;94m__[0;1;35;95m_/[0;1;31;91m_\\[0;1;33;93m__[0;1;32;92m_|[0m$ftl_ver_str\\n ${COL_DARK_GRAY}$scr_line_str${COL_NC}"
+            echo -e "[0;1;31;91m|¯[0;1;33;93m¯[0;1;32;92m¯[0;1;32;92m(¯[0;1;36;96m)[0;1;34;94m_[0;1;35;95m|[0;1;33;93m¯[0;1;31;91m|_  [0;1;32;92m__[0;1;36;96m_|[0;1;31;91m¯[0;1;34;94m|[0;1;35;95m__[0;1;31;91m_[0m$phc_ver_str\\n[0;1;33;93m| ¯[0;1;32;92m_[0;1;36;96m/¯[0;1;34;94m|[0;1;35;95m_[0;1;31;91m| [0;1;33;93m' [0;1;32;92m\\/ [0;1;36;96m_ [0;1;34;94m\\ [0;1;35;95m/ [0;1;31;91m-[0;1;33;93m_)[0m$lte_ver_str\\n[0;1;32;92m|_[0;1;36;96m| [0;1;34;94m|_[0;1;35;95m| [0;1;33;93m|_[0;1;32;92m||[0;1;36;96m_\\[0;1;34;94m__[0;1;35;95m_/[0;1;31;91m_\\[0;1;33;93m__[0;1;32;92m_|[0m$ftl_ver_str\\n ${COL_DARK_GRAY}$scr_line_str${COL_NC}"
         fi
 
         printFunc "  Hostname: " "$sys_name" "$host_info"
@@ -498,11 +503,11 @@ chronoFunc() {
         printFunc " RAM usage: " "$ram_perc%" "$ram_info"
         printFunc " HDD usage: " "$disk_perc" "$disk_info"
 
-        if [[ "$scr_lines" -gt 17 ]] && [[ "$chrono_width" != "small" ]]; then
+        if [[ $scr_lines -gt 17 ]] && [[ $chrono_width != "small" ]]; then
             printFunc "  LAN addr: " "${IPV4_ADDRESS/\/*/}" "$lan_info"
         fi
 
-        if [[ "$DHCP_ACTIVE" == "true" ]]; then
+        if [[ $DHCP_ACTIVE == "true" ]]; then
             printFunc "DHCP usage: " "$ph_dhcp_percent%" "$dhcp_info"
         fi
 
@@ -514,8 +519,8 @@ chronoFunc() {
         printFunc "Top Advert: " "$top_ad"
 
         # Provide more stats on screens with more lines
-        if [[ "$scr_lines" -eq 17 ]]; then
-            if [[ "$DHCP_ACTIVE" == "true" ]]; then
+        if [[ $scr_lines -eq 17 ]]; then
+            if [[ $DHCP_ACTIVE == "true" ]]; then
                 printFunc "Top Domain: " "$top_domain" "last"
             else
                 print_client="true"
@@ -524,16 +529,16 @@ chronoFunc() {
             print_client="true"
         fi
 
-        if [[ -n "$print_client" ]]; then
+        if [[ -n $print_client ]]; then
             printFunc "Top Domain: " "$top_domain"
             printFunc "Top Client: " "$top_client" "last"
         fi
 
         # Handle exit/refresh options
-        if [[ "${extra_arg}" == "exit" ]]; then
+        if [[ ${extra_arg} == "exit" ]]; then
             exit 0
         else
-            if [[ "${extra_arg}" == "refresh" ]]; then
+            if [[ ${extra_arg} == "refresh" ]]; then
                 sleep "$num"
             else
                 sleep 5
@@ -549,7 +554,7 @@ jsonFunc() {
 }
 
 helpFunc() {
-    if [[ "$1" == "?" ]]; then
+    if [[ $1 == "?" ]]; then
         echo "Unknown option. Please view 'pihole -c --help' for more information"
     else
         echo "Usage: pihole -c [options]
@@ -561,19 +566,19 @@ Options:
   -r, --refresh       Set update frequency (in seconds)
   -e, --exit          Output stats and exit without refreshing
   -h, --help          Display this help text"
-  fi
+    fi
 
-  exit 0
+    exit 0
 }
 
-if [[ $# = 0 ]]; then
+if [[ $# == 0 ]]; then
     chronoFunc
 fi
 
 case "$1" in
-    "-j" | "--json"    ) jsonFunc;;
-    "-h" | "--help"    ) helpFunc;;
-    "-r" | "--refresh" ) chronoFunc refresh "$2";;
-    "-e" | "--exit"    ) chronoFunc exit;;
-    *                  ) helpFunc "?";;
+    "-j" | "--json") jsonFunc ;;
+    "-h" | "--help") helpFunc ;;
+    "-r" | "--refresh") chronoFunc refresh "$2" ;;
+    "-e" | "--exit") chronoFunc exit ;;
+    *) helpFunc "?" ;;
 esac
diff --git a/advanced/Scripts/database_migration/gravity-db.sh b/advanced/Scripts/database_migration/gravity-db.sh
index 22f241dd..85b874c5 100644
--- a/advanced/Scripts/database_migration/gravity-db.sh
+++ b/advanced/Scripts/database_migration/gravity-db.sh
@@ -10,116 +10,116 @@
 # This file is copyright under the latest version of the EUPL.
 # Please see LICENSE file for your rights under this license.
 
-readonly scriptPath="/etc/.pihole/advanced/Scripts/database_migration/gravity"
+readonly scriptPath="@EPREFIX@/usr@LIBDIR@/pihole/advanced/Scripts/database_migration/gravity"
 
-upgrade_gravityDB(){
-	local database piholeDir auditFile version
-	database="${1}"
-	piholeDir="${2}"
-	auditFile="${piholeDir}/auditlog.list"
+upgrade_gravityDB() {
+    local database piholeDir auditFile version
+    database="${1}"
+    piholeDir="${2}"
+    auditFile="${piholeDir}/auditlog.list"
 
-	# Get database version
-	version="$(sqlite3 "${database}" "SELECT \"value\" FROM \"info\" WHERE \"property\" = 'version';")"
+    # Get database version
+    version="$(sqlite3 "${database}" "SELECT \"value\" FROM \"info\" WHERE \"property\" = 'version';")"
 
-	if [[ "$version" == "1" ]]; then
-		# This migration script upgrades the gravity.db file by
-		# adding the domain_audit table
-		echo -e "  ${INFO} Upgrading gravity database from version 1 to 2"
-		sqlite3 "${database}" < "${scriptPath}/1_to_2.sql"
-		version=2
+    if [[ $version == "1" ]]; then
+        # This migration script upgrades the gravity.db file by
+        # adding the domain_audit table
+        echo -e "  ${INFO} Upgrading gravity database from version 1 to 2"
+        sqlite3 "${database}" < "${scriptPath}/1_to_2.sql"
+        version=2
 
-		# Store audit domains in database table
-		if [ -e "${auditFile}" ]; then
-			echo -e "  ${INFO} Migrating content of ${auditFile} into new database"
-			# database_table_from_file is defined in gravity.sh
-			database_table_from_file "domain_audit" "${auditFile}"
-		fi
-	fi
-	if [[ "$version" == "2" ]]; then
-		# This migration script upgrades the gravity.db file by
-		# renaming the regex table to regex_blacklist, and
-		# creating a new regex_whitelist table + corresponding linking table and views
-		echo -e "  ${INFO} Upgrading gravity database from version 2 to 3"
-		sqlite3 "${database}" < "${scriptPath}/2_to_3.sql"
-		version=3
-	fi
-	if [[ "$version" == "3" ]]; then
-		# This migration script unifies the formally separated domain
-		# lists into a single table with a UNIQUE domain constraint
-		echo -e "  ${INFO} Upgrading gravity database from version 3 to 4"
-		sqlite3 "${database}" < "${scriptPath}/3_to_4.sql"
-		version=4
-	fi
-	if [[ "$version" == "4" ]]; then
-		# This migration script upgrades the gravity and list views
-		# implementing necessary changes for per-client blocking
-		echo -e "  ${INFO} Upgrading gravity database from version 4 to 5"
-		sqlite3 "${database}" < "${scriptPath}/4_to_5.sql"
-		version=5
-	fi
-	if [[ "$version" == "5" ]]; then
-		# This migration script upgrades the adlist view
-		# to return an ID used in gravity.sh
-		echo -e "  ${INFO} Upgrading gravity database from version 5 to 6"
-		sqlite3 "${database}" < "${scriptPath}/5_to_6.sql"
-		version=6
-	fi
-	if [[ "$version" == "6" ]]; then
-		# This migration script adds a special group with ID 0
-		# which is automatically associated to all clients not
-		# having their own group assignments
-		echo -e "  ${INFO} Upgrading gravity database from version 6 to 7"
-		sqlite3 "${database}" < "${scriptPath}/6_to_7.sql"
-		version=7
-	fi
-	if [[ "$version" == "7" ]]; then
-		# This migration script recreated the group table
-		# to ensure uniqueness on the group name
-		# We also add date_added and date_modified columns
-		echo -e "  ${INFO} Upgrading gravity database from version 7 to 8"
-		sqlite3 "${database}" < "${scriptPath}/7_to_8.sql"
-		version=8
-	fi
-	if [[ "$version" == "8" ]]; then
-		# This migration fixes some issues that were introduced
-		# in the previous migration script.
-		echo -e "  ${INFO} Upgrading gravity database from version 8 to 9"
-		sqlite3 "${database}" < "${scriptPath}/8_to_9.sql"
-		version=9
-	fi
-	if [[ "$version" == "9" ]]; then
-		# This migration drops unused tables and creates triggers to remove
-		# obsolete groups assignments when the linked items are deleted
-		echo -e "  ${INFO} Upgrading gravity database from version 9 to 10"
-		sqlite3 "${database}" < "${scriptPath}/9_to_10.sql"
-		version=10
-	fi
-	if [[ "$version" == "10" ]]; then
-		# This adds timestamp and an optional comment field to the client table
-		# These fields are only temporary and will be replaces by the columns
-		# defined in gravity.db.sql during gravity swapping. We add them here
-		# to keep the copying process generic (needs the same columns in both the
-		# source and the destination databases).
-		echo -e "  ${INFO} Upgrading gravity database from version 10 to 11"
-		sqlite3 "${database}" < "${scriptPath}/10_to_11.sql"
-		version=11
-	fi
-	if [[ "$version" == "11" ]]; then
-		# Rename group 0 from "Unassociated" to "Default"
-		echo -e "  ${INFO} Upgrading gravity database from version 11 to 12"
-		sqlite3 "${database}" < "${scriptPath}/11_to_12.sql"
-		version=12
-	fi
-	if [[ "$version" == "12" ]]; then
-		# Add column date_updated to adlist table
-		echo -e "  ${INFO} Upgrading gravity database from version 12 to 13"
-		sqlite3 "${database}" < "${scriptPath}/12_to_13.sql"
-		version=13
-	fi
-	if [[ "$version" == "13" ]]; then
-		# Add columns number and status to adlist table
-		echo -e "  ${INFO} Upgrading gravity database from version 13 to 14"
-		sqlite3 "${database}" < "${scriptPath}/13_to_14.sql"
-		version=14
-	fi
+        # Store audit domains in database table
+        if [ -e "${auditFile}" ]; then
+            echo -e "  ${INFO} Migrating content of ${auditFile} into new database"
+            # database_table_from_file is defined in gravity.sh
+            database_table_from_file "domain_audit" "${auditFile}"
+        fi
+    fi
+    if [[ $version == "2" ]]; then
+        # This migration script upgrades the gravity.db file by
+        # renaming the regex table to regex_blacklist, and
+        # creating a new regex_whitelist table + corresponding linking table and views
+        echo -e "  ${INFO} Upgrading gravity database from version 2 to 3"
+        sqlite3 "${database}" < "${scriptPath}/2_to_3.sql"
+        version=3
+    fi
+    if [[ $version == "3" ]]; then
+        # This migration script unifies the formally separated domain
+        # lists into a single table with a UNIQUE domain constraint
+        echo -e "  ${INFO} Upgrading gravity database from version 3 to 4"
+        sqlite3 "${database}" < "${scriptPath}/3_to_4.sql"
+        version=4
+    fi
+    if [[ $version == "4" ]]; then
+        # This migration script upgrades the gravity and list views
+        # implementing necessary changes for per-client blocking
+        echo -e "  ${INFO} Upgrading gravity database from version 4 to 5"
+        sqlite3 "${database}" < "${scriptPath}/4_to_5.sql"
+        version=5
+    fi
+    if [[ $version == "5" ]]; then
+        # This migration script upgrades the adlist view
+        # to return an ID used in gravity.sh
+        echo -e "  ${INFO} Upgrading gravity database from version 5 to 6"
+        sqlite3 "${database}" < "${scriptPath}/5_to_6.sql"
+        version=6
+    fi
+    if [[ $version == "6" ]]; then
+        # This migration script adds a special group with ID 0
+        # which is automatically associated to all clients not
+        # having their own group assignments
+        echo -e "  ${INFO} Upgrading gravity database from version 6 to 7"
+        sqlite3 "${database}" < "${scriptPath}/6_to_7.sql"
+        version=7
+    fi
+    if [[ $version == "7" ]]; then
+        # This migration script recreated the group table
+        # to ensure uniqueness on the group name
+        # We also add date_added and date_modified columns
+        echo -e "  ${INFO} Upgrading gravity database from version 7 to 8"
+        sqlite3 "${database}" < "${scriptPath}/7_to_8.sql"
+        version=8
+    fi
+    if [[ $version == "8" ]]; then
+        # This migration fixes some issues that were introduced
+        # in the previous migration script.
+        echo -e "  ${INFO} Upgrading gravity database from version 8 to 9"
+        sqlite3 "${database}" < "${scriptPath}/8_to_9.sql"
+        version=9
+    fi
+    if [[ $version == "9" ]]; then
+        # This migration drops unused tables and creates triggers to remove
+        # obsolete groups assignments when the linked items are deleted
+        echo -e "  ${INFO} Upgrading gravity database from version 9 to 10"
+        sqlite3 "${database}" < "${scriptPath}/9_to_10.sql"
+        version=10
+    fi
+    if [[ $version == "10" ]]; then
+        # This adds timestamp and an optional comment field to the client table
+        # These fields are only temporary and will be replaces by the columns
+        # defined in gravity.db.sql during gravity swapping. We add them here
+        # to keep the copying process generic (needs the same columns in both the
+        # source and the destination databases).
+        echo -e "  ${INFO} Upgrading gravity database from version 10 to 11"
+        sqlite3 "${database}" < "${scriptPath}/10_to_11.sql"
+        version=11
+    fi
+    if [[ $version == "11" ]]; then
+        # Rename group 0 from "Unassociated" to "Default"
+        echo -e "  ${INFO} Upgrading gravity database from version 11 to 12"
+        sqlite3 "${database}" < "${scriptPath}/11_to_12.sql"
+        version=12
+    fi
+    if [[ $version == "12" ]]; then
+        # Add column date_updated to adlist table
+        echo -e "  ${INFO} Upgrading gravity database from version 12 to 13"
+        sqlite3 "${database}" < "${scriptPath}/12_to_13.sql"
+        version=13
+    fi
+    if [[ $version == "13" ]]; then
+        # Add columns number and status to adlist table
+        echo -e "  ${INFO} Upgrading gravity database from version 13 to 14"
+        sqlite3 "${database}" < "${scriptPath}/13_to_14.sql"
+        version=14
+    fi
 }
diff --git a/advanced/Scripts/list.sh b/advanced/Scripts/list.sh
index e213b014..c1b48ead 100755
--- a/advanced/Scripts/list.sh
+++ b/advanced/Scripts/list.sh
@@ -11,12 +11,12 @@
 # Please see LICENSE file for your rights under this license.
 
 # Globals
-piholeDir="/etc/pihole"
+piholeDir="@EPREFIX@/etc/pihole"
 GRAVITYDB="${piholeDir}/gravity.db"
 # Source pihole-FTL from install script
 pihole_FTL="${piholeDir}/pihole-FTL.conf"
-if [[ -f "${pihole_FTL}" ]]; then
-  source "${pihole_FTL}"
+if [[ -f ${pihole_FTL} ]]; then
+    source "${pihole_FTL}"
 fi
 
 # Set this only after sourcing pihole-FTL.conf as the gravity database path may
@@ -36,7 +36,7 @@ comment=""
 declare -i domaincount
 domaincount=0
 
-colfile="/opt/pihole/COL_TABLE"
+colfile="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 source ${colfile}
 
 # IDs are hard-wired to domain interpretation in the gravity database scheme
@@ -47,29 +47,29 @@ readonly regex_whitelist="2"
 readonly regex_blacklist="3"
 
 GetListnameFromTypeId() {
-    if [[ "$1" == "${whitelist}" ]]; then
+    if [[ $1 == "${whitelist}" ]]; then
         echo "whitelist"
-    elif  [[ "$1" == "${blacklist}" ]]; then
+    elif [[ $1 == "${blacklist}" ]]; then
         echo "blacklist"
-    elif  [[ "$1" == "${regex_whitelist}" ]]; then
+    elif [[ $1 == "${regex_whitelist}" ]]; then
         echo "regex whitelist"
-    elif  [[ "$1" == "${regex_blacklist}" ]]; then
+    elif [[ $1 == "${regex_blacklist}" ]]; then
         echo "regex blacklist"
     fi
 }
 
 GetListParamFromTypeId() {
-    if [[ "${typeId}" == "${whitelist}" ]]; then
+    if [[ ${typeId} == "${whitelist}" ]]; then
         echo "w"
-    elif  [[ "${typeId}" == "${blacklist}" ]]; then
+    elif [[ ${typeId} == "${blacklist}" ]]; then
         echo "b"
-    elif  [[ "${typeId}" == "${regex_whitelist}" && "${wildcard}" == true ]]; then
+    elif [[ ${typeId} == "${regex_whitelist}" && ${wildcard} == true ]]; then
         echo "-white-wild"
-    elif  [[ "${typeId}" == "${regex_whitelist}" ]]; then
+    elif [[ ${typeId} == "${regex_whitelist}" ]]; then
         echo "-white-regex"
-    elif  [[ "${typeId}" == "${regex_blacklist}" && "${wildcard}" == true ]]; then
+    elif [[ ${typeId} == "${regex_blacklist}" && ${wildcard} == true ]]; then
         echo "-wild"
-    elif  [[ "${typeId}" == "${regex_blacklist}" ]]; then
+    elif [[ ${typeId} == "${regex_blacklist}" ]]; then
         echo "-regex"
     fi
 }
@@ -92,7 +92,7 @@ Options:
   -l, --list          Display all your ${listname}listed domains
   --nuke              Removes all entries in a list"
 
-  exit 0
+    exit 0
 }
 
 ValidateDomain() {
@@ -100,28 +100,28 @@ ValidateDomain() {
     domain="${1,,}"
 
     # Check validity of domain (don't check for regex entries)
-    if [[ "${#domain}" -le 253 ]]; then
-        if [[ ( "${typeId}" == "${regex_blacklist}" || "${typeId}" == "${regex_whitelist}" ) && "${wildcard}" == false ]]; then
+    if [[ ${#domain} -le 253 ]]; then
+        if [[ (${typeId} == "${regex_blacklist}" || ${typeId} == "${regex_whitelist}") && ${wildcard} == false ]]; then
             validDomain="${domain}"
         else
             validDomain=$(grep -P "^((-|_)*[a-z\\d]((-|_)*[a-z\\d])*(-|_)*)(\\.(-|_)*([a-z\\d]((-|_)*[a-z\\d])*))*$" <<< "${domain}") # Valid chars check
-            validDomain=$(grep -P "^[^\\.]{1,63}(\\.[^\\.]{1,63})*$" <<< "${validDomain}") # Length of each label
+            validDomain=$(grep -P "^[^\\.]{1,63}(\\.[^\\.]{1,63})*$" <<< "${validDomain}")                                            # Length of each label
         fi
     fi
 
-    if [[ -n "${validDomain}" ]]; then
+    if [[ -n ${validDomain} ]]; then
         domList=("${domList[@]}" "${validDomain}")
     else
         echo -e "  ${CROSS} ${domain} is not a valid argument or domain name!"
     fi
 
-    domaincount=$((domaincount+1))
+    domaincount=$((domaincount + 1))
 }
 
 ProcessDomainList() {
     for dom in "${domList[@]}"; do
         # Format domain into regex filter if requested
-        if [[ "${wildcard}" == true ]]; then
+        if [[ ${wildcard} == true ]]; then
             dom="(\\.|^)${dom//\./\\.}$"
         fi
 
@@ -132,7 +132,7 @@ ProcessDomainList() {
         else
             RemoveDomain "${dom}"
         fi
-  done
+    done
 }
 
 AddDomain() {
@@ -143,30 +143,30 @@ AddDomain() {
     num="$(sqlite3 "${gravityDBfile}" "SELECT COUNT(*) FROM domainlist WHERE domain = '${domain}';")"
     requestedListname="$(GetListnameFromTypeId "${typeId}")"
 
-    if [[ "${num}" -ne 0 ]]; then
-      existingTypeId="$(sqlite3 "${gravityDBfile}" "SELECT type FROM domainlist WHERE domain = '${domain}';")"
-      if [[ "${existingTypeId}" == "${typeId}" ]]; then
-        if [[ "${verbose}" == true ]]; then
-            echo -e "  ${INFO} ${1} already exists in ${requestedListname}, no need to add!"
-        fi
-      else
-        existingListname="$(GetListnameFromTypeId "${existingTypeId}")"
-        sqlite3 "${gravityDBfile}" "UPDATE domainlist SET type = ${typeId} WHERE domain='${domain}';"
-        if [[ "${verbose}" == true ]]; then
-            echo -e "  ${INFO} ${1} already exists in ${existingListname}, it has been moved to ${requestedListname}!"
+    if [[ ${num} -ne 0 ]]; then
+        existingTypeId="$(sqlite3 "${gravityDBfile}" "SELECT type FROM domainlist WHERE domain = '${domain}';")"
+        if [[ ${existingTypeId} == "${typeId}" ]]; then
+            if [[ ${verbose} == true ]]; then
+                echo -e "  ${INFO} ${1} already exists in ${requestedListname}, no need to add!"
+            fi
+        else
+            existingListname="$(GetListnameFromTypeId "${existingTypeId}")"
+            sqlite3 "${gravityDBfile}" "UPDATE domainlist SET type = ${typeId} WHERE domain='${domain}';"
+            if [[ ${verbose} == true ]]; then
+                echo -e "  ${INFO} ${1} already exists in ${existingListname}, it has been moved to ${requestedListname}!"
+            fi
         fi
-      fi
-      return
+        return
     fi
 
     # Domain not found in the table, add it!
-    if [[ "${verbose}" == true ]]; then
+    if [[ ${verbose} == true ]]; then
         echo -e "  ${INFO} Adding ${domain} to the ${requestedListname}..."
     fi
     reload=true
     # Insert only the domain here. The enabled and date_added fields will be filled
     # with their default values (enabled = true, date_added = current timestamp)
-    if [[ -z "${comment}" ]]; then
+    if [[ -z ${comment} ]]; then
         sqlite3 "${gravityDBfile}" "INSERT INTO domainlist (domain,type) VALUES ('${domain}',${typeId});"
     else
         # also add comment when variable has been set through the "--comment" option
@@ -183,15 +183,15 @@ RemoveDomain() {
 
     requestedListname="$(GetListnameFromTypeId "${typeId}")"
 
-    if [[ "${num}" -eq 0 ]]; then
-      if [[ "${verbose}" == true ]]; then
-          echo -e "  ${INFO} ${domain} does not exist in ${requestedListname}, no need to remove!"
-      fi
-      return
+    if [[ ${num} -eq 0 ]]; then
+        if [[ ${verbose} == true ]]; then
+            echo -e "  ${INFO} ${domain} does not exist in ${requestedListname}, no need to remove!"
+        fi
+        return
     fi
 
     # Domain found in the table, remove it!
-    if [[ "${verbose}" == true ]]; then
+    if [[ ${verbose} == true ]]; then
         echo -e "  ${INFO} Removing ${domain} from the ${requestedListname}..."
     fi
     reload=true
@@ -210,8 +210,7 @@ Displaylist() {
     else
         echo -e "Displaying ${requestedListname}:"
         count=1
-        while IFS= read -r line
-        do
+        while IFS= read -r line; do
             # Count number of pipes seen in this line
             # This is necessary because we can only detect the pipe separating the fields
             # from the end backwards as the domain (which is the first field) may contain
@@ -219,12 +218,12 @@ Displaylist() {
             num_pipes="$(grep -c "^" <<< "$(grep -o "|" <<< "${line}")")"
 
             # Extract domain and enabled status based on the obtained number of pipe characters
-            domain="$(cut -d'|' -f"-$((num_pipes-1))" <<< "${line}")"
+            domain="$(cut -d'|' -f"-$((num_pipes - 1))" <<< "${line}")"
             enabled="$(cut -d'|' -f"$((num_pipes))" <<< "${line}")"
-            datemod="$(cut -d'|' -f"$((num_pipes+1))" <<< "${line}")"
+            datemod="$(cut -d'|' -f"$((num_pipes + 1))" <<< "${line}")"
 
             # Translate boolean status into human readable string
-            if [[ "${enabled}" -eq 1 ]]; then
+            if [[ ${enabled} -eq 1 ]]; then
                 status="enabled"
             else
                 status="disabled"
@@ -234,49 +233,58 @@ Displaylist() {
             nicedate=$(date --rfc-2822 -d "@${datemod}")
 
             echo "  ${count}: ${domain} (${status}, last modified ${nicedate})"
-            count=$((count+1))
+            count=$((count + 1))
         done <<< "${data}"
     fi
-    exit 0;
+    exit 0
 }
 
 NukeList() {
     count=$(sqlite3 "${gravityDBfile}" "SELECT COUNT(1) FROM domainlist WHERE type = ${typeId};")
-    listname="$(GetListnameFromTypeId "${typeId}")"    
-    if [ "$count" -gt 0 ];then
+    listname="$(GetListnameFromTypeId "${typeId}")"
+    if [ "$count" -gt 0 ]; then
         sqlite3 "${gravityDBfile}" "DELETE FROM domainlist WHERE type = ${typeId};"
         echo "  ${TICK} Removed ${count} domain(s) from the ${listname}"
     else
         echo "  ${INFO} ${listname} already empty. Nothing to do!"
-    fi    
-    exit 0;
+    fi
+    exit 0
 }
 
 GetComment() {
     comment="$1"
-    if [[ "${comment}" =~ [^a-zA-Z0-9_\#:/\.,\ -] ]]; then
-      echo "  ${CROSS} Found invalid characters in domain comment!"
-      exit
+    if [[ ${comment} =~ [^a-zA-Z0-9_\#:/\.,\ -] ]]; then
+        echo "  ${CROSS} Found invalid characters in domain comment!"
+        exit
     fi
 }
 
-while (( "$#" )); do
+while (("$#")); do
     case "${1}" in
-        "-w" | "whitelist"   ) typeId=0;;
-        "-b" | "blacklist"   ) typeId=1;;
-        "--white-regex" | "white-regex" ) typeId=2;;
-        "--white-wild" | "white-wild" ) typeId=2; wildcard=true;;
-        "--wild" | "wildcard" ) typeId=3; wildcard=true;;
-        "--regex" | "regex"   ) typeId=3;;
-        "-nr"| "--noreload"  ) reload=false;;
-        "-d" | "--delmode"   ) addmode=false;;
-        "-q" | "--quiet"     ) verbose=false;;
-        "-h" | "--help"      ) helpFunc;;
-        "-l" | "--list"      ) Displaylist;;
-        "--nuke"             ) NukeList;;
-        "--web"              ) web=true;;
-        "--comment"          ) GetComment "${2}"; shift;;
-        *                    ) ValidateDomain "${1}";;
+        "-w" | "whitelist") typeId=0 ;;
+        "-b" | "blacklist") typeId=1 ;;
+        "--white-regex" | "white-regex") typeId=2 ;;
+        "--white-wild" | "white-wild")
+            typeId=2
+            wildcard=true
+            ;;
+        "--wild" | "wildcard")
+            typeId=3
+            wildcard=true
+            ;;
+        "--regex" | "regex") typeId=3 ;;
+        "-nr" | "--noreload") reload=false ;;
+        "-d" | "--delmode") addmode=false ;;
+        "-q" | "--quiet") verbose=false ;;
+        "-h" | "--help") helpFunc ;;
+        "-l" | "--list") Displaylist ;;
+        "--nuke") NukeList ;;
+        "--web") web=true ;;
+        "--comment")
+            GetComment "${2}"
+            shift
+            ;;
+        *) ValidateDomain "${1}" ;;
     esac
     shift
 done
@@ -291,9 +299,9 @@ ProcessDomainList
 
 # Used on web interface
 if $web; then
-echo "DONE"
+    echo "DONE"
 fi
 
-if [[ "${reload}" != false ]]; then
+if [[ ${reload} != false ]]; then
     pihole restartdns reload-lists
 fi
diff --git a/advanced/Scripts/pihole-reenable.sh b/advanced/Scripts/pihole-reenable.sh
index 93ec3b95..99d8b87a 100755
--- a/advanced/Scripts/pihole-reenable.sh
+++ b/advanced/Scripts/pihole-reenable.sh
@@ -17,7 +17,7 @@
 # This ensures that pihole ends up in the correct state after a sequence of
 # commands suchs as: `pihole disable 30s; pihole enable; pihole disable`
 
-readonly PI_HOLE_BIN_DIR="/usr/local/bin"
+readonly PI_HOLE_BIN_DIR="@EPREFIX@/usr/bin"
 
 sleep "${1}"
 "${PI_HOLE_BIN_DIR}"/pihole enable
diff --git a/advanced/Scripts/piholeARPTable.sh b/advanced/Scripts/piholeARPTable.sh
index 66d05bf9..ab1771b7 100755
--- a/advanced/Scripts/piholeARPTable.sh
+++ b/advanced/Scripts/piholeARPTable.sh
@@ -10,7 +10,7 @@
 # This file is copyright under the latest version of the EUPL.
 # Please see LICENSE file for your rights under this license.
 
-coltable="/opt/pihole/COL_TABLE"
+coltable="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 if [[ -f ${coltable} ]]; then
     source ${coltable}
 fi
@@ -20,19 +20,18 @@ fi
 # Constructed to return nothing when
 # a) the setting is not present in the config file, or
 # b) the setting is commented out (e.g. "#DBFILE=...")
-FTLconf="/etc/pihole/pihole-FTL.conf"
+FTLconf="@EPREFIX@/etc/pihole/pihole-FTL.conf"
 if [ -e "$FTLconf" ]; then
     DBFILE="$(sed -n -e 's/^\s*DBFILE\s*=\s*//p' ${FTLconf})"
 fi
 # Test for empty string. Use standard path in this case.
 if [ -z "$DBFILE" ]; then
-    DBFILE="/etc/pihole/pihole-FTL.db"
+    DBFILE="@EPREFIX@/var/lib/pihole/pihole-FTL.db"
 fi
 
-
-flushARP(){
+flushARP() {
     local output
-    if [[ "${args[1]}" != "quiet" ]]; then
+    if [[ ${args[1]} != "quiet" ]]; then
         echo -ne "  ${INFO} Flushing network table ..."
     fi
 
@@ -54,7 +53,7 @@ flushARP(){
         return 1
     fi
 
-    if [[ "${args[1]}" != "quiet" ]]; then
+    if [[ ${args[1]} != "quiet" ]]; then
         echo -e "${OVER}  ${TICK} Flushed network table"
     fi
 }
@@ -62,5 +61,5 @@ flushARP(){
 args=("$@")
 
 case "${args[0]}" in
-    "arpflush"            ) flushARP;;
+    "arpflush") flushARP ;;
 esac
diff --git a/advanced/Scripts/piholeDebug.sh b/advanced/Scripts/piholeDebug.sh
index 13a886f1..d7919b58 100755
--- a/advanced/Scripts/piholeDebug.sh
+++ b/advanced/Scripts/piholeDebug.sh
@@ -22,12 +22,12 @@ set -o pipefail
 ######## GLOBAL VARS ########
 # These variables would normally be next to the other files
 # but we need them to be first in order to get the colors needed for the script output
-PIHOLE_SCRIPTS_DIRECTORY="/opt/pihole"
-PIHOLE_COLTABLE_FILE="${PIHOLE_SCRIPTS_DIRECTORY}/COL_TABLE"
+PIHOLE_SCRIPTS_DIRECTORY="@EPREFIX@/usr/@LIBDIR@/pihole"
+PIHOLE_COLTABLE_FILE="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 
 # These provide the colors we need for making the log more readable
 if [[ -f ${PIHOLE_COLTABLE_FILE} ]]; then
-  source ${PIHOLE_COLTABLE_FILE}
+    source ${PIHOLE_COLTABLE_FILE}
 else
     COL_NC='\e[0m' # No Color
     COL_RED='\e[1;91m'
@@ -64,18 +64,18 @@ TRICORDER_SSL_PORT_NUMBER=9998
 
 # Directories required by Pi-hole
 # https://discourse.pi-hole.net/t/what-files-does-pi-hole-use/1684
-CORE_GIT_DIRECTORY="/etc/.pihole"
-CRON_D_DIRECTORY="/etc/cron.d"
-DNSMASQ_D_DIRECTORY="/etc/dnsmasq.d"
-PIHOLE_DIRECTORY="/etc/pihole"
-PIHOLE_SCRIPTS_DIRECTORY="/opt/pihole"
-BIN_DIRECTORY="/usr/local/bin"
-RUN_DIRECTORY="/run"
-LOG_DIRECTORY="/var/log"
+CORE_GIT_DIRECTORY="@EPREFIX@/etc/pihole/.pihole"
+CRON_D_DIRECTORY="@EPREFIX@/etc/cron.d"
+DNSMASQ_D_DIRECTORY="@EPREFIX@/etc/pihole/dnsmasq.d"
+PIHOLE_DIRECTORY="@EPREFIX@/etc/pihole"
+PIHOLE_SCRIPTS_DIRECTORY="@EPREFIX@/usr/@LIBDIR@/pihole"
+BIN_DIRECTORY="@EPREFIX@/usr/bin"
+RUN_DIRECTORY="@EPREFIX@/run"
+LOG_DIRECTORY="@EPREFIX@/var/log"
 WEB_SERVER_LOG_DIRECTORY="${LOG_DIRECTORY}/lighttpd"
-WEB_SERVER_CONFIG_DIRECTORY="/etc/lighttpd"
-HTML_DIRECTORY="/var/www/html"
-WEB_GIT_DIRECTORY="${HTML_DIRECTORY}/admin"
+WEB_SERVER_CONFIG_DIRECTORY="@EPREFIX@/etc/lighttpd"
+HTML_DIRECTORY="@EPREFIX@/var/www/localhost/htdocs"
+WEB_GIT_DIRECTORY="${HTML_DIRECTORY}/pihole-admin"
 #BLOCK_PAGE_DIRECTORY="${HTML_DIRECTORY}/pihole"
 SHM_DIRECTORY="/dev/shm"
 
@@ -108,7 +108,7 @@ get_ftl_conf_value() {
     local value
 
     # Obtain key=... setting from pihole-FTL.conf
-    if [[ -e "$PIHOLE_FTL_CONF_FILE" ]]; then
+    if [[ -e $PIHOLE_FTL_CONF_FILE ]]; then
         # Constructed to return nothing when
         # a) the setting is not present in the config file, or
         # b) the setting is commented out (e.g. "#DBFILE=...")
@@ -116,7 +116,7 @@ get_ftl_conf_value() {
     fi
 
     # Test for missing value. Use default value in this case.
-    if [[ -z "$value" ]]; then
+    if [[ -z $value ]]; then
         value="$default"
     fi
 
@@ -146,7 +146,7 @@ PIHOLE_WEB_SERVER_ERROR_LOG_FILE="${WEB_SERVER_LOG_DIRECTORY}/error.log"
 #SUPPORTED_OS=("Raspbian" "Ubuntu" "Fedora" "Debian" "CentOS")
 
 # Store Pi-hole's processes in an array for easy use and parsing
-PIHOLE_PROCESSES=( "lighttpd" "pihole-FTL" )
+PIHOLE_PROCESSES=("lighttpd" "pihole-FTL")
 
 # Store the required directories in an array so it can be parsed through
 #REQUIRED_DIRECTORIES=("${CORE_GIT_DIRECTORY}"
@@ -165,27 +165,27 @@ PIHOLE_PROCESSES=( "lighttpd" "pihole-FTL" )
 
 # Store the required directories in an array so it can be parsed through
 REQUIRED_FILES=("${PIHOLE_CRON_FILE}"
-"${PIHOLE_DNS_CONFIG_FILE}"
-"${PIHOLE_DHCP_CONFIG_FILE}"
-"${PIHOLE_WILDCARD_CONFIG_FILE}"
-"${WEB_SERVER_CONFIG_FILE}"
-"${WEB_SERVER_CUSTOM_CONFIG_FILE}"
-"${PIHOLE_INSTALL_LOG_FILE}"
-"${PIHOLE_RAW_BLOCKLIST_FILES}"
-"${PIHOLE_LOCAL_HOSTS_FILE}"
-"${PIHOLE_LOGROTATE_FILE}"
-"${PIHOLE_SETUP_VARS_FILE}"
-"${PIHOLE_FTL_CONF_FILE}"
-"${PIHOLE_COMMAND}"
-"${PIHOLE_COLTABLE_FILE}"
-"${FTL_PID}"
-"${FTL_PORT}"
-"${PIHOLE_LOG}"
-"${PIHOLE_LOG_GZIPS}"
-"${PIHOLE_DEBUG_LOG}"
-"${PIHOLE_FTL_LOG}"
-"${PIHOLE_WEB_SERVER_ACCESS_LOG_FILE}"
-"${PIHOLE_WEB_SERVER_ERROR_LOG_FILE}")
+    "${PIHOLE_DNS_CONFIG_FILE}"
+    "${PIHOLE_DHCP_CONFIG_FILE}"
+    "${PIHOLE_WILDCARD_CONFIG_FILE}"
+    "${WEB_SERVER_CONFIG_FILE}"
+    "${WEB_SERVER_CUSTOM_CONFIG_FILE}"
+    "${PIHOLE_INSTALL_LOG_FILE}"
+    "${PIHOLE_RAW_BLOCKLIST_FILES}"
+    "${PIHOLE_LOCAL_HOSTS_FILE}"
+    "${PIHOLE_LOGROTATE_FILE}"
+    "${PIHOLE_SETUP_VARS_FILE}"
+    "${PIHOLE_FTL_CONF_FILE}"
+    "${PIHOLE_COMMAND}"
+    "${PIHOLE_COLTABLE_FILE}"
+    "${FTL_PID}"
+    "${FTL_PORT}"
+    "${PIHOLE_LOG}"
+    "${PIHOLE_LOG_GZIPS}"
+    "${PIHOLE_DEBUG_LOG}"
+    "${PIHOLE_FTL_LOG}"
+    "${PIHOLE_WEB_SERVER_ACCESS_LOG_FILE}"
+    "${PIHOLE_WEB_SERVER_ERROR_LOG_FILE}")
 
 DISCLAIMER="This process collects information from your Pi-hole, and optionally uploads it to a unique and random directory on tricorder.pi-hole.net.
 
@@ -194,7 +194,7 @@ The intent of this script is to allow users to self-diagnose their installations
 NOTE: All log files auto-delete after 48 hours and ONLY the Pi-hole developers can access your data via the given token. We have taken these extra steps to secure your data and will work to further reduce any personal information gathered.
 "
 
-show_disclaimer(){
+show_disclaimer() {
     log_write "${DISCLAIMER}"
 }
 
@@ -203,7 +203,7 @@ source_setup_variables() {
     log_write "\\n${COL_PURPLE}*** [ INITIALIZING ]${COL_NC} Sourcing setup variables"
     # If the variable file exists,
     if ls "${PIHOLE_SETUP_VARS_FILE}" 1> /dev/null 2>&1; then
-        log_write "${INFO} Sourcing ${PIHOLE_SETUP_VARS_FILE}...";
+        log_write "${INFO} Sourcing ${PIHOLE_SETUP_VARS_FILE}..."
         # source it
         source ${PIHOLE_SETUP_VARS_FILE}
     else
@@ -217,7 +217,7 @@ make_temporary_log() {
     TEMPLOG=$(mktemp /tmp/pihole_temp.XXXXXX)
     # Open handle 3 for templog
     # https://stackoverflow.com/questions/18460186/writing-outputs-to-log-file-and-console
-    exec 3>"$TEMPLOG"
+    exec 3> "$TEMPLOG"
     # Delete templog, but allow for addressing via file handle
     # This lets us write to the log without having a temporary file on the drive, which
     # is meant to be a security measure so there is not a lingering file on the drive during the debug process
@@ -259,10 +259,10 @@ compare_local_version_to_git_version() {
     # The named component of the project (Core or Web)
     local pihole_component="${2}"
     # If we are checking the Core versions,
-    if [[ "${pihole_component}" == "Core" ]]; then
+    if [[ ${pihole_component} == "Core" ]]; then
         # We need to search for "Pi-hole" when using pihole -v
         local search_term="Pi-hole"
-    elif [[ "${pihole_component}" == "Web" ]]; then
+    elif [[ ${pihole_component} == "Web" ]]; then
         # We need to search for "AdminLTE" so store it in a variable as well
         #shellcheck disable=2034
         local search_term="AdminLTE"
@@ -272,18 +272,18 @@ compare_local_version_to_git_version() {
     # Store the error message in a variable in case we want to change and/or reuse it
     local error_msg="git status failed"
     # If the pihole git directory exists,
-    if [[ -d "${git_dir}" ]]; then
+    if [[ -d ${git_dir} ]]; then
         # move into it
-        cd "${git_dir}" || \
-        # If not, show an error
-        log_write "${COL_RED}Could not cd into ${git_dir}$COL_NC"
+        cd "${git_dir}" ||
+            # If not, show an error
+            log_write "${COL_RED}Could not cd into ${git_dir}$COL_NC"
         if git status &> /dev/null; then
             # The current version the user is on
             local remote_version
-            remote_version=$(git describe --tags --abbrev=0);
+            remote_version=$(git describe --tags --abbrev=0)
             # What branch they are on
             local remote_branch
-            remote_branch=$(git rev-parse --abbrev-ref HEAD);
+            remote_branch=$(git rev-parse --abbrev-ref HEAD)
             # The commit they are on
             local remote_commit
             remote_commit=$(git describe --long --dirty --tags --always)
@@ -292,7 +292,7 @@ compare_local_version_to_git_version() {
             local_status=$(git status -s)
             # echo this information out to the user in a nice format
             # If the current version matches what pihole -v produces, the user is up-to-date
-            if [[ "${remote_version}" == "$(pihole -v | awk '/${search_term}/ {print $6}' | cut -d ')' -f1)" ]]; then
+            if [[ ${remote_version} == "$(pihole -v | awk '/${search_term}/ {print $6}' | cut -d ')' -f1)" ]]; then
                 log_write "${TICK} ${pihole_component}: ${COL_GREEN}${remote_version}${COL_NC}"
             # If not,
             else
@@ -306,7 +306,7 @@ compare_local_version_to_git_version() {
             log_write "${INFO} Remotes: ${remotes//$'\n'/'\n             '}"
 
             # If the repo is on the master branch, they are on the stable codebase
-            if [[ "${remote_branch}" == "master" ]]; then
+            if [[ ${remote_branch} == "master" ]]; then
                 # so the color of the text is green
                 log_write "${INFO} Branch: ${COL_GREEN}${remote_branch}${COL_NC}"
             # If it is any other branch, they are in a development branch
@@ -318,13 +318,13 @@ compare_local_version_to_git_version() {
             log_write "${INFO} Commit: ${remote_commit}"
             # if `local_status` is non-null, then the repo is not clean, display details here
             if [[ ${local_status} ]]; then
-              # Replace new lines in the status with 12 spaces to make the output cleaner
-              log_write "${INFO} Status: ${local_status//$'\n'/'\n            '}"
-              local local_diff
-              local_diff=$(git diff)
-              if [[ ${local_diff} ]]; then
-                log_write "${INFO} Diff: ${local_diff//$'\n'/'\n          '}"
-              fi
+                # Replace new lines in the status with 12 spaces to make the output cleaner
+                log_write "${INFO} Status: ${local_status//$'\n'/'\n            '}"
+                local local_diff
+                local_diff=$(git diff)
+                if [[ ${local_diff} ]]; then
+                    log_write "${INFO} Diff: ${local_diff//$'\n'/'\n          '}"
+                fi
             fi
         # If git status failed,
         else
@@ -336,8 +336,8 @@ compare_local_version_to_git_version() {
     else
         # There is no git directory so check if the web interface was disabled
         local setup_vars_web_interface
-        setup_vars_web_interface=$(< ${PIHOLE_SETUP_VARS_FILE} grep ^INSTALL_WEB_INTERFACE | cut -d '=' -f2)
-        if [[ "${pihole_component}" == "Web" ]] && [[ "${setup_vars_web_interface}" == "false" ]]; then
+        setup_vars_web_interface=$(grep < ${PIHOLE_SETUP_VARS_FILE} ^INSTALL_WEB_INTERFACE | cut -d '=' -f2)
+        if [[ ${pihole_component} == "Web" ]] && [[ ${setup_vars_web_interface} == "false" ]]; then
             log_write "${INFO} ${pihole_component}: Disabled in setupVars.conf via INSTALL_WEB_INTERFACE=false"
         else
             # Return an error message
@@ -354,7 +354,7 @@ check_ftl_version() {
     # Use the built in command to check FTL's version
     FTL_VERSION=$(pihole-FTL version)
     # Compare the current FTL version to the remote version
-    if [[ "${FTL_VERSION}" == "$(pihole -v | awk '/FTL/ {print $6}' | cut -d ')' -f1)" ]]; then
+    if [[ ${FTL_VERSION} == "$(pihole -v | awk '/FTL/ {print $6}' | cut -d ')' -f1)" ]]; then
         # If they are the same, FTL is up-to-date
         log_write "${TICK} ${ftl_name}: ${COL_GREEN}${FTL_VERSION}${COL_NC}"
     else
@@ -373,7 +373,6 @@ check_component_versions() {
     check_ftl_version
 }
 
-
 get_program_version() {
     local program_name="${1}"
     # Create a local variable so this function can be safely reused
@@ -381,15 +380,17 @@ get_program_version() {
     echo_current_diagnostic "${program_name} version"
     # Evaluate the program we are checking, if it is any of the ones below, show the version
     case "${program_name}" in
-        "lighttpd") program_version="$(${program_name} -v 2> /dev/null | head -n1 | cut -d '/' -f2 | cut -d ' ' -f1)"
-                    ;;
-        "php") program_version="$(${program_name} -v 2> /dev/null | head -n1 | cut -d '-' -f1 | cut -d ' ' -f2)"
-                ;;
+        "lighttpd")
+            program_version="$(${program_name} -v 2> /dev/null | head -n1 | cut -d '/' -f2 | cut -d ' ' -f1)"
+            ;;
+        "php")
+            program_version="$(${program_name} -v 2> /dev/null | head -n1 | cut -d '-' -f1 | cut -d ' ' -f2)"
+            ;;
         # If a match is not found, show an error
-        *) echo "Unrecognized program";
+        *) echo "Unrecognized program" ;;
     esac
     # If the program does not have a version (the variable is empty)
-    if [[ -z "${program_version}" ]]; then
+    if [[ -z ${program_version} ]]; then
         # Display and error
         log_write "${CROSS} ${COL_RED}${program_name} version could not be detected.${COL_NC}"
     else
@@ -415,7 +416,10 @@ os_check() {
     detected_os=$(grep "\bID\b" /etc/os-release | cut -d '=' -f2 | tr -d '"')
     detected_version=$(grep VERSION_ID /etc/os-release | cut -d '=' -f2 | tr -d '"')
 
-    cmdResult="$(dig +short -t txt ${remote_os_domain} @ns1.pi-hole.net 2>&1; echo $?)"
+    cmdResult="$(
+        dig +short -t txt ${remote_os_domain} @ns1.pi-hole.net 2>&1
+        echo $?
+    )"
     #Get the return code of the previous command (last line)
     digReturnCode="${cmdResult##*$'\n'}"
 
@@ -423,17 +427,15 @@ os_check() {
     response="${cmdResult%%$'\n'*}"
 
     IFS=" " read -r -a supportedOS < <(echo "${response}" | tr -d '"')
-    for distro_and_versions in "${supportedOS[@]}"
-    do
+    for distro_and_versions in "${supportedOS[@]}"; do
         distro_part="${distro_and_versions%%=*}"
         versions_part="${distro_and_versions##*=}"
 
-        if [[ "${detected_os^^}" =~ ${distro_part^^} ]]; then
+        if [[ ${detected_os^^} =~ ${distro_part^^} ]]; then
             valid_os=true
-            IFS="," read -r -a supportedVer <<<"${versions_part}"
-            for version in "${supportedVer[@]}"
-            do
-                if [[ "${detected_version}" =~ $version ]]; then
+            IFS="," read -r -a supportedVer <<< "${versions_part}"
+            for version in "${supportedVer[@]}"; do
+                if [[ ${detected_version} =~ $version ]]; then
                     valid_version=true
                     break
                 fi
@@ -487,8 +489,8 @@ check_selinux() {
             enforcing)
                 log_write "${CROSS} ${COL_RED}Default SELinux: $DEFAULT_SELINUX${COL_NC}"
                 ;;
-            *)  # 'permissive' and 'disabled'
-                log_write "${TICK} ${COL_GREEN}Default SELinux: $DEFAULT_SELINUX${COL_NC}";
+            *) # 'permissive' and 'disabled'
+                log_write "${TICK} ${COL_GREEN}Default SELinux: $DEFAULT_SELINUX${COL_NC}"
                 ;;
         esac
         # Check the current state of SELinux
@@ -497,12 +499,12 @@ check_selinux() {
             enforcing)
                 log_write "${CROSS} ${COL_RED}Current SELinux: $CURRENT_SELINUX${COL_NC}"
                 ;;
-            *)  # 'permissive' and 'disabled'
-                log_write "${TICK} ${COL_GREEN}Current SELinux: $CURRENT_SELINUX${COL_NC}";
+            *) # 'permissive' and 'disabled'
+                log_write "${TICK} ${COL_GREEN}Current SELinux: $CURRENT_SELINUX${COL_NC}"
                 ;;
         esac
     else
-        log_write "${INFO} ${COL_GREEN}SELinux not detected${COL_NC}";
+        log_write "${INFO} ${COL_GREEN}SELinux not detected${COL_NC}"
     fi
 }
 
@@ -515,15 +517,15 @@ check_firewalld() {
         # get its status via systemctl
         local firewalld_status
         firewalld_status=$(systemctl is-active firewalld)
-        log_write "${INFO} ${COL_GREEN}Firewalld service ${firewalld_status}${COL_NC}";
+        log_write "${INFO} ${COL_GREEN}Firewalld service ${firewalld_status}${COL_NC}"
         if [ "${firewalld_status}" == "active" ]; then
             # test common required service ports
             local firewalld_enabled_services
             firewalld_enabled_services=$(firewall-cmd --list-services)
             local firewalld_expected_services=("http" "dns" "dhcp" "dhcpv6")
             for i in "${firewalld_expected_services[@]}"; do
-                if [[ "${firewalld_enabled_services}" =~ ${i} ]]; then
-                    log_write "${TICK} ${COL_GREEN}  Allow Service: ${i}${COL_NC}";
+                if [[ ${firewalld_enabled_services} =~ ${i} ]]; then
+                    log_write "${TICK} ${COL_GREEN}  Allow Service: ${i}${COL_NC}"
                 else
                     log_write "${CROSS} ${COL_RED}  Allow Service: ${i}${COL_NC} (${FAQ_HARDWARE_REQUIREMENTS_FIREWALLD})"
                 fi
@@ -531,21 +533,21 @@ check_firewalld() {
             # check for custom FTL FirewallD zone
             local firewalld_zones
             firewalld_zones=$(firewall-cmd --get-zones)
-            if [[ "${firewalld_zones}" =~ "ftl" ]]; then
-                log_write "${TICK} ${COL_GREEN}FTL Custom Zone Detected${COL_NC}";
+            if [[ ${firewalld_zones} =~ "ftl" ]]; then
+                log_write "${TICK} ${COL_GREEN}FTL Custom Zone Detected${COL_NC}"
                 # check FTL custom zone interface: lo
                 local firewalld_ftl_zone_interfaces
                 firewalld_ftl_zone_interfaces=$(firewall-cmd --zone=ftl --list-interfaces)
-                if [[ "${firewalld_ftl_zone_interfaces}" =~ "lo" ]]; then
-                    log_write "${TICK} ${COL_GREEN}  Local Interface Detected${COL_NC}";
+                if [[ ${firewalld_ftl_zone_interfaces} =~ "lo" ]]; then
+                    log_write "${TICK} ${COL_GREEN}  Local Interface Detected${COL_NC}"
                 else
                     log_write "${CROSS} ${COL_RED}  Local Interface Not Detected${COL_NC} (${FAQ_HARDWARE_REQUIREMENTS_FIREWALLD})"
                 fi
                 # check FTL custom zone port: 4711
                 local firewalld_ftl_zone_ports
                 firewalld_ftl_zone_ports=$(firewall-cmd --zone=ftl --list-ports)
-                if [[ "${firewalld_ftl_zone_ports}" =~ "4711/tcp" ]]; then
-                    log_write "${TICK} ${COL_GREEN}  FTL Port 4711/tcp Detected${COL_NC}";
+                if [[ ${firewalld_ftl_zone_ports} =~ "4711/tcp" ]]; then
+                    log_write "${TICK} ${COL_GREEN}  FTL Port 4711/tcp Detected${COL_NC}"
                 else
                     log_write "${CROSS} ${COL_RED}  FTL Port 4711/tcp Not Detected${COL_NC} (${FAQ_HARDWARE_REQUIREMENTS_FIREWALLD})"
                 fi
@@ -554,7 +556,7 @@ check_firewalld() {
             fi
         fi
     else
-        log_write "${TICK} ${COL_GREEN}Firewalld service not detected${COL_NC}";
+        log_write "${TICK} ${COL_GREEN}Firewalld service not detected${COL_NC}"
     fi
 }
 
@@ -563,25 +565,30 @@ processor_check() {
     # Store the processor type in a variable
     PROCESSOR=$(uname -m)
     # If it does not contain a value,
-    if [[ -z "${PROCESSOR}" ]]; then
+    if [[ -z ${PROCESSOR} ]]; then
         # we couldn't detect it, so show an error
         PROCESSOR=$(lscpu | awk '/Architecture/ {print $2}')
         log_write "${CROSS} ${COL_RED}${PROCESSOR}${COL_NC} has not been tested with FTL, but may still work: (${FAQ_FTL_COMPATIBILITY})"
     else
         # Check if the architecture is currently supported for FTL
         case "${PROCESSOR}" in
-            "amd64" | "x86_64") log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
+            "amd64" | "x86_64")
+                log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
                 ;;
-            "armv6l") log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
+            "armv6l")
+                log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
                 ;;
-            "armv6") log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
+            "armv6")
+                log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
                 ;;
-            "armv7l") log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
+            "armv7l")
+                log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
                 ;;
-            "aarch64") log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
+            "aarch64")
+                log_write "${TICK} ${COL_GREEN}${PROCESSOR}${COL_NC}"
                 ;;
             # Otherwise, show the processor type
-            *) log_write "${INFO} ${PROCESSOR}";
+            *) log_write "${INFO} ${PROCESSOR}" ;;
         esac
     fi
 }
@@ -589,7 +596,7 @@ processor_check() {
 parse_setup_vars() {
     echo_current_diagnostic "Setup variables"
     # If the file exists,
-    if [[ -r "${PIHOLE_SETUP_VARS_FILE}" ]]; then
+    if [[ -r ${PIHOLE_SETUP_VARS_FILE} ]]; then
         # parse it
         parse_file "${PIHOLE_SETUP_VARS_FILE}"
     else
@@ -612,11 +619,11 @@ does_ip_match_setup_vars() {
     local ip_address="${2}"
     # See what IP is in the setupVars.conf file
     local setup_vars_ip
-    setup_vars_ip=$(< ${PIHOLE_SETUP_VARS_FILE} grep IPV"${protocol}"_ADDRESS | cut -d '=' -f2)
+    setup_vars_ip=$(grep < ${PIHOLE_SETUP_VARS_FILE} IPV"${protocol}"_ADDRESS | cut -d '=' -f2)
     # If it's an IPv6 address
-    if [[ "${protocol}" == "6" ]]; then
+    if [[ ${protocol} == "6" ]]; then
         # Strip off the / (CIDR notation)
-        if [[ "${ip_address%/*}" == "${setup_vars_ip%/*}" ]]; then
+        if [[ ${ip_address%/*} == "${setup_vars_ip%/*}" ]]; then
             # if it matches, show it in green
             log_write "   ${COL_GREEN}${ip_address%/*}${COL_NC} matches the IP found in ${PIHOLE_SETUP_VARS_FILE}"
         else
@@ -627,7 +634,7 @@ does_ip_match_setup_vars() {
     else
         # if the protocol isn't 6, it's 4 so no need to strip the CIDR notation
         # since it exists in the setupVars.conf that way
-        if [[ "${ip_address}" == "${setup_vars_ip}" ]]; then
+        if [[ ${ip_address} == "${setup_vars_ip}" ]]; then
             # show in green if it matches
             log_write "   ${COL_GREEN}${ip_address}${COL_NC} matches the IP found in ${PIHOLE_SETUP_VARS_FILE}"
         else
@@ -664,11 +671,11 @@ detect_ip_addresses() {
         return 1
     fi
     # If the protocol is v6
-    if [[ "${protocol}" == "6" ]]; then
+    if [[ ${protocol} == "6" ]]; then
         # let the user know that as long as there is one green address, things should be ok
         log_write "   ^ Please note that you may have more than one IP address listed."
         log_write "   As long as one of them is green, and it matches what is in ${PIHOLE_SETUP_VARS_FILE}, there is no need for concern.\\n"
-        log_write "   The link to the FAQ is for an issue that sometimes occurs when the IPv6 address changes, which is why we check for it.\\n"
+        log_write '   The link to the FAQ is for an issue that sometimes occurs when the IPv6 address changes, which is why we check for it.\n'
     fi
 }
 
@@ -698,14 +705,14 @@ ping_gateway() {
     gateway="$(ip -"${protocol}" route | grep default | grep "${PIHOLE_INTERFACE}" | cut -d ' ' -f 3)"
 
     # If the gateway variable has a value (meaning a gateway was found),
-    if [[ -n "${gateway}" ]]; then
+    if [[ -n ${gateway} ]]; then
         log_write "${INFO} Default IPv${protocol} gateway: ${gateway}"
         # Let the user know we will ping the gateway for a response
         log_write "   * Pinging ${gateway}..."
         # Try to quietly ping the gateway 3 times, with a timeout of 3 seconds, using numeric output only,
         # on the pihole interface, and tail the last three lines of the output
         # If pinging the gateway is not successful,
-        if ! ${cmd} -c 1 -W 2 -n "${gateway}" -I "${PIHOLE_INTERFACE}" >/dev/null; then
+        if ! ${cmd} -c 1 -W 2 -n "${gateway}" -I "${PIHOLE_INTERFACE}" > /dev/null; then
             # let the user know
             log_write "${CROSS} ${COL_RED}Gateway did not respond.${COL_NC} ($FAQ_GATEWAY)\\n"
             # and return an error code
@@ -726,7 +733,7 @@ ping_internet() {
     ping_ipv4_or_ipv6 "${protocol}"
     log_write "* Checking Internet connectivity via IPv${protocol}..."
     # Try to ping the address 3 times
-    if ! ${cmd} -c 1 -W 2 -n ${public_address} -I "${PIHOLE_INTERFACE}" >/dev/null; then
+    if ! ${cmd} -c 1 -W 2 -n ${public_address} -I "${PIHOLE_INTERFACE}" > /dev/null; then
         # if it's unsuccessful, show an error
         log_write "${CROSS} ${COL_RED}Cannot reach the Internet.${COL_NC}\\n"
         return 1
@@ -747,7 +754,7 @@ compare_port_to_service_assigned() {
     port="${3}"
 
     # If the service is a Pi-hole service, highlight it in green
-    if [[ "${service_name}" == "${expected_service}" ]]; then
+    if [[ ${service_name} == "${expected_service}" ]]; then
         log_write "[${COL_GREEN}${port}${COL_NC}] is in use by ${COL_GREEN}${service_name}${COL_NC}"
     # Otherwise,
     else
@@ -767,8 +774,8 @@ check_required_ports() {
     ports_in_use=()
     # Sort the addresses and remove duplicates
     while IFS= read -r line; do
-        ports_in_use+=( "$line" )
-    done < <( lsof -iTCP -sTCP:LISTEN -P -n +c 10 )
+        ports_in_use+=("$line")
+    done < <(lsof -iTCP -sTCP:LISTEN -P -n +c 10)
 
     # Now that we have the values stored,
     for i in "${!ports_in_use[@]}"; do
@@ -781,19 +788,22 @@ check_required_ports() {
         port_number="$(echo "${ports_in_use[$i]}" | awk '{print $9}')"
 
         # Skip the line if it's the titles of the columns the lsof command produces
-        if [[ "${service_name}" == COMMAND ]]; then
+        if [[ ${service_name} == COMMAND ]]; then
             continue
         fi
         # Use a case statement to determine if the right services are using the right ports
         case "$(echo "$port_number" | rev | cut -d: -f1 | rev)" in
-            53) compare_port_to_service_assigned  "${resolver}" "${service_name}" 53
+            53)
+                compare_port_to_service_assigned "${resolver}" "${service_name}" 53
                 ;;
-            80) compare_port_to_service_assigned  "${web_server}" "${service_name}" 80
+            80)
+                compare_port_to_service_assigned "${web_server}" "${service_name}" 80
                 ;;
-            4711) compare_port_to_service_assigned  "${ftl}" "${service_name}" 4711
+            4711)
+                compare_port_to_service_assigned "${ftl}" "${service_name}" 4711
                 ;;
             # If it's not a default port that Pi-hole needs, just print it out for the user to see
-            *) log_write "${port_number} ${service_name} (${protocol_type})";
+            *) log_write "${port_number} ${service_name} (${protocol_type})" ;;
         esac
     done
 }
@@ -926,7 +936,7 @@ dig_at() {
     fi
 }
 
-process_status(){
+process_status() {
     # Check to make sure Pi-hole's services are running and active
     echo_current_diagnostic "Pi-hole processes"
     # Local iterator
@@ -948,7 +958,7 @@ process_status(){
             fi
         fi
         # and print it out to the user
-        if [[ "${status_of_process}" == "active" ]]; then
+        if [[ ${status_of_process} == "active" ]]; then
             # If it's active, show it in green
             log_write "${TICK} ${COL_GREEN}${i}${COL_NC} daemon is ${COL_GREEN}${status_of_process}${COL_NC}"
         else
@@ -958,15 +968,15 @@ process_status(){
     done
 }
 
-ftl_full_status(){
+ftl_full_status() {
     # if using systemd print the full status of pihole-FTL
     echo_current_diagnostic "Pi-hole-FTL full status"
     local FTL_status
     if command -v systemctl &> /dev/null; then
-      FTL_status=$(systemctl status --full --no-pager pihole-FTL.service)
-      log_write "   ${FTL_status}"
+        FTL_status=$(systemctl status --full --no-pager pihole-FTL.service)
+        log_write "   ${FTL_status}"
     else
-      log_write "${INFO} systemctl:  command not found"
+        log_write "${INFO} systemctl:  command not found"
     fi
 }
 
@@ -980,16 +990,16 @@ make_array_from_file() {
     # Set the array to be empty so we can start fresh when the function is used
     local file_content=()
     # If the file is a directory
-    if [[ -d "${filename}" ]]; then
+    if [[ -d ${filename} ]]; then
         # do nothing since it cannot be parsed
         :
     else
         # Otherwise, read the file line by line
-        while IFS= read -r line;do
+        while IFS= read -r line; do
             # Othwerise, strip out comments and blank lines
             new_line=$(echo "${line}" | sed -e 's/^\s*#.*$//' -e '/^$/d')
             # If the line still has content (a non-zero value)
-            if [[ -n "${new_line}" ]]; then
+            if [[ -n ${new_line} ]]; then
                 # Put it into the array
                 file_content+=("${new_line}")
             else
@@ -997,7 +1007,7 @@ make_array_from_file() {
                 :
             fi
             # Increment the iterator +1
-            i=$((i+1))
+            i=$((i + 1))
             # but if the limit of lines we want to see is exceeded
             if [[ -z ${limit} ]]; then
                 # do nothing
@@ -1022,7 +1032,7 @@ parse_file() {
     OLD_IFS="$IFS"
     # Get the lines that are in the file(s) and store them in an array for parsing later
     local file_info
-    if [[ -f "$filename" ]]; then
+    if [[ -f $filename ]]; then
         #shellcheck disable=SC2016
         IFS=$'\r\n' command eval 'file_info=( $(cat "${filename}") )'
     else
@@ -1032,9 +1042,9 @@ parse_file() {
     local file_lines
     # For each line in the file,
     for file_lines in "${file_info[@]}"; do
-        if [[ ! -z "${file_lines}" ]]; then
+        if [[ -n ${file_lines} ]]; then
             # don't include the Web password hash
-            [[ "${file_lines}" =~ ^\#.*$  || ! "${file_lines}" || "${file_lines}" == "WEBPASSWORD="* ]] && continue
+            [[ ${file_lines} =~ ^\#.*$ || ! ${file_lines} || ${file_lines} == "WEBPASSWORD="* ]] && continue
             # otherwise, display the lines of the file
             log_write "    ${file_lines}"
         fi
@@ -1084,15 +1094,15 @@ list_files_in_dir() {
         if [[ -d "${dir_to_parse}/${each_file}" ]]; then
             # If it's a directory, do nothing
             :
-        elif [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_DEBUG_LOG}" ]] || \
-            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_RAW_BLOCKLIST_FILES}" ]] || \
-            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_INSTALL_LOG_FILE}" ]] || \
-            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_SETUP_VARS_FILE}" ]] || \
-            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_LOG}" ]] || \
-            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_WEB_SERVER_ACCESS_LOG_FILE}" ]] || \
+        elif [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_DEBUG_LOG}" ]] ||
+            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_RAW_BLOCKLIST_FILES}" ]] ||
+            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_INSTALL_LOG_FILE}" ]] ||
+            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_SETUP_VARS_FILE}" ]] ||
+            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_LOG}" ]] ||
+            [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_WEB_SERVER_ACCESS_LOG_FILE}" ]] ||
             [[ "${dir_to_parse}/${each_file}" == "${PIHOLE_LOG_GZIPS}" ]]; then
             :
-        elif [[ "${dir_to_parse}" == "${SHM_DIRECTORY}" ]]; then
+        elif [[ ${dir_to_parse} == "${SHM_DIRECTORY}" ]]; then
             # SHM file - we do not want to see the content, but we want to see the files and their sizes
             log_write "$(ls -ld "${dir_to_parse}"/"${each_file}")"
         else
@@ -1104,13 +1114,15 @@ list_files_in_dir() {
                     # Check if the file we want to view has a limit (because sometimes we just need a little bit of info from the file, not the entire thing)
                     case "${dir_to_parse}/${each_file}" in
                         # If it's Web server error log, give the first and last 25 lines
-                        "${PIHOLE_WEB_SERVER_ERROR_LOG_FILE}") head_tail_log "${dir_to_parse}/${each_file}" 25
+                        "${PIHOLE_WEB_SERVER_ERROR_LOG_FILE}")
+                            head_tail_log "${dir_to_parse}/${each_file}" 25
                             ;;
-                        # Same for the FTL log
-                        "${PIHOLE_FTL_LOG}") head_tail_log "${dir_to_parse}/${each_file}" 35
+                            # Same for the FTL log
+                        "${PIHOLE_FTL_LOG}")
+                            head_tail_log "${dir_to_parse}/${each_file}" 35
                             ;;
                         # parse the file into an array in case we ever need to analyze it line-by-line
-                        *) make_array_from_file "${dir_to_parse}/${each_file}";
+                        *) make_array_from_file "${dir_to_parse}/${each_file}" ;;
                     esac
                 else
                     # Otherwise, do nothing since it's not a file needed for Pi-hole so we don't care about it
@@ -1179,12 +1191,12 @@ show_db_entries() {
     OLD_IFS="$IFS"
     IFS=$'\r\n'
     local entries=()
-    mapfile -t entries < <(\
+    mapfile -t entries < <(
         sqlite3 "${PIHOLE_GRAVITY_DB_FILE}" \
             -cmd ".headers on" \
             -cmd ".mode column" \
             -cmd ".width ${widths}" \
-            "${query}"\
+            "${query}"
     )
 
     for line in "${entries[@]}"; do
@@ -1204,12 +1216,12 @@ show_FTL_db_entries() {
     OLD_IFS="$IFS"
     IFS=$'\r\n'
     local entries=()
-    mapfile -t entries < <(\
+    mapfile -t entries < <(
         sqlite3 "${PIHOLE_FTL_DB_FILE}" \
             -cmd ".headers on" \
             -cmd ".mode column" \
             -cmd ".width ${widths}" \
-            "${query}"\
+            "${query}"
     )
 
     for line in "${entries[@]}"; do
@@ -1342,20 +1354,19 @@ tricorder_use_nc_or_curl() {
         # transmit he log via TLS and store the token returned in a variable
         tricorder_token=$(curl --silent --upload-file ${PIHOLE_DEBUG_LOG} https://tricorder.pi-hole.net:${TRICORDER_SSL_PORT_NUMBER})
         if [ -z "${tricorder_token}" ]; then
-         # curl failed, fallback to nc
-         log_write "    * ${COL_GREEN}curl${COL_NC} failed, falling back to ${COL_YELLOW}netcat${COL_NC} for transmission."
-         tricorder_token=$(< ${PIHOLE_DEBUG_LOG} nc tricorder.pi-hole.net ${TRICORDER_NC_PORT_NUMBER})
+            # curl failed, fallback to nc
+            log_write "    * ${COL_GREEN}curl${COL_NC} failed, falling back to ${COL_YELLOW}netcat${COL_NC} for transmission."
+            tricorder_token=$(nc < ${PIHOLE_DEBUG_LOG} tricorder.pi-hole.net ${TRICORDER_NC_PORT_NUMBER})
         fi
     # Otherwise,
     else
         # use net cat
         log_write "${INFO} Using ${COL_YELLOW}netcat${COL_NC} for transmission."
         # Save the token returned by our server in a variable
-        tricorder_token=$(< ${PIHOLE_DEBUG_LOG} nc tricorder.pi-hole.net ${TRICORDER_NC_PORT_NUMBER})
+        tricorder_token=$(nc < ${PIHOLE_DEBUG_LOG} tricorder.pi-hole.net ${TRICORDER_NC_PORT_NUMBER})
     fi
 }
 
-
 upload_to_tricorder() {
     local username="pihole"
     # Set the permissions and owner
@@ -1386,14 +1397,17 @@ upload_to_tricorder() {
         read -r -p "[?] Would you like to upload the log? [y/N] " response
         case ${response} in
             # If they say yes, run our function for uploading the log
-            [yY][eE][sS]|[yY]) tricorder_use_nc_or_curl;;
+            [yY][eE][sS] | [yY]) tricorder_use_nc_or_curl ;;
             # If they choose no, just exit out of the script
-            *) log_write "    * Log will ${COL_GREEN}NOT${COL_NC} be uploaded to tricorder.\\n    * A local copy of the debug log can be found at: ${COL_CYAN}${PIHOLE_DEBUG_LOG}${COL_NC}\\n";exit;
+            *)
+                log_write "    * Log will ${COL_GREEN}NOT${COL_NC} be uploaded to tricorder.\\n    * A local copy of the debug log can be found at: ${COL_CYAN}${PIHOLE_DEBUG_LOG}${COL_NC}\\n"
+                exit
+                ;;
         esac
     fi
     # Check if tricorder.pi-hole.net is reachable and provide token
     # along with some additional useful information
-    if [[ -n "${tricorder_token}" ]]; then
+    if [[ -n ${tricorder_token} ]]; then
         # Again, try to make this visually striking so the user realizes they need to do something with this information
         # Namely, provide the Pi-hole devs with the token
         log_write ""
diff --git a/advanced/Scripts/piholeLogFlush.sh b/advanced/Scripts/piholeLogFlush.sh
index 51e94d7c..8517b2f7 100755
--- a/advanced/Scripts/piholeLogFlush.sh
+++ b/advanced/Scripts/piholeLogFlush.sh
@@ -8,7 +8,7 @@
 # This file is copyright under the latest version of the EUPL.
 # Please see LICENSE file for your rights under this license.
 
-colfile="/opt/pihole/COL_TABLE"
+colfile="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 source ${colfile}
 
 # Determine database location
@@ -16,21 +16,21 @@ source ${colfile}
 # Constructed to return nothing when
 # a) the setting is not present in the config file, or
 # b) the setting is commented out (e.g. "#DBFILE=...")
-FTLconf="/etc/pihole/pihole-FTL.conf"
+FTLconf="@EPREFIX@/etc/pihole/pihole-FTL.conf"
 if [ -e "$FTLconf" ]; then
     DBFILE="$(sed -n -e 's/^\s*DBFILE\s*=\s*//p' ${FTLconf})"
 fi
 # Test for empty string. Use standard path in this case.
 if [ -z "$DBFILE" ]; then
-    DBFILE="/etc/pihole/pihole-FTL.db"
+    DBFILE="@EPREFIX@/var/lib/pihole/pihole-FTL.db"
 fi
 
-if [[ "$@" != *"quiet"* ]]; then
+if [[ $@ != *"quiet"* ]]; then
     echo -ne "  ${INFO} Flushing /var/log/pihole.log ..."
 fi
-if [[ "$@" == *"once"* ]]; then
+if [[ $@ == *"once"* ]]; then
     # Nightly logrotation
-    if command -v /usr/sbin/logrotate >/dev/null; then
+    if command -v /usr/sbin/logrotate > /dev/null; then
         # Logrotate once
         /usr/sbin/logrotate --force /etc/pihole/logrotate
     else
@@ -45,9 +45,10 @@ if [[ "$@" == *"once"* ]]; then
     fi
 else
     # Manual flushing
-    if command -v /usr/sbin/logrotate >/dev/null; then
+    if command -v /usr/sbin/logrotate > /dev/null; then
         # Logrotate twice to move all data out of sight of FTL
-        /usr/sbin/logrotate --force /etc/pihole/logrotate; sleep 3
+        /usr/sbin/logrotate --force /etc/pihole/logrotate
+        sleep 3
         /usr/sbin/logrotate --force /etc/pihole/logrotate
     else
         # Flush both pihole.log and pihole.log.1 (if existing)
@@ -64,7 +65,7 @@ else
     sudo pihole restartdns
 fi
 
-if [[ "$@" != *"quiet"* ]]; then
+if [[ $@ != *"quiet"* ]]; then
     echo -e "${OVER}  ${TICK} Flushed /var/log/pihole.log"
     echo -e "  ${TICK} Deleted ${deleted} queries from database"
 fi
diff --git a/advanced/Scripts/query.sh b/advanced/Scripts/query.sh
index 26b4508e..95fcfe00 100755
--- a/advanced/Scripts/query.sh
+++ b/advanced/Scripts/query.sh
@@ -11,8 +11,8 @@
 # Please see LICENSE file for your rights under this license.
 
 # Globals
-piholeDir="/etc/pihole"
-GRAVITYDB="${piholeDir}/gravity.db"
+piholeDir="@EPREFIX@/etc/pihole"
+GRAVITYDB="@EPREFIX@/var/lib/pihole/gravity.db"
 options="$*"
 all=""
 exact=""
@@ -20,19 +20,19 @@ blockpage=""
 matchType="match"
 # Source pihole-FTL from install script
 pihole_FTL="${piholeDir}/pihole-FTL.conf"
-if [[ -f "${pihole_FTL}" ]]; then
-  source "${pihole_FTL}"
+if [[ -f ${pihole_FTL} ]]; then
+    source "${pihole_FTL}"
 fi
 
 # Set this only after sourcing pihole-FTL.conf as the gravity database path may
 # have changed
 gravityDBfile="${GRAVITYDB}"
 
-colfile="/opt/pihole/COL_TABLE"
+colfile="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 source "${colfile}"
 
 # Scan an array of files for matching strings
-scanList(){
+scanList() {
     # Escape full stops
     local domain="${1}" esc_domain="${1//./\\.}" lists="${2}" type="${3:-}"
 
@@ -44,21 +44,22 @@ scanList(){
 
     # /dev/null forces filename to be printed when only one list has been generated
     case "${type}" in
-        "exact" ) grep -i -E -l "(^|(?<!#)\\s)${esc_domain}($|\\s|#)" ${lists} /dev/null 2>/dev/null;;
-        # Iterate through each regexp and check whether it matches the domainQuery
-        # If it does, print the matching regexp and continue looping
-        # Input 1 - regexps | Input 2 - domainQuery
-        "regex" ) 
+        "exact") grep -i -E -l "(^|(?<!#)\\s)${esc_domain}($|\\s|#)" ${lists} /dev/null 2> /dev/null ;;
+            # Iterate through each regexp and check whether it matches the domainQuery
+            # If it does, print the matching regexp and continue looping
+            # Input 1 - regexps | Input 2 - domainQuery
+        "regex")
             for list in ${lists}; do
-                if [[ "${domain}" =~ ${list} ]]; then
-                    printf "%b\n" "${list}";
+                if [[ ${domain} =~ ${list} ]]; then
+                    printf "%b\n" "${list}"
                 fi
-            done;;
-        *       ) grep -i "${esc_domain}" ${lists} /dev/null 2>/dev/null;;
+            done
+            ;;
+        *) grep -i "${esc_domain}" ${lists} /dev/null 2> /dev/null ;;
     esac
 }
 
-if [[ "${options}" == "-h" ]] || [[ "${options}" == "--help" ]]; then
+if [[ ${options} == "-h" ]] || [[ ${options} == "--help" ]]; then
     echo "Usage: pihole -q [option] <domain>
 Example: 'pihole -q -exact domain.com'
 Query the adlists for a specified domain
@@ -67,16 +68,18 @@ Options:
   -exact              Search the block lists for exact domain matches
   -all                Return all query matches within a block list
   -h, --help          Show this help dialog"
-  exit 0
+    exit 0
 fi
 
 # Handle valid options
-if [[ "${options}" == *"-bp"* ]]; then
-    exact="exact"; blockpage=true
+if [[ ${options} == *"-bp"* ]]; then
+    exact="exact"
+    blockpage=true
 else
-    [[ "${options}" == *"-all"* ]] && all=true
-    if [[ "${options}" == *"-exact"* ]]; then
-        exact="exact"; matchType="exact ${matchType}"
+    [[ ${options} == *"-all"* ]] && all=true
+    if [[ ${options} == *"-exact"* ]]; then
+        exact="exact"
+        matchType="exact ${matchType}"
     fi
 fi
 
@@ -87,13 +90,13 @@ options=$(sed -E 's/ ?-(bp|adlists?|all|exact) ?//g' <<< "${options}")
 # Handle remaining options
 # If $options contain non ASCII characters, convert to punycode
 case "${options}" in
-    ""             ) str="No domain specified";;
-    *" "*          ) str="Unknown query option specified";;
-    *[![:ascii:]]* ) domainQuery=$(idn2 "${options}");;
-    *              ) domainQuery="${options}";;
+    "") str="No domain specified" ;;
+    *" "*) str="Unknown query option specified" ;;
+    *[![:ascii:]]*) domainQuery=$(idn2 "${options}") ;;
+    *) domainQuery="${options}" ;;
 esac
 
-if [[ -n "${str:-}" ]]; then
+if [[ -n ${str:-} ]]; then
     echo -e "${str}${COL_NC}\\nTry 'pihole -q --help' for more information."
     exit 1
 fi
@@ -108,47 +111,47 @@ scanDatabaseTable() {
     # Underscores are SQLite wildcards matching exactly one character. We obviously want to suppress this
     # behavior. The "ESCAPE '\'" clause specifies that an underscore preceded by an '\' should be matched
     # as a literal underscore character. We pretreat the $domain variable accordingly to escape underscores.
-    if [[ "${table}" == "gravity" ]]; then
-      case "${exact}" in
-          "exact" ) querystr="SELECT gravity.domain,adlist.address,adlist.enabled FROM gravity LEFT JOIN adlist ON adlist.id = gravity.adlist_id WHERE domain = '${domain}'";;
-          *       ) querystr="SELECT gravity.domain,adlist.address,adlist.enabled FROM gravity LEFT JOIN adlist ON adlist.id = gravity.adlist_id WHERE domain LIKE '%${domain//_/\\_}%' ESCAPE '\\'";;
-      esac
+    if [[ ${table} == "gravity" ]]; then
+        case "${exact}" in
+            "exact") querystr="SELECT gravity.domain,adlist.address,adlist.enabled FROM gravity LEFT JOIN adlist ON adlist.id = gravity.adlist_id WHERE domain = '${domain}'" ;;
+            *) querystr="SELECT gravity.domain,adlist.address,adlist.enabled FROM gravity LEFT JOIN adlist ON adlist.id = gravity.adlist_id WHERE domain LIKE '%${domain//_/\\_}%' ESCAPE '\\'" ;;
+        esac
     else
-      case "${exact}" in
-          "exact" ) querystr="SELECT domain,enabled FROM domainlist WHERE type = '${type}' AND domain = '${domain}'";;
-          *       ) querystr="SELECT domain,enabled FROM domainlist WHERE type = '${type}' AND domain LIKE '%${domain//_/\\_}%' ESCAPE '\\'";;
-      esac
+        case "${exact}" in
+            "exact") querystr="SELECT domain,enabled FROM domainlist WHERE type = '${type}' AND domain = '${domain}'" ;;
+            *) querystr="SELECT domain,enabled FROM domainlist WHERE type = '${type}' AND domain LIKE '%${domain//_/\\_}%' ESCAPE '\\'" ;;
+        esac
     fi
 
     # Send prepared query to gravity database
     result="$(sqlite3 "${gravityDBfile}" "${querystr}")" 2> /dev/null
-    if [[ -z "${result}" ]]; then
+    if [[ -z ${result} ]]; then
         # Return early when there are no matches in this table
         return
     fi
 
-    if [[ "${table}" == "gravity" ]]; then
-      echo "${result}"
-      return
+    if [[ ${table} == "gravity" ]]; then
+        echo "${result}"
+        return
     fi
 
     # Mark domain as having been white-/blacklist matched (global variable)
     wbMatch=true
 
     # Print table name
-    if [[ -z "${blockpage}" ]]; then
+    if [[ -z ${blockpage} ]]; then
         echo " ${matchType^} found in ${COL_BOLD}exact ${table}${COL_NC}"
     fi
 
     # Loop over results and print them
     mapfile -t results <<< "${result}"
     for result in "${results[@]}"; do
-        if [[ -n "${blockpage}" ]]; then
+        if [[ -n ${blockpage} ]]; then
             echo "π ${result}"
             exit 0
         fi
-        domain="${result/|*}"
-        if [[ "${result#*|}" == "0" ]]; then
+        domain="${result/|*/}"
+        if [[ ${result#*|} == "0" ]]; then
             extra=" (disabled)"
         else
             extra=""
@@ -167,13 +170,13 @@ scanRegexDatabaseTable() {
     mapfile -t regexList < <(sqlite3 "${gravityDBfile}" "SELECT domain FROM domainlist WHERE type = ${type}" 2> /dev/null)
 
     # If we have regexps to process
-    if [[ "${#regexList[@]}" -ne 0 ]]; then
+    if [[ ${#regexList[@]} -ne 0 ]]; then
         # Split regexps over a new line
         str_regexList=$(printf '%s\n' "${regexList[@]}")
         # Check domain against regexps
         mapfile -t regexMatches < <(scanList "${domain}" "${str_regexList}" "regex")
         # If there were regex matches
-        if [[  "${#regexMatches[@]}" -ne 0 ]]; then
+        if [[ ${#regexMatches[@]} -ne 0 ]]; then
             # Split matching regexps over a new line
             str_regexMatches=$(printf '%s\n' "${regexMatches[@]}")
             # Form a "matched" message
@@ -181,7 +184,7 @@ scanRegexDatabaseTable() {
             # Form a "results" message
             str_result="${COL_BOLD}${str_regexMatches}${COL_NC}"
             # If we are displaying more than just the source of the block
-            if [[ -z "${blockpage}" ]]; then
+            if [[ -z ${blockpage} ]]; then
                 # Set the wildcard match flag
                 wcMatch=true
                 # Echo the "matched" message, indented by one space
@@ -209,21 +212,22 @@ scanRegexDatabaseTable "${domainQuery}" "blacklist" "3"
 mapfile -t results <<< "$(scanDatabaseTable "${domainQuery}" "gravity")"
 
 # Handle notices
-if [[ -z "${wbMatch:-}" ]] && [[ -z "${wcMatch:-}" ]] && [[ -z "${results[*]}" ]]; then
+if [[ -z ${wbMatch:-} ]] && [[ -z ${wcMatch:-} ]] && [[ -z ${results[*]} ]]; then
     echo -e "  ${INFO} No ${exact/t/t }results found for ${COL_BOLD}${domainQuery}${COL_NC} within the block lists"
     exit 0
-elif [[ -z "${results[*]}" ]]; then
+elif [[ -z ${results[*]} ]]; then
     # Result found in WL/BL/Wildcards
     exit 0
-elif [[ -z "${all}" ]] && [[ "${#results[*]}" -ge 100 ]]; then
+elif [[ -z ${all} ]] && [[ ${#results[*]} -ge 100 ]]; then
     echo -e "  ${INFO} Over 100 ${exact/t/t }results found for ${COL_BOLD}${domainQuery}${COL_NC}
         This can be overridden using the -all option"
     exit 0
 fi
 
 # Print "Exact matches for" title
-if [[ -n "${exact}" ]] && [[ -z "${blockpage}" ]]; then
-    plural=""; [[ "${#results[*]}" -gt 1 ]] && plural="es"
+if [[ -n ${exact} ]] && [[ -z ${blockpage} ]]; then
+    plural=""
+    [[ ${#results[*]} -gt 1 ]] && plural="es"
     echo " ${matchType^}${plural} for ${COL_BOLD}${domainQuery}${COL_NC} found in:"
 fi
 
@@ -232,18 +236,18 @@ for result in "${results[@]}"; do
     extra="${result#*|}"
     adlistAddress="${extra/|*/}"
     extra="${extra#*|}"
-    if [[ "${extra}" == "0" ]]; then
-      extra="(disabled)"
+    if [[ ${extra} == "0" ]]; then
+        extra="(disabled)"
     else
-      extra=""
+        extra=""
     fi
 
-    if [[ -n "${blockpage}" ]]; then
+    if [[ -n ${blockpage} ]]; then
         echo "0 ${adlistAddress}"
-    elif [[ -n "${exact}" ]]; then
+    elif [[ -n ${exact} ]]; then
         echo "  - ${adlistAddress} ${extra}"
     else
-        if [[ ! "${adlistAddress}" == "${adlistAddress_prev:-}" ]]; then
+        if [[ ${adlistAddress} != "${adlistAddress_prev:-}" ]]; then
             count=""
             echo " ${matchType^} found in ${COL_BOLD}${adlistAddress}${COL_NC}:"
             adlistAddress_prev="${adlistAddress}"
@@ -251,9 +255,9 @@ for result in "${results[@]}"; do
         : $((count++))
 
         # Print matching domain if $max_count has not been reached
-        [[ -z "${all}" ]] && max_count="50"
-        if [[ -z "${all}" ]] && [[ "${count}" -ge "${max_count}" ]]; then
-            [[ "${count}" -gt "${max_count}" ]] && continue
+        [[ -z ${all} ]] && max_count="50"
+        if [[ -z ${all} ]] && [[ ${count} -ge ${max_count} ]]; then
+            [[ ${count} -gt ${max_count} ]] && continue
             echo "   ${COL_GRAY}Over ${count} results found, skipping rest of file${COL_NC}"
         else
             echo "   ${match} ${extra}"
diff --git a/advanced/Scripts/version.sh b/advanced/Scripts/version.sh
index f77ee635..d88c5a50 100755
--- a/advanced/Scripts/version.sh
+++ b/advanced/Scripts/version.sh
@@ -10,8 +10,8 @@
 
 # Variables
 DEFAULT="-1"
-COREGITDIR="/etc/.pihole/"
-WEBGITDIR="/var/www/html/admin/"
+COREGITDIR="@EPREFIX@/etc/pihole/.pihole/"
+WEBGITDIR="@EPREFIX@/var/www/localhost/htdocs/pihole-admin"
 
 getLocalVersion() {
     # FTL requires a different method
@@ -86,7 +86,7 @@ getRemoteVersion(){
     local version
     local cachedVersions
     local arrCache
-    cachedVersions="/etc/pihole/GitHubVersions"
+    cachedVersions="@EPREFIX@/etc/pihole/GitHubVersions"
 
     #If the above file exists, then we can read from that. Prevents overuse of GitHub API
     if [[ -f "$cachedVersions" ]]; then
diff --git a/advanced/Scripts/webpage.sh b/advanced/Scripts/webpage.sh
index 8ef4d940..3495f2fb 100755
--- a/advanced/Scripts/webpage.sh
+++ b/advanced/Scripts/webpage.sh
@@ -10,23 +10,23 @@
 # This file is copyright under the latest version of the EUPL.
 # Please see LICENSE file for your rights under this license.
 
-readonly dnsmasqconfig="/etc/dnsmasq.d/01-pihole.conf"
-readonly dhcpconfig="/etc/dnsmasq.d/02-pihole-dhcp.conf"
-readonly FTLconf="/etc/pihole/pihole-FTL.conf"
+readonly dnsmasqconfig="@EPREFIX@/etc/pihole/dnsmasq.d/01-pihole.conf"
+readonly dhcpconfig="@EPREFIX@/etc/pihole/dnsmasq.d/02-pihole-dhcp.conf"
+readonly FTLconf="@EPREFIX@/etc/pihole/pihole-FTL.conf"
 # 03 -> wildcards
-readonly dhcpstaticconfig="/etc/dnsmasq.d/04-pihole-static-dhcp.conf"
-readonly dnscustomfile="/etc/pihole/custom.list"
-readonly dnscustomcnamefile="/etc/dnsmasq.d/05-pihole-custom-cname.conf"
+readonly dhcpstaticconfig="@EPREFIX@/etc/pihole/dnsmasq.d/04-pihole-static-dhcp.conf"
+readonly dnscustomfile="@EPREFIX@/etc/pihole/custom.list"
+readonly dnscustomcnamefile="@EPREFIX@/etc/pihole/dnsmasq.d/05-pihole-custom-cname.conf"
 
-readonly gravityDBfile="/etc/pihole/gravity.db"
+readonly gravityDBfile="@EPREFIX@/var/lib/gravity.db"
 
 # Source install script for ${setupVars}, ${PI_HOLE_BIN_DIR} and valid_ip()
-readonly PI_HOLE_FILES_DIR="/etc/.pihole"
+readonly PI_HOLE_FILES_DIR="@EPREFIX@/etc/pihole/.pihole"
 # shellcheck disable=SC2034  # used in basic-install
 PH_TEST="true"
-source "${PI_HOLE_FILES_DIR}/automated install/basic-install.sh"
+source "${PI_HOLE_FILES_DIR}/automated-install/basic-install.sh"
 
-coltable="/opt/pihole/COL_TABLE"
+coltable="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 if [[ -f ${coltable} ]]; then
     source ${coltable}
 fi
@@ -75,7 +75,7 @@ changeFTLsetting() {
 }
 
 add_dnsmasq_setting() {
-    if [[ "${2}" != "" ]]; then
+    if [[ ${2} != "" ]]; then
         echo "${1}=${2}" >> "${dnsmasqconfig}"
     else
         echo "${1}" >> "${dnsmasqconfig}"
@@ -111,7 +111,7 @@ SetWebPassword() {
         exit 1
     fi
 
-    if (( ${#args[2]} > 0 )) ; then
+    if ((${#args[2]} > 0)); then
         readonly PASSWORD="${args[2]}"
         readonly CONFIRM="${PASSWORD}"
     else
@@ -121,17 +121,17 @@ SetWebPassword() {
         read -s -r -p "Enter New Password (Blank for no password): " PASSWORD
         echo ""
 
-    if [ "${PASSWORD}" == "" ]; then
-        change_setting "WEBPASSWORD" ""
-        echo -e "  ${TICK} Password Removed"
-        exit 0
-    fi
+        if [ "${PASSWORD}" == "" ]; then
+            change_setting "WEBPASSWORD" ""
+            echo -e "  ${TICK} Password Removed"
+            exit 0
+        fi
 
-    read -s -r -p "Confirm Password: " CONFIRM
-    echo ""
+        read -s -r -p "Confirm Password: " CONFIRM
+        echo ""
     fi
 
-    if [ "${PASSWORD}" == "${CONFIRM}" ] ; then
+    if [ "${PASSWORD}" == "${CONFIRM}" ]; then
         # We do not wrap this in brackets, otherwise BASH will expand any appropriate syntax
         hash=$(HashPassword "$PASSWORD")
         # Save hash to file
@@ -149,13 +149,13 @@ ProcessDNSSettings() {
     delete_dnsmasq_setting "server"
 
     COUNTER=1
-    while true ; do
+    while true; do
         var=PIHOLE_DNS_${COUNTER}
         if [ -z "${!var}" ]; then
-            break;
+            break
         fi
         add_dnsmasq_setting "server" "${!var}"
-        (( COUNTER++ ))
+        ((COUNTER++))
     done
 
     # The option LOCAL_DNS_PORT is deprecated
@@ -169,21 +169,21 @@ ProcessDNSSettings() {
     delete_dnsmasq_setting "domain-needed"
     delete_dnsmasq_setting "expand-hosts"
 
-    if [[ "${DNS_FQDN_REQUIRED}" == true ]]; then
+    if [[ ${DNS_FQDN_REQUIRED} == true ]]; then
         add_dnsmasq_setting "domain-needed"
         add_dnsmasq_setting "expand-hosts"
     fi
 
     delete_dnsmasq_setting "bogus-priv"
 
-    if [[ "${DNS_BOGUS_PRIV}" == true ]]; then
+    if [[ ${DNS_BOGUS_PRIV} == true ]]; then
         add_dnsmasq_setting "bogus-priv"
     fi
 
     delete_dnsmasq_setting "dnssec"
     delete_dnsmasq_setting "trust-anchor="
 
-    if [[ "${DNSSEC}" == true ]]; then
+    if [[ ${DNSSEC} == true ]]; then
         echo "dnssec
 trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC683457104237C7F8EC8D
 " >> "${dnsmasqconfig}"
@@ -199,10 +199,10 @@ trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC68345710423
     delete_dnsmasq_setting "interface"
     delete_dnsmasq_setting "local-service"
 
-    if [[ "${DNSMASQ_LISTENING}" == "all" ]]; then
+    if [[ ${DNSMASQ_LISTENING} == "all" ]]; then
         # Listen on all interfaces, permit all origins
         add_dnsmasq_setting "except-interface" "nonexisting"
-    elif [[ "${DNSMASQ_LISTENING}" == "local" ]]; then
+    elif [[ ${DNSMASQ_LISTENING} == "local" ]]; then
         # Listen only on all interfaces, but only local subnets
         add_dnsmasq_setting "local-service"
     else
@@ -215,7 +215,7 @@ trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC68345710423
         add_dnsmasq_setting "interface" "${PIHOLE_INTERFACE}"
     fi
 
-    if [[ "${CONDITIONAL_FORWARDING}" == true ]]; then
+    if [[ ${CONDITIONAL_FORWARDING} == true ]]; then
         # Convert legacy "conditional forwarding" to rev-server configuration
         # Remove any existing REV_SERVER settings
         delete_setting "REV_SERVER"
@@ -237,17 +237,17 @@ trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC68345710423
         #          1.168.192.in-addr.arpa to 192.168.1.0/24
         #          168.192.in-addr.arpa to 192.168.0.0/16
         #          192.in-addr.arpa to 192.0.0.0/8
-        if [[ "${CONDITIONAL_FORWARDING_REVERSE}" == *"in-addr.arpa" ]];then
+        if [[ ${CONDITIONAL_FORWARDING_REVERSE} == *"in-addr.arpa" ]]; then
             arrRev=("${CONDITIONAL_FORWARDING_REVERSE//./ }")
             case ${#arrRev[@]} in
-                6   )   REV_SERVER_CIDR="${arrRev[3]}.${arrRev[2]}.${arrRev[1]}.${arrRev[0]}/32";;
-                5   )   REV_SERVER_CIDR="${arrRev[2]}.${arrRev[1]}.${arrRev[0]}.0/24";;
-                4   )   REV_SERVER_CIDR="${arrRev[1]}.${arrRev[0]}.0.0/16";;
-                3   )   REV_SERVER_CIDR="${arrRev[0]}.0.0.0/8";;
+                6) REV_SERVER_CIDR="${arrRev[3]}.${arrRev[2]}.${arrRev[1]}.${arrRev[0]}/32" ;;
+                5) REV_SERVER_CIDR="${arrRev[2]}.${arrRev[1]}.${arrRev[0]}.0/24" ;;
+                4) REV_SERVER_CIDR="${arrRev[1]}.${arrRev[0]}.0.0/16" ;;
+                3) REV_SERVER_CIDR="${arrRev[0]}.0.0.0/8" ;;
             esac
         else
-          # Set REV_SERVER_CIDR to whatever value it was set to
-          REV_SERVER_CIDR="${CONDITIONAL_FORWARDING_REVERSE}"
+            # Set REV_SERVER_CIDR to whatever value it was set to
+            REV_SERVER_CIDR="${CONDITIONAL_FORWARDING_REVERSE}"
         fi
 
         # If REV_SERVER_CIDR is not converted by the above, then use the REV_SERVER_TARGET variable to derive it
@@ -266,7 +266,7 @@ trust-anchor=.,20326,8,2,E06D44B80B8F1D39A95C0B0D7C65D08458E880409BBC68345710423
         delete_setting "CONDITIONAL_FORWARDING_IP"
     fi
 
-    if [[ "${REV_SERVER}" == true ]]; then
+    if [[ ${REV_SERVER} == true ]]; then
         add_dnsmasq_setting "rev-server=${REV_SERVER_CIDR},${REV_SERVER_TARGET}"
         if [ -n "${REV_SERVER_DOMAIN}" ]; then
             add_dnsmasq_setting "server=/${REV_SERVER_DOMAIN}/${REV_SERVER_TARGET}"
@@ -290,39 +290,38 @@ SetDNSServers() {
     # Save setting to file
     delete_setting "PIHOLE_DNS"
     IFS=',' read -r -a array <<< "${args[2]}"
-    for index in "${!array[@]}"
-    do
+    for index in "${!array[@]}"; do
         # Replace possible "\#" by "#". This fixes AdminLTE#1427
         local ip
         ip="${array[index]//\\#/#}"
 
-        if valid_ip "${ip}" || valid_ip6 "${ip}" ; then
-            add_setting "PIHOLE_DNS_$((index+1))" "${ip}"
+        if valid_ip "${ip}" || valid_ip6 "${ip}"; then
+            add_setting "PIHOLE_DNS_$((index + 1))" "${ip}"
         else
             echo -e "  ${CROSS} Invalid IP has been passed"
             exit 1
         fi
     done
 
-    if [[ "${args[3]}" == "domain-needed" ]]; then
+    if [[ ${args[3]} == "domain-needed" ]]; then
         change_setting "DNS_FQDN_REQUIRED" "true"
     else
         change_setting "DNS_FQDN_REQUIRED" "false"
     fi
 
-    if [[ "${args[4]}" == "bogus-priv" ]]; then
+    if [[ ${args[4]} == "bogus-priv" ]]; then
         change_setting "DNS_BOGUS_PRIV" "true"
     else
         change_setting "DNS_BOGUS_PRIV" "false"
     fi
 
-    if [[ "${args[5]}" == "dnssec" ]]; then
+    if [[ ${args[5]} == "dnssec" ]]; then
         change_setting "DNSSEC" "true"
     else
         change_setting "DNSSEC" "false"
     fi
 
-    if [[ "${args[6]}" == "rev-server" ]]; then
+    if [[ ${args[6]} == "rev-server" ]]; then
         change_setting "REV_SERVER" "true"
         change_setting "REV_SERVER_CIDR" "${args[7]}"
         change_setting "REV_SERVER_TARGET" "${args[8]}"
@@ -345,12 +344,12 @@ SetExcludeClients() {
     change_setting "API_EXCLUDE_CLIENTS" "${args[2]}"
 }
 
-Poweroff(){
-    nohup bash -c "sleep 5; poweroff" &> /dev/null </dev/null &
+Poweroff() {
+    nohup bash -c "sleep 5; poweroff" &> /dev/null < /dev/null &
 }
 
 Reboot() {
-    nohup bash -c "sleep 5; reboot" &> /dev/null </dev/null &
+    nohup bash -c "sleep 5; reboot" &> /dev/null < /dev/null &
 }
 
 RestartDNS() {
@@ -364,35 +363,35 @@ SetQueryLogOptions() {
 ProcessDHCPSettings() {
     source "${setupVars}"
 
-    if [[ "${DHCP_ACTIVE}" == "true" ]]; then
-    interface="${PIHOLE_INTERFACE}"
+    if [[ ${DHCP_ACTIVE} == "true" ]]; then
+        interface="${PIHOLE_INTERFACE}"
 
-    # Use eth0 as fallback interface
-    if [ -z ${interface} ]; then
-        interface="eth0"
-    fi
+        # Use eth0 as fallback interface
+        if [ -z ${interface} ]; then
+            interface="eth0"
+        fi
 
-    if [[ "${PIHOLE_DOMAIN}" == "" ]]; then
-        PIHOLE_DOMAIN="lan"
-        change_setting "PIHOLE_DOMAIN" "${PIHOLE_DOMAIN}"
-    fi
+        if [[ ${PIHOLE_DOMAIN} == "" ]]; then
+            PIHOLE_DOMAIN="lan"
+            change_setting "PIHOLE_DOMAIN" "${PIHOLE_DOMAIN}"
+        fi
 
-    if [[ "${DHCP_LEASETIME}" == "0" ]]; then
-        leasetime="infinite"
-    elif [[ "${DHCP_LEASETIME}" == "" ]]; then
-        leasetime="24"
-        change_setting "DHCP_LEASETIME" "${leasetime}"
-    elif [[ "${DHCP_LEASETIME}" == "24h" ]]; then
-        #Installation is affected by known bug, introduced in a previous version.
-        #This will automatically clean up setupVars.conf and remove the unnecessary "h"
-        leasetime="24"
-        change_setting "DHCP_LEASETIME" "${leasetime}"
-    else
-        leasetime="${DHCP_LEASETIME}h"
-    fi
+        if [[ ${DHCP_LEASETIME} == "0" ]]; then
+            leasetime="infinite"
+        elif [[ ${DHCP_LEASETIME} == "" ]]; then
+            leasetime="24"
+            change_setting "DHCP_LEASETIME" "${leasetime}"
+        elif [[ ${DHCP_LEASETIME} == "24h" ]]; then
+            #Installation is affected by known bug, introduced in a previous version.
+            #This will automatically clean up setupVars.conf and remove the unnecessary "h"
+            leasetime="24"
+            change_setting "DHCP_LEASETIME" "${leasetime}"
+        else
+            leasetime="${DHCP_LEASETIME}h"
+        fi
 
-    # Write settings to file
-    echo "###############################################################################
+        # Write settings to file
+        echo "###############################################################################
 #  DHCP SERVER CONFIG FILE AUTOMATICALLY POPULATED BY PI-HOLE WEB INTERFACE.  #
 #            ANY CHANGES MADE TO THIS FILE WILL BE LOST ON CHANGE             #
 ###############################################################################
@@ -402,37 +401,37 @@ dhcp-option=option:router,${DHCP_ROUTER}
 dhcp-leasefile=/etc/pihole/dhcp.leases
 #quiet-dhcp
 " > "${dhcpconfig}"
-    chmod 644 "${dhcpconfig}"
-
-    if [[ "${PIHOLE_DOMAIN}" != "none" ]]; then
-        echo "domain=${PIHOLE_DOMAIN}" >> "${dhcpconfig}"
-
-        # When there is a Pi-hole domain set and "Never forward non-FQDNs" is
-        # ticked, we add `local=/domain/` to tell FTL that this domain is purely
-        # local and FTL may answer queries from /etc/hosts or DHCP but should
-        # never forward queries on that domain to any upstream servers
-        if  [[ "${DNS_FQDN_REQUIRED}" == true ]]; then
-          echo "local=/${PIHOLE_DOMAIN}/" >> "${dhcpconfig}"
+        chmod 644 "${dhcpconfig}"
+
+        if [[ ${PIHOLE_DOMAIN} != "none" ]]; then
+            echo "domain=${PIHOLE_DOMAIN}" >> "${dhcpconfig}"
+
+            # When there is a Pi-hole domain set and "Never forward non-FQDNs" is
+            # ticked, we add `local=/domain/` to tell FTL that this domain is purely
+            # local and FTL may answer queries from /etc/hosts or DHCP but should
+            # never forward queries on that domain to any upstream servers
+            if [[ ${DNS_FQDN_REQUIRED} == true ]]; then
+                echo "local=/${PIHOLE_DOMAIN}/" >> "${dhcpconfig}"
+            fi
         fi
-    fi
 
-    # Sourced from setupVars
-    # shellcheck disable=SC2154
-    if [[ "${DHCP_rapid_commit}" == "true" ]]; then
-        echo "dhcp-rapid-commit" >> "${dhcpconfig}"
-    fi
+        # Sourced from setupVars
+        # shellcheck disable=SC2154
+        if [[ ${DHCP_rapid_commit} == "true" ]]; then
+            echo "dhcp-rapid-commit" >> "${dhcpconfig}"
+        fi
 
-    if [[ "${DHCP_IPv6}" == "true" ]]; then
-        echo "#quiet-dhcp6
+        if [[ ${DHCP_IPv6} == "true" ]]; then
+            echo "#quiet-dhcp6
 #enable-ra
 dhcp-option=option6:dns-server,[::]
 dhcp-range=::100,::1ff,constructor:${interface},ra-names,slaac,${leasetime}
 ra-param=*,0,0
 " >> "${dhcpconfig}"
-    fi
+        fi
 
     else
-        if [[ -f "${dhcpconfig}" ]]; then
+        if [[ -f ${dhcpconfig} ]]; then
             rm "${dhcpconfig}" &> /dev/null
         fi
     fi
@@ -485,16 +484,16 @@ SetWebUITheme() {
     change_setting "WEBTHEME" "${args[2]}"
 }
 
-CheckUrl(){
+CheckUrl() {
     local regex check_url
     # Check for characters NOT allowed in URLs
     regex="[^a-zA-Z0-9:/?&%=~._()-;]"
 
     # this will remove first @ that is after schema and before domain
     # \1 is optional schema, \2 is userinfo
-    check_url="$( sed -re 's#([^:/]*://)?([^/]+)@#\1\2#' <<< "$1" )"
+    check_url="$(sed -re 's#([^:/]*://)?([^/]+)@#\1\2#' <<< "$1")"
 
-    if [[ "${check_url}" =~ ${regex} ]]; then
+    if [[ ${check_url} =~ ${regex} ]]; then
         return 1
     else
         return 0
@@ -508,13 +507,13 @@ CustomizeAdLists() {
     comment="${args[4]}"
 
     if CheckUrl "${address}"; then
-        if [[ "${args[2]}" == "enable" ]]; then
+        if [[ ${args[2]} == "enable" ]]; then
             sqlite3 "${gravityDBfile}" "UPDATE adlist SET enabled = 1 WHERE address = '${address}'"
-        elif [[ "${args[2]}" == "disable" ]]; then
+        elif [[ ${args[2]} == "disable" ]]; then
             sqlite3 "${gravityDBfile}" "UPDATE adlist SET enabled = 0 WHERE address = '${address}'"
-        elif [[ "${args[2]}" == "add" ]]; then
+        elif [[ ${args[2]} == "add" ]]; then
             sqlite3 "${gravityDBfile}" "INSERT OR IGNORE INTO adlist (address, comment) VALUES ('${address}', '${comment}')"
-        elif [[ "${args[2]}" == "del" ]]; then
+        elif [[ ${args[2]} == "del" ]]; then
             sqlite3 "${gravityDBfile}" "DELETE FROM adlist WHERE address = '${address}'"
         else
             echo "Not permitted"
@@ -527,7 +526,7 @@ CustomizeAdLists() {
 }
 
 SetPrivacyMode() {
-    if [[ "${args[2]}" == "true" ]]; then
+    if [[ ${args[2]} == "true" ]]; then
         change_setting "API_PRIVACY_MODE" "true"
     else
         change_setting "API_PRIVACY_MODE" "false"
@@ -538,9 +537,9 @@ ResolutionSettings() {
     typ="${args[2]}"
     state="${args[3]}"
 
-    if [[ "${typ}" == "forward" ]]; then
+    if [[ ${typ} == "forward" ]]; then
         change_setting "API_GET_UPSTREAM_DNS_HOSTNAME" "${state}"
-    elif [[ "${typ}" == "clients" ]]; then
+    elif [[ ${typ} == "clients" ]]; then
         change_setting "API_GET_CLIENT_HOSTNAME" "${state}"
     fi
 }
@@ -550,10 +549,10 @@ AddDHCPStaticAddress() {
     ip="${args[3]}"
     host="${args[4]}"
 
-    if [[ "${ip}" == "noip" ]]; then
+    if [[ ${ip} == "noip" ]]; then
         # Static host name
         echo "dhcp-host=${mac},${host}" >> "${dhcpstaticconfig}"
-    elif [[ "${host}" == "nohost" ]]; then
+    elif [[ ${host} == "nohost" ]]; then
         # Static IP
         echo "dhcp-host=${mac},${ip}" >> "${dhcpstaticconfig}"
     else
@@ -564,7 +563,7 @@ AddDHCPStaticAddress() {
 
 RemoveDHCPStaticAddress() {
     mac="${args[2]}"
-    if [[ "$mac" =~ ^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$ ]]; then
+    if [[ $mac =~ ^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$ ]]; then
         sed -i "/dhcp-host=${mac}.*/d" "${dhcpstaticconfig}"
     else
         echo "  ${CROSS} Invalid Mac Passed!"
@@ -574,7 +573,7 @@ RemoveDHCPStaticAddress() {
 }
 
 SetAdminEmail() {
-    if [[ "${1}" == "-h" ]] || [[ "${1}" == "--help" ]]; then
+    if [[ ${1} == "-h" ]] || [[ ${1} == "--help" ]]; then
         echo "Usage: pihole -a email <address>
 Example: 'pihole -a email admin@address.com'
 Set an administrative contact address for the Block Page
@@ -585,13 +584,13 @@ Options:
         exit 0
     fi
 
-    if [[ -n "${args[2]}" ]]; then
+    if [[ -n ${args[2]} ]]; then
 
         # Sanitize email address in case of security issues
         # Regex from https://stackoverflow.com/a/2138832/4065967
         local regex
         regex="^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\$"
-        if [[ ! "${args[2]}" =~ ${regex} ]]; then
+        if [[ ! ${args[2]} =~ ${regex} ]]; then
             echo -e "  ${CROSS} Invalid email address"
             exit 0
         fi
@@ -607,7 +606,7 @@ Options:
 SetListeningMode() {
     source "${setupVars}"
 
-    if [[ "$3" == "-h" ]] || [[ "$3" == "--help" ]]; then
+    if [[ $3 == "-h" ]] || [[ $3 == "--help" ]]; then
         echo "Usage: pihole -a -i [interface]
 Example: 'pihole -a -i local'
 Specify dnsmasq's network interface listening behavior
@@ -618,12 +617,12 @@ Interfaces:
   single              Listen only on ${PIHOLE_INTERFACE} interface
   all                 Listen on all interfaces, permit all origins"
         exit 0
-  fi
+    fi
 
-    if [[ "${args[2]}" == "all" ]]; then
+    if [[ ${args[2]} == "all" ]]; then
         echo -e "  ${INFO} Listening on all interfaces, permitting all origins. Please use a firewall!"
         change_setting "DNSMASQ_LISTENING" "all"
-    elif [[ "${args[2]}" == "local" ]]; then
+    elif [[ ${args[2]} == "local" ]]; then
         echo -e "  ${INFO} Listening on all interfaces, permitting origins from one hop away (LAN)"
         change_setting "DNSMASQ_LISTENING" "local"
     else
@@ -633,7 +632,7 @@ Interfaces:
 
     # Don't restart DNS server yet because other settings
     # will be applied afterwards if "-web" is set
-    if [[ "${args[3]}" != "-web" ]]; then
+    if [[ ${args[3]} != "-web" ]]; then
         ProcessDNSSettings
         # Restart dnsmasq to load new configuration
         RestartDNS
@@ -649,44 +648,40 @@ Teleporter() {
     php /var/www/html/admin/scripts/pi-hole/php/teleporter.php > "pi-hole-${host:-noname}-teleporter_${datetimestamp}.tar.gz"
 }
 
-checkDomain()
-{
+checkDomain() {
     local domain validDomain
     # Convert to lowercase
     domain="${1,,}"
     validDomain=$(grep -P "^((-|_)*[a-z\\d]((-|_)*[a-z\\d])*(-|_)*)(\\.(-|_)*([a-z\\d]((-|_)*[a-z\\d])*))*$" <<< "${domain}") # Valid chars check
-    validDomain=$(grep -P "^[^\\.]{1,63}(\\.[^\\.]{1,63})*$" <<< "${validDomain}") # Length of each label
+    validDomain=$(grep -P "^[^\\.]{1,63}(\\.[^\\.]{1,63})*$" <<< "${validDomain}")                                            # Length of each label
     echo "${validDomain}"
 }
 
-addAudit()
-{
+addAudit() {
     shift # skip "-a"
     shift # skip "audit"
     local domains validDomain
     domains=""
-    for domain in "$@"
-    do
-      # Check domain to be added. Only continue if it is valid
-      validDomain="$(checkDomain "${domain}")"
-      if [[ -n "${validDomain}" ]]; then
-        # Put comma in between domains when there is
-        # more than one domains to be added
-        # SQL INSERT allows adding multiple rows at once using the format
-        ## INSERT INTO table (domain) VALUES ('abc.de'),('fgh.ij'),('klm.no'),('pqr.st');
-        if [[ -n "${domains}" ]]; then
-          domains="${domains},"
+    for domain in "$@"; do
+        # Check domain to be added. Only continue if it is valid
+        validDomain="$(checkDomain "${domain}")"
+        if [[ -n ${validDomain} ]]; then
+            # Put comma in between domains when there is
+            # more than one domains to be added
+            # SQL INSERT allows adding multiple rows at once using the format
+            ## INSERT INTO table (domain) VALUES ('abc.de'),('fgh.ij'),('klm.no'),('pqr.st');
+            if [[ -n ${domains} ]]; then
+                domains="${domains},"
+            fi
+            domains="${domains}('${domain}')"
         fi
-        domains="${domains}('${domain}')"
-      fi
     done
     # Insert only the domain here. The date_added field will be
     # filled with its default value (date_added = current timestamp)
     sqlite3 "${gravityDBfile}" "INSERT INTO domain_audit (domain) VALUES ${domains};"
 }
 
-clearAudit()
-{
+clearAudit() {
     sqlite3 "${gravityDBfile}" "DELETE FROM domain_audit;"
 }
 
@@ -703,7 +698,7 @@ AddCustomDNSAddress() {
 
     ip="${args[2]}"
     host="${args[3]}"
-	echo "${ip} ${host}" >> "${dnscustomfile}"
+    echo "${ip} ${host}" >> "${dnscustomfile}"
 
     # Restart dnsmasq to load new custom DNS entries
     RestartDNS
@@ -715,7 +710,7 @@ RemoveCustomDNSAddress() {
     ip="${args[2]}"
     host="${args[3]}"
 
-    if valid_ip "${ip}" || valid_ip6 "${ip}" ; then
+    if valid_ip "${ip}" || valid_ip6 "${ip}"; then
         sed -i "/${ip} ${host}/d" "${dnscustomfile}"
     else
         echo -e "  ${CROSS} Invalid IP has been passed"
@@ -745,9 +740,9 @@ RemoveCustomCNAMERecord() {
     target="${args[3]}"
 
     validDomain="$(checkDomain "${domain}")"
-    if [[ -n "${validDomain}" ]]; then
+    if [[ -n ${validDomain} ]]; then
         validTarget="$(checkDomain "${target}")"
-        if [[ -n "${validDomain}" ]]; then
+        if [[ -n ${validDomain} ]]; then
             sed -i "/cname=${validDomain},${validTarget}/d" "${dnscustomcnamefile}"
         else
             echo "  ${CROSS} Invalid Target Passed!"
@@ -766,43 +761,52 @@ main() {
     args=("$@")
 
     case "${args[1]}" in
-        "-p" | "password"     ) SetWebPassword;;
-        "-c" | "celsius"      ) unit="C"; SetTemperatureUnit;;
-        "-f" | "fahrenheit"   ) unit="F"; SetTemperatureUnit;;
-        "-k" | "kelvin"       ) unit="K"; SetTemperatureUnit;;
-        "setdns"              ) SetDNSServers;;
-        "setexcludedomains"   ) SetExcludeDomains;;
-        "setexcludeclients"   ) SetExcludeClients;;
-        "poweroff"            ) Poweroff;;
-        "reboot"              ) Reboot;;
-        "restartdns"          ) RestartDNS;;
-        "setquerylog"         ) SetQueryLogOptions;;
-        "enabledhcp"          ) EnableDHCP;;
-        "disabledhcp"         ) DisableDHCP;;
-        "layout"              ) SetWebUILayout;;
-        "theme"               ) SetWebUITheme;;
-        "-h" | "--help"       ) helpFunc;;
-        "privacymode"         ) SetPrivacyMode;;
-        "resolve"             ) ResolutionSettings;;
-        "addstaticdhcp"       ) AddDHCPStaticAddress;;
-        "removestaticdhcp"    ) RemoveDHCPStaticAddress;;
-        "-e" | "email"        ) SetAdminEmail "$3";;
-        "-i" | "interface"    ) SetListeningMode "$@";;
-        "-t" | "teleporter"   ) Teleporter;;
-        "adlist"              ) CustomizeAdLists;;
-        "audit"               ) addAudit "$@";;
-        "clearaudit"          ) clearAudit;;
-        "-l" | "privacylevel" ) SetPrivacyLevel;;
-        "addcustomdns"        ) AddCustomDNSAddress;;
-        "removecustomdns"     ) RemoveCustomDNSAddress;;
-        "addcustomcname"      ) AddCustomCNAMERecord;;
-        "removecustomcname"   ) RemoveCustomCNAMERecord;;
-        *                     ) helpFunc;;
+        "-p" | "password") SetWebPassword ;;
+        "-c" | "celsius")
+            unit="C"
+            SetTemperatureUnit
+            ;;
+        "-f" | "fahrenheit")
+            unit="F"
+            SetTemperatureUnit
+            ;;
+        "-k" | "kelvin")
+            unit="K"
+            SetTemperatureUnit
+            ;;
+        "setdns") SetDNSServers ;;
+        "setexcludedomains") SetExcludeDomains ;;
+        "setexcludeclients") SetExcludeClients ;;
+        "poweroff") Poweroff ;;
+        "reboot") Reboot ;;
+        "restartdns") RestartDNS ;;
+        "setquerylog") SetQueryLogOptions ;;
+        "enabledhcp") EnableDHCP ;;
+        "disabledhcp") DisableDHCP ;;
+        "layout") SetWebUILayout ;;
+        "theme") SetWebUITheme ;;
+        "-h" | "--help") helpFunc ;;
+        "privacymode") SetPrivacyMode ;;
+        "resolve") ResolutionSettings ;;
+        "addstaticdhcp") AddDHCPStaticAddress ;;
+        "removestaticdhcp") RemoveDHCPStaticAddress ;;
+        "-e" | "email") SetAdminEmail "$3" ;;
+        "-i" | "interface") SetListeningMode "$@" ;;
+        "-t" | "teleporter") Teleporter ;;
+        "adlist") CustomizeAdLists ;;
+        "audit") addAudit "$@" ;;
+        "clearaudit") clearAudit ;;
+        "-l" | "privacylevel") SetPrivacyLevel ;;
+        "addcustomdns") AddCustomDNSAddress ;;
+        "removecustomdns") RemoveCustomDNSAddress ;;
+        "addcustomcname") AddCustomCNAMERecord ;;
+        "removecustomcname") RemoveCustomCNAMERecord ;;
+        *) helpFunc ;;
     esac
 
     shift
 
-    if [[ $# = 0 ]]; then
+    if [[ $# == 0 ]]; then
         helpFunc
     fi
 }
diff --git a/advanced/Scripts/wildcard_regex_converter.sh b/advanced/Scripts/wildcard_regex_converter.sh
index b4b6b4a1..26a698e6 100644
--- a/advanced/Scripts/wildcard_regex_converter.sh
+++ b/advanced/Scripts/wildcard_regex_converter.sh
@@ -10,7 +10,7 @@
 
 # regexFile set in gravity.sh
 
-wildcardFile="/etc/dnsmasq.d/03-pihole-wildcard.conf"
+wildcardFile="@EPREFIX@/etc/pihole/dnsmasq.d/03-pihole-wildcard.conf"
 
 convert_wildcard_to_regex() {
     if [ ! -f "${wildcardFile}" ]; then
diff --git a/advanced/Templates/gravity_copy.sql b/advanced/Templates/gravity_copy.sql
index 4a2a9b22..f5556929 100644
--- a/advanced/Templates/gravity_copy.sql
+++ b/advanced/Templates/gravity_copy.sql
@@ -1,6 +1,6 @@
 .timeout 30000
 
-ATTACH DATABASE '/etc/pihole/gravity.db' AS OLD;
+ATTACH DATABASE '@EPREFIX@/var/lib/pihole/gravity.db' AS OLD;
 
 BEGIN TRANSACTION;
 
diff --git a/advanced/Templates/pihole.cron b/advanced/Templates/pihole.cron
index ecd1e808..7b6c2102 100644
--- a/advanced/Templates/pihole.cron
+++ b/advanced/Templates/pihole.cron
@@ -18,19 +18,12 @@
 #          early morning. Download any updates from the adlists
 #          Squash output to log, then splat the log to stdout on error to allow for
 #          standard crontab job error handling.
-59 1    * * 7   root    PATH="$PATH:/usr/sbin:/usr/local/bin/" pihole updateGravity >/var/log/pihole_updateGravity.log || cat /var/log/pihole_updateGravity.log
+59 1    * * 7   root    PATH="$PATH:@EPREFIX@/usr/sbin" @EPREFIX@/usr/bin/pihole updateGravity >/var/log/pihole_updateGravity.log || cat /var/log/pihole_updateGravity.log
 
 # Pi-hole: Flush the log daily at 00:00
 #          The flush script will use logrotate if available
 #          parameter "once": logrotate only once (default is twice)
 #          parameter "quiet": don't print messages
-00 00   * * *   root    PATH="$PATH:/usr/sbin:/usr/local/bin/" pihole flush once quiet
+00 00   * * *   root    PATH="$PATH:@EPREFIX@/usr/sbin" @EPREFIX@/usr/bin/pihole flush once quiet
 
-@reboot root /usr/sbin/logrotate /etc/pihole/logrotate
-
-# Pi-hole: Grab local version and branch every 10 minutes
-*/10 *  * * *   root    PATH="$PATH:/usr/sbin:/usr/local/bin/" pihole updatechecker local
-
-# Pi-hole: Grab remote version every 24 hours
-59 17  * * *   root    PATH="$PATH:/usr/sbin:/usr/local/bin/" pihole updatechecker remote
-@reboot root    PATH="$PATH:/usr/sbin:/usr/local/bin/" pihole updatechecker remote reboot
+@reboot root @EPREFIX@/usr/bin/logrotate @EPREFIX@/etc/pihole/logrotate
diff --git a/advanced/index.php b/advanced/index.php
index a38cd365..9412d5a4 100644
--- a/advanced/index.php
+++ b/advanced/index.php
@@ -11,11 +11,11 @@ $serverName = htmlspecialchars($_SERVER["SERVER_NAME"]);
 // Remove external ipv6 brackets if any
 $serverName = preg_replace('/^\[(.*)\]$/', '${1}', $serverName);
 
-if (!is_file("/etc/pihole/setupVars.conf"))
+if (!is_file("@EPREFIX@/etc/pihole/setupVars.conf"))
   die("[ERROR] File not found: <code>/etc/pihole/setupVars.conf</code>");
 
 // Get values from setupVars.conf
-$setupVars = parse_ini_file("/etc/pihole/setupVars.conf");
+$setupVars = parse_ini_file("@EPREFIX@/etc/pihole/setupVars.conf");
 $svPasswd = !empty($setupVars["WEBPASSWORD"]);
 $svEmail = (!empty($setupVars["ADMIN_EMAIL"]) && filter_var($setupVars["ADMIN_EMAIL"], FILTER_VALIDATE_EMAIL)) ? $setupVars["ADMIN_EMAIL"] : "";
 unset($setupVars);
@@ -130,11 +130,11 @@ EOT;
 $bpAskAdmin = !empty($svEmail) ? '<a href="mailto:'.$svEmail.'?subject=Site Blocked: '.$serverName.'"></a>' : "<span/>";
 
 // Get possible non-standard location of FTL's database
-$FTLsettings = parse_ini_file("/etc/pihole/pihole-FTL.conf");
+$FTLsettings = parse_ini_file("@EPREFIX@/etc/pihole/pihole-FTL.conf");
 if (isset($FTLsettings["GRAVITYDB"])) {
     $gravityDBFile = $FTLsettings["GRAVITYDB"];
 } else {
-    $gravityDBFile = "/etc/pihole/gravity.db";
+    $gravityDBFile = "@EPREFIX@/var/lib/pihole/gravity.db";
 }
 
 // Connect to gravity.db
@@ -240,7 +240,7 @@ $wlOutputClass = (isset($wlInfo) && $wlInfo === "recentwl") ? $wlInfo : "hidden"
 $wlOutput = (isset($wlInfo) && $wlInfo !== "recentwl") ? "<a href='http://$wlInfo'>$wlInfo</a>" : "";
 
 // Get Pi-hole Core version
-$phVersion = exec("cd /etc/.pihole/ && git describe --long --tags");
+$phVersion = "@PIHOLE_VERSION@";
 
 // Print $execTime on development branches
 // Testing for - is marginally faster than "git rev-parse --abbrev-ref HEAD"
diff --git a/gravity.sh b/gravity.sh
index 24a41c48..7a6fa493 100755
--- a/gravity.sh
+++ b/gravity.sh
@@ -13,17 +13,17 @@
 
 export LC_ALL=C
 
-coltable="/opt/pihole/COL_TABLE"
+coltable="@EPREFIX@/usr/@LIBDIR@/pihole/COL_TABLE"
 source "${coltable}"
-regexconverter="/opt/pihole/wildcard_regex_converter.sh"
+regexconverter="@EPREFIX@/usr/@LIBDIR@/pihole/wildcard_regex_converter.sh"
 source "${regexconverter}"
 # shellcheck disable=SC1091
-source "/etc/.pihole/advanced/Scripts/database_migration/gravity-db.sh"
+source "@EPREFIX@/usr/@LIBDIR@/database_migration/gravity-db.sh"
 
 basename="pihole"
-PIHOLE_COMMAND="/usr/local/bin/${basename}"
+PIHOLE_COMMAND="@EPREFIX@/usr/bin/${basename}"
 
-piholeDir="/etc/${basename}"
+piholeDir="@EPREFIX@/etc/${basename}"
 
 # Legacy (pre v5.0) list file locations
 whitelistFile="${piholeDir}/whitelist.txt"
@@ -32,10 +32,10 @@ regexFile="${piholeDir}/regex.list"
 adListFile="${piholeDir}/adlists.list"
 
 localList="${piholeDir}/local.list"
-VPNList="/etc/openvpn/ipp.txt"
+VPNList="@EPREFIX@/etc/openvpn/ipp.txt"
 
-piholeGitDir="/etc/.pihole"
-gravityDBfile_default="${piholeDir}/gravity.db"
+piholeGitDir="@EPREFIX@/usr/@LIBDIR@/pihole"
+gravityDBfile_default="@EPREFIX@/var/lib/pihole/gravity.db"
 # GRAVITYDB may be overwritten by source pihole-FTL.conf below
 GRAVITYDB="${gravityDBfile_default}"
 gravityDBschema="${piholeGitDir}/advanced/Templates/gravity.db.sql"
@@ -45,28 +45,28 @@ domainsExtension="domains"
 
 # Source setupVars from install script
 setupVars="${piholeDir}/setupVars.conf"
-if [[ -f "${setupVars}" ]];then
-  source "${setupVars}"
+if [[ -f ${setupVars} ]]; then
+    source "${setupVars}"
 
-  # Remove CIDR mask from IPv4/6 addresses
-  IPV4_ADDRESS="${IPV4_ADDRESS%/*}"
-  IPV6_ADDRESS="${IPV6_ADDRESS%/*}"
+    # Remove CIDR mask from IPv4/6 addresses
+    IPV4_ADDRESS="${IPV4_ADDRESS%/*}"
+    IPV6_ADDRESS="${IPV6_ADDRESS%/*}"
 
-  # Determine if IPv4/6 addresses exist
-  if [[ -z "${IPV4_ADDRESS}" ]] && [[ -z "${IPV6_ADDRESS}" ]]; then
-    echo -e "  ${COL_LIGHT_RED}No IP addresses found! Please run 'pihole -r' to reconfigure${COL_NC}"
-    exit 1
-  fi
+    # Determine if IPv4/6 addresses exist
+    if [[ -z ${IPV4_ADDRESS} ]] && [[ -z ${IPV6_ADDRESS} ]]; then
+        echo -e "  ${COL_LIGHT_RED}No IP addresses found! Please run 'pihole -r' to reconfigure${COL_NC}"
+        exit 1
+    fi
 else
-  echo -e "  ${COL_LIGHT_RED}Installation Failure: ${setupVars} does not exist! ${COL_NC}
+    echo -e "  ${COL_LIGHT_RED}Installation Failure: ${setupVars} does not exist! ${COL_NC}
   Please run 'pihole -r', and choose the 'reconfigure' option to fix."
-  exit 1
+    exit 1
 fi
 
 # Source pihole-FTL from install script
 pihole_FTL="${piholeDir}/pihole-FTL.conf"
-if [[ -f "${pihole_FTL}" ]]; then
-  source "${pihole_FTL}"
+if [[ -f ${pihole_FTL} ]]; then
+    source "${pihole_FTL}"
 fi
 
 # Set this only after sourcing pihole-FTL.conf as the gravity database path may
@@ -74,628 +74,640 @@ fi
 gravityDBfile="${GRAVITYDB}"
 gravityTEMPfile="${GRAVITYDB}_temp"
 
-if [[ -z "${BLOCKINGMODE}" ]] ; then
-  BLOCKINGMODE="NULL"
+if [[ -z ${BLOCKINGMODE} ]]; then
+    BLOCKINGMODE="NULL"
 fi
 
 # Determine if superseded pihole.conf exists
 if [[ -r "${piholeDir}/pihole.conf" ]]; then
-  echo -e "  ${COL_LIGHT_RED}Ignoring overrides specified within pihole.conf! ${COL_NC}"
+    echo -e "  ${COL_LIGHT_RED}Ignoring overrides specified within pihole.conf! ${COL_NC}"
 fi
 
 # Generate new sqlite3 file from schema template
 generate_gravity_database() {
-  sqlite3 "${1}" < "${gravityDBschema}"
+    sqlite3 "${1}" < "${gravityDBschema}"
 }
 
 # Copy data from old to new database file and swap them
 gravity_swap_databases() {
-  local str copyGravity
-  str="Building tree"
-  echo -ne "  ${INFO} ${str}..."
-
-  # The index is intentionally not UNIQUE as poor quality adlists may contain domains more than once
-  output=$( { sqlite3 "${gravityTEMPfile}" "CREATE INDEX idx_gravity ON gravity (domain, adlist_id);"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to build gravity tree in ${gravityTEMPfile}\\n  ${output}"
-    return 1
-  fi
-  echo -e "${OVER}  ${TICK} ${str}"
-
-  str="Swapping databases"
-  echo -ne "  ${INFO} ${str}..."
-
-  # Gravity copying SQL script
-  copyGravity="$(cat "${gravityDBcopy}")"
-  if [[ "${gravityDBfile}" != "${gravityDBfile_default}" ]]; then
-    # Replace default gravity script location by custom location
-    copyGravity="${copyGravity//"${gravityDBfile_default}"/"${gravityDBfile}"}"
-  fi
-
-  output=$( { sqlite3 "${gravityTEMPfile}" <<< "${copyGravity}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to copy data from ${gravityDBfile} to ${gravityTEMPfile}\\n  ${output}"
-    return 1
-  fi
-  echo -e "${OVER}  ${TICK} ${str}"
-
-  # Swap databases and remove old database
-  rm "${gravityDBfile}"
-  mv "${gravityTEMPfile}" "${gravityDBfile}"
+    local str copyGravity
+    str="Building tree"
+    echo -ne "  ${INFO} ${str}..."
+
+    # The index is intentionally not UNIQUE as poor quality adlists may contain domains more than once
+    output=$({ sqlite3 "${gravityTEMPfile}" "CREATE INDEX idx_gravity ON gravity (domain, adlist_id);"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to build gravity tree in ${gravityTEMPfile}\\n  ${output}"
+        return 1
+    fi
+    echo -e "${OVER}  ${TICK} ${str}"
+
+    str="Swapping databases"
+    echo -ne "  ${INFO} ${str}..."
+
+    # Gravity copying SQL script
+    copyGravity="$(cat "${gravityDBcopy}")"
+    if [[ ${gravityDBfile} != "${gravityDBfile_default}" ]]; then
+        # Replace default gravity script location by custom location
+        copyGravity="${copyGravity//"${gravityDBfile_default}"/"${gravityDBfile}"}"
+    fi
+
+    output=$({ sqlite3 "${gravityTEMPfile}" <<< "${copyGravity}"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to copy data from ${gravityDBfile} to ${gravityTEMPfile}\\n  ${output}"
+        return 1
+    fi
+    echo -e "${OVER}  ${TICK} ${str}"
+
+    # Swap databases and remove old database
+    rm "${gravityDBfile}"
+    mv "${gravityTEMPfile}" "${gravityDBfile}"
 }
 
 # Update timestamp when the gravity table was last updated successfully
 update_gravity_timestamp() {
-  output=$( { printf ".timeout 30000\\nINSERT OR REPLACE INTO info (property,value) values ('updated',cast(strftime('%%s', 'now') as int));" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to update gravity timestamp in database ${gravityDBfile}\\n  ${output}"
-    return 1
-  fi
-  return 0
+    output=$({ printf ".timeout 30000\\nINSERT OR REPLACE INTO info (property,value) values ('updated',cast(strftime('%%s', 'now') as int));" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to update gravity timestamp in database ${gravityDBfile}\\n  ${output}"
+        return 1
+    fi
+    return 0
 }
 
 # Import domains from file and store them in the specified database table
 database_table_from_file() {
-  # Define locals
-  local table source backup_path backup_file tmpFile type
-  table="${1}"
-  source="${2}"
-  backup_path="${piholeDir}/migration_backup"
-  backup_file="${backup_path}/$(basename "${2}")"
-  tmpFile="$(mktemp -p "/tmp" --suffix=".gravity")"
-
-  local timestamp
-  timestamp="$(date --utc +'%s')"
-
-  local rowid
-  declare -i rowid
-  rowid=1
-
-  # Special handling for domains to be imported into the common domainlist table
-  if [[ "${table}" == "whitelist" ]]; then
-    type="0"
-    table="domainlist"
-  elif [[ "${table}" == "blacklist" ]]; then
-    type="1"
-    table="domainlist"
-  elif [[ "${table}" == "regex" ]]; then
-    type="3"
-    table="domainlist"
-  fi
-
-  # Get MAX(id) from domainlist when INSERTing into this table
-  if [[ "${table}" == "domainlist" ]]; then
-    rowid="$(sqlite3 "${gravityDBfile}" "SELECT MAX(id) FROM domainlist;")"
-    if [[ -z "$rowid" ]]; then
-      rowid=0
-    fi
-    rowid+=1
-  fi
-
-  # Loop over all domains in ${source} file
-  # Read file line by line
-  grep -v '^ *#' < "${source}" | while IFS= read -r domain
-  do
-    # Only add non-empty lines
-    if [[ -n "${domain}" ]]; then
-      if [[ "${table}" == "domain_audit" ]]; then
-        # domain_audit table format (no enable or modified fields)
-        echo "${rowid},\"${domain}\",${timestamp}" >> "${tmpFile}"
-      elif [[ "${table}" == "adlist" ]]; then
-        # Adlist table format
-        echo "${rowid},\"${domain}\",1,${timestamp},${timestamp},\"Migrated from ${source}\",,0,0,0" >> "${tmpFile}"
-      else
-        # White-, black-, and regexlist table format
-        echo "${rowid},${type},\"${domain}\",1,${timestamp},${timestamp},\"Migrated from ${source}\"" >> "${tmpFile}"
-      fi
-      rowid+=1
-    fi
-  done
-
-  # Store domains in database table specified by ${table}
-  # Use printf as .mode and .import need to be on separate lines
-  # see https://unix.stackexchange.com/a/445615/83260
-  output=$( { printf ".timeout 30000\\n.mode csv\\n.import \"%s\" %s\\n" "${tmpFile}" "${table}" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to fill table ${table}${type} in database ${gravityDBfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  fi
-
-  # Move source file to backup directory, create directory if not existing
-  mkdir -p "${backup_path}"
-  mv "${source}" "${backup_file}" 2> /dev/null || \
-      echo -e "  ${CROSS} Unable to backup ${source} to ${backup_path}"
-
-  # Delete tmpFile
-  rm "${tmpFile}" > /dev/null 2>&1 || \
-    echo -e "  ${CROSS} Unable to remove ${tmpFile}"
+    # Define locals
+    local table source backup_path backup_file tmpFile type
+    table="${1}"
+    source="${2}"
+    backup_path="${piholeDir}/migration_backup"
+    backup_file="${backup_path}/$(basename "${2}")"
+    tmpFile="$(mktemp -p "/tmp" --suffix=".gravity")"
+
+    local timestamp
+    timestamp="$(date --utc +'%s')"
+
+    local rowid
+    declare -i rowid
+    rowid=1
+
+    # Special handling for domains to be imported into the common domainlist table
+    if [[ ${table} == "whitelist" ]]; then
+        type="0"
+        table="domainlist"
+    elif [[ ${table} == "blacklist" ]]; then
+        type="1"
+        table="domainlist"
+    elif [[ ${table} == "regex" ]]; then
+        type="3"
+        table="domainlist"
+    fi
+
+    # Get MAX(id) from domainlist when INSERTing into this table
+    if [[ ${table} == "domainlist" ]]; then
+        rowid="$(sqlite3 "${gravityDBfile}" "SELECT MAX(id) FROM domainlist;")"
+        if [[ -z $rowid ]]; then
+            rowid=0
+        fi
+        rowid+=1
+    fi
+
+    # Loop over all domains in ${source} file
+    # Read file line by line
+    grep -v '^ *#' < "${source}" | while IFS= read -r domain; do
+        # Only add non-empty lines
+        if [[ -n ${domain} ]]; then
+            if [[ ${table} == "domain_audit" ]]; then
+                # domain_audit table format (no enable or modified fields)
+                echo "${rowid},\"${domain}\",${timestamp}" >> "${tmpFile}"
+            elif [[ ${table} == "adlist" ]]; then
+                # Adlist table format
+                echo "${rowid},\"${domain}\",1,${timestamp},${timestamp},\"Migrated from ${source}\",,0,0,0" >> "${tmpFile}"
+            else
+                # White-, black-, and regexlist table format
+                echo "${rowid},${type},\"${domain}\",1,${timestamp},${timestamp},\"Migrated from ${source}\"" >> "${tmpFile}"
+            fi
+            rowid+=1
+        fi
+    done
+
+    # Store domains in database table specified by ${table}
+    # Use printf as .mode and .import need to be on separate lines
+    # see https://unix.stackexchange.com/a/445615/83260
+    output=$({ printf '.timeout 30000\n.mode csv\n.import "%s" %s\n' "${tmpFile}" "${table}" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to fill table ${table}${type} in database ${gravityDBfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    fi
+
+    # Move source file to backup directory, create directory if not existing
+    mkdir -p "${backup_path}"
+    mv "${source}" "${backup_file}" 2> /dev/null ||
+        echo -e "  ${CROSS} Unable to backup ${source} to ${backup_path}"
+
+    # Delete tmpFile
+    rm "${tmpFile}" > /dev/null 2>&1 ||
+        echo -e "  ${CROSS} Unable to remove ${tmpFile}"
 }
 
 # Update timestamp of last update of this list. We store this in the "old" database as all values in the new database will later be overwritten
 database_adlist_updated() {
-  output=$( { printf ".timeout 30000\\nUPDATE adlist SET date_updated = (cast(strftime('%%s', 'now') as int)) WHERE id = %i;\\n" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  status="$?"
+    output=$({ printf ".timeout 30000\\nUPDATE adlist SET date_updated = (cast(strftime('%%s', 'now') as int)) WHERE id = %i;\\n" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    status="$?"
 
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to update timestamp of adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  fi
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to update timestamp of adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    fi
 }
 
 # Check if a column with name ${2} exists in gravity table with name ${1}
 gravity_column_exists() {
-  output=$( { printf ".timeout 30000\\nSELECT EXISTS(SELECT * FROM pragma_table_info('%s') WHERE name='%s');\\n" "${1}" "${2}" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  if [[ "${output}" == "1" ]]; then
-    return 0 # Bash 0 is success
-  fi
+    output=$({ printf ".timeout 30000\\nSELECT EXISTS(SELECT * FROM pragma_table_info('%s') WHERE name='%s');\\n" "${1}" "${2}" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    if [[ ${output} == "1" ]]; then
+        return 0 # Bash 0 is success
+    fi
 
-  return 1 # Bash non-0 is failure
+    return 1 # Bash non-0 is failure
 }
 
 # Update number of domain on this list. We store this in the "old" database as all values in the new database will later be overwritten
 database_adlist_number() {
-  # Only try to set number of domains when this field exists in the gravity database
-  if ! gravity_column_exists "adlist" "number"; then
-    return;
-  fi
-
-  output=$( { printf ".timeout 30000\\nUPDATE adlist SET number = %i, invalid_domains = %i WHERE id = %i;\\n" "${num_lines}" "${num_invalid}" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to update number of domains in adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  fi
+    # Only try to set number of domains when this field exists in the gravity database
+    if ! gravity_column_exists "adlist" "number"; then
+        return
+    fi
+
+    output=$({ printf '.timeout 30000\nUPDATE adlist SET number = %i, invalid_domains = %i WHERE id = %i;\n' "${num_lines}" "${num_invalid}" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to update number of domains in adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    fi
 }
 
 # Update status of this list. We store this in the "old" database as all values in the new database will later be overwritten
 database_adlist_status() {
-  # Only try to set the status when this field exists in the gravity database
-  if ! gravity_column_exists "adlist" "status"; then
-    return;
-  fi
-
-  output=$( { printf ".timeout 30000\\nUPDATE adlist SET status = %i WHERE id = %i;\\n" "${2}" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to update status of adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  fi
+    # Only try to set the status when this field exists in the gravity database
+    if ! gravity_column_exists "adlist" "status"; then
+        return
+    fi
+
+    output=$({ printf '.timeout 30000\nUPDATE adlist SET status = %i WHERE id = %i;\n' "${2}" "${1}" | sqlite3 "${gravityDBfile}"; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to update status of adlist with ID ${1} in database ${gravityDBfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    fi
 }
 
 # Migrate pre-v5.0 list files to database-based Pi-hole versions
 migrate_to_database() {
-  # Create database file only if not present
-  if [ ! -e "${gravityDBfile}" ]; then
-    # Create new database file - note that this will be created in version 1
-    echo -e "  ${INFO} Creating new gravity database"
-    generate_gravity_database "${gravityDBfile}"
+    # Create database file only if not present
+    if [ ! -e "${gravityDBfile}" ]; then
+        # Create new database file - note that this will be created in version 1
+        echo -e "  ${INFO} Creating new gravity database"
+        generate_gravity_database "${gravityDBfile}"
+
+        # Check if gravity database needs to be updated
+        upgrade_gravityDB "${gravityDBfile}" "${piholeDir}"
+
+        # Migrate list files to new database
+        if [ -e "${adListFile}" ]; then
+            # Store adlist domains in database
+            echo -e "  ${INFO} Migrating content of ${adListFile} into new database"
+            database_table_from_file "adlist" "${adListFile}"
+        fi
+        if [ -e "${blacklistFile}" ]; then
+            # Store blacklisted domains in database
+            echo -e "  ${INFO} Migrating content of ${blacklistFile} into new database"
+            database_table_from_file "blacklist" "${blacklistFile}"
+        fi
+        if [ -e "${whitelistFile}" ]; then
+            # Store whitelisted domains in database
+            echo -e "  ${INFO} Migrating content of ${whitelistFile} into new database"
+            database_table_from_file "whitelist" "${whitelistFile}"
+        fi
+        if [ -e "${regexFile}" ]; then
+            # Store regex domains in database
+            # Important note: We need to add the domains to the "regex" table
+            # as it will only later be renamed to "regex_blacklist"!
+            echo -e "  ${INFO} Migrating content of ${regexFile} into new database"
+            database_table_from_file "regex" "${regexFile}"
+        fi
+    fi
 
     # Check if gravity database needs to be updated
     upgrade_gravityDB "${gravityDBfile}" "${piholeDir}"
-
-    # Migrate list files to new database
-    if [ -e "${adListFile}" ]; then
-      # Store adlist domains in database
-      echo -e "  ${INFO} Migrating content of ${adListFile} into new database"
-      database_table_from_file "adlist" "${adListFile}"
-    fi
-    if [ -e "${blacklistFile}" ]; then
-      # Store blacklisted domains in database
-      echo -e "  ${INFO} Migrating content of ${blacklistFile} into new database"
-      database_table_from_file "blacklist" "${blacklistFile}"
-    fi
-    if [ -e "${whitelistFile}" ]; then
-      # Store whitelisted domains in database
-      echo -e "  ${INFO} Migrating content of ${whitelistFile} into new database"
-      database_table_from_file "whitelist" "${whitelistFile}"
-    fi
-    if [ -e "${regexFile}" ]; then
-      # Store regex domains in database
-      # Important note: We need to add the domains to the "regex" table
-      # as it will only later be renamed to "regex_blacklist"!
-      echo -e "  ${INFO} Migrating content of ${regexFile} into new database"
-      database_table_from_file "regex" "${regexFile}"
-    fi
-  fi
-
-  # Check if gravity database needs to be updated
-  upgrade_gravityDB "${gravityDBfile}" "${piholeDir}"
 }
 
 # Determine if DNS resolution is available before proceeding
 gravity_CheckDNSResolutionAvailable() {
-  local lookupDomain="pi.hole"
+    local lookupDomain="pi.hole"
 
-  # Determine if $localList does not exist, and ensure it is not empty
-  if [[ ! -e "${localList}" ]] || [[ -s "${localList}" ]]; then
-    lookupDomain="raw.githubusercontent.com"
-  fi
+    # Determine if $localList does not exist, and ensure it is not empty
+    if [[ ! -e ${localList} ]] || [[ -s ${localList} ]]; then
+        lookupDomain="raw.githubusercontent.com"
+    fi
 
-  # Determine if $lookupDomain is resolvable
-  if timeout 4 getent hosts "${lookupDomain}" &> /dev/null; then
-    # Print confirmation of resolvability if it had previously failed
-    if [[ -n "${secs:-}" ]]; then
-      echo -e "${OVER}  ${TICK} DNS resolution is now available\\n"
+    # Determine if $lookupDomain is resolvable
+    if timeout 4 getent hosts "${lookupDomain}" &> /dev/null; then
+        # Print confirmation of resolvability if it had previously failed
+        if [[ -n ${secs:-} ]]; then
+            echo -e "${OVER}  ${TICK} DNS resolution is now available\\n"
+        fi
+        return 0
+    elif [[ -n ${secs:-} ]]; then
+        echo -e "${OVER}  ${CROSS} DNS resolution is not available"
+        exit 1
     fi
-    return 0
-  elif [[ -n "${secs:-}" ]]; then
-    echo -e "${OVER}  ${CROSS} DNS resolution is not available"
-    exit 1
-  fi
 
-  # If the /etc/resolv.conf contains resolvers other than 127.0.0.1 then the local dnsmasq will not be queried and pi.hole is NXDOMAIN.
-  # This means that even though name resolution is working, the getent hosts check fails and the holddown timer keeps ticking and eventually fails
-  # So we check the output of the last command and if it failed, attempt to use dig +short as a fallback
-  if timeout 4 dig +short "${lookupDomain}" &> /dev/null; then
-    if [[ -n "${secs:-}" ]]; then
-      echo -e "${OVER}  ${TICK} DNS resolution is now available\\n"
+    # If the /etc/resolv.conf contains resolvers other than 127.0.0.1 then the local dnsmasq will not be queried and pi.hole is NXDOMAIN.
+    # This means that even though name resolution is working, the getent hosts check fails and the holddown timer keeps ticking and eventually fails
+    # So we check the output of the last command and if it failed, attempt to use dig +short as a fallback
+    if timeout 4 dig +short "${lookupDomain}" &> /dev/null; then
+        if [[ -n ${secs:-} ]]; then
+            echo -e "${OVER}  ${TICK} DNS resolution is now available\\n"
+        fi
+        return 0
+    elif [[ -n ${secs:-} ]]; then
+        echo -e "${OVER}  ${CROSS} DNS resolution is not available"
+        exit 1
     fi
-    return 0
-  elif [[ -n "${secs:-}" ]]; then
-    echo -e "${OVER}  ${CROSS} DNS resolution is not available"
-    exit 1
-  fi
-
-  # Determine error output message
-  if pgrep pihole-FTL &> /dev/null; then
-    echo -e "  ${CROSS} DNS resolution is currently unavailable"
-  else
-    echo -e "  ${CROSS} DNS service is not running"
-    "${PIHOLE_COMMAND}" restartdns
-  fi
-
-  # Ensure DNS server is given time to be resolvable
-  secs="120"
-  echo -ne "  ${INFO} Time until retry: ${secs}"
-  until timeout 1 getent hosts "${lookupDomain}" &> /dev/null; do
-    [[ "${secs:-}" -eq 0 ]] && break
-    echo -ne "${OVER}  ${INFO} Time until retry: ${secs}"
-    : $((secs--))
-    sleep 1
-  done
-
-  # Try again
-  gravity_CheckDNSResolutionAvailable
+
+    # Determine error output message
+    if pgrep pihole-FTL &> /dev/null; then
+        echo -e "  ${CROSS} DNS resolution is currently unavailable"
+    else
+        echo -e "  ${CROSS} DNS service is not running"
+        "${PIHOLE_COMMAND}" restartdns
+    fi
+
+    # Ensure DNS server is given time to be resolvable
+    secs="120"
+    echo -ne "  ${INFO} Time until retry: ${secs}"
+    until timeout 1 getent hosts "${lookupDomain}" &> /dev/null; do
+        [[ ${secs:-} -eq 0 ]] && break
+        echo -ne "${OVER}  ${INFO} Time until retry: ${secs}"
+        : $((secs--))
+        sleep 1
+    done
+
+    # Try again
+    gravity_CheckDNSResolutionAvailable
 }
 
 # Retrieve blocklist URLs and parse domains from adlist.list
 gravity_DownloadBlocklists() {
-  echo -e "  ${INFO} ${COL_BOLD}Neutrino emissions detected${COL_NC}..."
+    echo -e "  ${INFO} ${COL_BOLD}Neutrino emissions detected${COL_NC}..."
 
-  if [[ "${gravityDBfile}" != "${gravityDBfile_default}" ]]; then
-    echo -e "  ${INFO} Storing gravity database in ${COL_BOLD}${gravityDBfile}${COL_NC}"
-  fi
+    if [[ ${gravityDBfile} != "${gravityDBfile_default}" ]]; then
+        echo -e "  ${INFO} Storing gravity database in ${COL_BOLD}${gravityDBfile}${COL_NC}"
+    fi
 
-  # Retrieve source URLs from gravity database
-  # We source only enabled adlists, sqlite3 stores boolean values as 0 (false) or 1 (true)
-  mapfile -t sources <<< "$(sqlite3 "${gravityDBfile}" "SELECT address FROM vw_adlist;" 2> /dev/null)"
-  mapfile -t sourceIDs <<< "$(sqlite3 "${gravityDBfile}" "SELECT id FROM vw_adlist;" 2> /dev/null)"
+    # Retrieve source URLs from gravity database
+    # We source only enabled adlists, sqlite3 stores boolean values as 0 (false) or 1 (true)
+    mapfile -t sources <<< "$(sqlite3 "${gravityDBfile}" "SELECT address FROM vw_adlist;" 2> /dev/null)"
+    mapfile -t sourceIDs <<< "$(sqlite3 "${gravityDBfile}" "SELECT id FROM vw_adlist;" 2> /dev/null)"
 
-  # Parse source domains from $sources
-  mapfile -t sourceDomains <<< "$(
-    # Logic: Split by folder/port
-    awk -F '[/:]' '{
+    # Parse source domains from $sources
+    mapfile -t sourceDomains <<< "$(
+        # Logic: Split by folder/port
+        awk -F '[/:]' '{
       # Remove URL protocol & optional username:password@
       gsub(/(.*:\/\/|.*:.*@)/, "", $0)
       if(length($1)>0){print $1}
       else {print "local"}
     }' <<< "$(printf '%s\n' "${sources[@]}")" 2> /dev/null
-  )"
+    )"
 
-  local str="Pulling blocklist source list into range"
+    local str="Pulling blocklist source list into range"
 
-  if [[ -n "${sources[*]}" ]] && [[ -n "${sourceDomains[*]}" ]]; then
-    echo -e "${OVER}  ${TICK} ${str}"
-  else
-    echo -e "${OVER}  ${CROSS} ${str}"
-    echo -e "  ${INFO} No source list found, or it is empty"
+    if [[ -n ${sources[*]} ]] && [[ -n ${sourceDomains[*]} ]]; then
+        echo -e "${OVER}  ${TICK} ${str}"
+    else
+        echo -e "${OVER}  ${CROSS} ${str}"
+        echo -e "  ${INFO} No source list found, or it is empty"
+        echo ""
+        return 1
+    fi
+
+    local url domain agent cmd_ext str target compression
     echo ""
-    return 1
-  fi
-
-  local url domain agent cmd_ext str target compression
-  echo ""
-
-  # Prepare new gravity database
-  str="Preparing new gravity database"
-  echo -ne "  ${INFO} ${str}..."
-  rm "${gravityTEMPfile}" > /dev/null 2>&1
-  output=$( { sqlite3 "${gravityTEMPfile}" < "${gravityDBschema}"; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to create new database ${gravityTEMPfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  else
-    echo -e "${OVER}  ${TICK} ${str}"
-  fi
-
-  target="$(mktemp -p "/tmp" --suffix=".gravity")"
-
-  # Use compression to reduce the amount of data that is transferred
-  # between the Pi-hole and the ad list provider. Use this feature
-  # only if it is supported by the locally available version of curl
-  if curl -V | grep -q "Features:.* libz"; then
-    compression="--compressed"
-    echo -e "  ${INFO} Using libz compression\n"
-  else
-      compression=""
-      echo -e "  ${INFO} Libz compression not available\n"
-    fi
-  # Loop through $sources and download each one
-  for ((i = 0; i < "${#sources[@]}"; i++)); do
-    url="${sources[$i]}"
-    domain="${sourceDomains[$i]}"
-    id="${sourceIDs[$i]}"
-
-    # Save the file as list.#.domain
-    saveLocation="${piholeDir}/list.${id}.${domain}.${domainsExtension}"
-    activeDomains[$i]="${saveLocation}"
-
-    # Default user-agent (for Cloudflare's Browser Integrity Check: https://support.cloudflare.com/hc/en-us/articles/200170086-What-does-the-Browser-Integrity-Check-do-)
-    agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36"
-
-    # Provide special commands for blocklists which may need them
-    case "${domain}" in
-      "pgl.yoyo.org") cmd_ext="-d mimetype=plaintext -d hostformat=hosts";;
-      *) cmd_ext="";;
-    esac
 
-    echo -e "  ${INFO} Target: ${url}"
-    local regex check_url
-    # Check for characters NOT allowed in URLs
-    regex="[^a-zA-Z0-9:/?&%=~._()-;]"
+    # Prepare new gravity database
+    str="Preparing new gravity database"
+    echo -ne "  ${INFO} ${str}..."
+    rm "${gravityTEMPfile}" > /dev/null 2>&1
+    output=$({ sqlite3 "${gravityTEMPfile}" < "${gravityDBschema}"; } 2>&1)
+    status="$?"
 
-    # this will remove first @ that is after schema and before domain
-    # \1 is optional schema, \2 is userinfo
-    check_url="$( sed -re 's#([^:/]*://)?([^/]+)@#\1\2#' <<< "$url" )"
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to create new database ${gravityTEMPfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    else
+        echo -e "${OVER}  ${TICK} ${str}"
+    fi
+
+    target="$(mktemp -p "/tmp" --suffix=".gravity")"
 
-    if [[ "${check_url}" =~ ${regex} ]]; then
-        echo -e "  ${CROSS} Invalid Target"
+    # Use compression to reduce the amount of data that is transferred
+    # between the Pi-hole and the ad list provider. Use this feature
+    # only if it is supported by the locally available version of curl
+    if curl -V | grep -q "Features:.* libz"; then
+        compression="--compressed"
+        echo -e "  ${INFO} Using libz compression\n"
     else
-       gravity_DownloadBlocklistFromUrl "${url}" "${cmd_ext}" "${agent}" "${sourceIDs[$i]}" "${saveLocation}" "${target}" "${compression}"
+        compression=""
+        echo -e "  ${INFO} Libz compression not available\n"
     fi
-    echo ""
-  done
+    # Loop through $sources and download each one
+    for ((i = 0; i < "${#sources[@]}"; i++)); do
+        url="${sources[$i]}"
+        domain="${sourceDomains[$i]}"
+        id="${sourceIDs[$i]}"
+
+        # Save the file as list.#.domain
+        saveLocation="${piholeDir}/list.${id}.${domain}.${domainsExtension}"
+        activeDomains[$i]="${saveLocation}"
+
+        # Default user-agent (for Cloudflare's Browser Integrity Check: https://support.cloudflare.com/hc/en-us/articles/200170086-What-does-the-Browser-Integrity-Check-do-)
+        agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36"
+
+        # Provide special commands for blocklists which may need them
+        case "${domain}" in
+            "pgl.yoyo.org") cmd_ext="-d mimetype=plaintext -d hostformat=hosts" ;;
+            *) cmd_ext="" ;;
+        esac
+
+        echo -e "  ${INFO} Target: ${url}"
+        local regex check_url
+        # Check for characters NOT allowed in URLs
+        regex="[^a-zA-Z0-9:/?&%=~._()-;]"
+
+        # this will remove first @ that is after schema and before domain
+        # \1 is optional schema, \2 is userinfo
+        check_url="$(sed -re 's#([^:/]*://)?([^/]+)@#\1\2#' <<< "$url")"
+
+        if [[ ${check_url} =~ ${regex} ]]; then
+            echo -e "  ${CROSS} Invalid Target"
+        else
+            gravity_DownloadBlocklistFromUrl "${url}" "${cmd_ext}" "${agent}" "${sourceIDs[$i]}" "${saveLocation}" "${target}" "${compression}"
+        fi
+        echo ""
+    done
 
-  str="Storing downloaded domains in new gravity database"
-  echo -ne "  ${INFO} ${str}..."
-  output=$( { printf ".timeout 30000\\n.mode csv\\n.import \"%s\" gravity\\n" "${target}" | sqlite3 "${gravityTEMPfile}"; } 2>&1 )
-  status="$?"
+    str="Storing downloaded domains in new gravity database"
+    echo -ne "  ${INFO} ${str}..."
+    output=$({ printf '.timeout 30000\n.mode csv\n.import "%s" gravity\n' "${target}" | sqlite3 "${gravityTEMPfile}"; } 2>&1)
+    status="$?"
 
-  if [[ "${status}" -ne 0 ]]; then
-    echo -e "\\n  ${CROSS} Unable to fill gravity table in database ${gravityTEMPfile}\\n  ${output}"
-    gravity_Cleanup "error"
-  else
-    echo -e "${OVER}  ${TICK} ${str}"
-  fi
-
-  if [[ "${status}" -eq 0 && -n "${output}" ]]; then
-    echo -e "  Encountered non-critical SQL warnings. Please check the suitability of the lists you're using!\\n\\n  SQL warnings:"
-    local warning file line lineno
-    while IFS= read -r line; do
-      echo "  - ${line}"
-      warning="$(grep -oh "^[^:]*:[0-9]*" <<< "${line}")"
-      file="${warning%:*}"
-      lineno="${warning#*:}"
-      if [[ -n "${file}" && -n "${lineno}" ]]; then
-        echo -n "    Line contains: "
-        awk "NR==${lineno}" < "${file}"
-      fi
-    done <<< "${output}"
-    echo ""
-  fi
+    if [[ ${status} -ne 0 ]]; then
+        echo -e "\\n  ${CROSS} Unable to fill gravity table in database ${gravityTEMPfile}\\n  ${output}"
+        gravity_Cleanup "error"
+    else
+        echo -e "${OVER}  ${TICK} ${str}"
+    fi
+
+    if [[ ${status} -eq 0 && -n ${output} ]]; then
+        echo -e "  Encountered non-critical SQL warnings. Please check the suitability of the lists you're using!\\n\\n  SQL warnings:"
+        local warning file line lineno
+        while IFS= read -r line; do
+            echo "  - ${line}"
+            warning="$(grep -oh "^[^:]*:[0-9]*" <<< "${line}")"
+            file="${warning%:*}"
+            lineno="${warning#*:}"
+            if [[ -n ${file} && -n ${lineno} ]]; then
+                echo -n "    Line contains: "
+                awk "NR==${lineno}" < "${file}"
+            fi
+        done <<< "${output}"
+        echo ""
+    fi
 
-  rm "${target}" > /dev/null 2>&1 || \
-    echo -e "  ${CROSS} Unable to remove ${target}"
+    rm "${target}" > /dev/null 2>&1 ||
+        echo -e "  ${CROSS} Unable to remove ${target}"
 
-  gravity_Blackbody=true
+    gravity_Blackbody=true
 }
 
 total_num=0
 num_lines=0
 num_invalid=0
 parseList() {
-  local adlistID="${1}" src="${2}" target="${3}" incorrect_lines
-  # This sed does the following things:
-  # 1. Remove all domains containing invalid characters. Valid are: a-z, A-Z, 0-9, dot (.), minus (-), underscore (_)
-  # 2. Append ,adlistID to every line
-  # 3. Ensures there is a newline on the last line
-  sed -e "/[^a-zA-Z0-9.\_-]/d;s/$/,${adlistID}/;/.$/a\\" "${src}" >> "${target}"
-  # Find (up to) five domains containing invalid characters (see above)
-  incorrect_lines="$(sed -e "/[^a-zA-Z0-9.\_-]/!d" "${src}" | head -n 5)"
-
-  local num_target_lines num_correct_lines num_invalid
-  # Get number of lines in source file
-  num_lines="$(grep -c "^" "${src}")"
-  # Get number of lines in destination file
-  num_target_lines="$(grep -c "^" "${target}")"
-  num_correct_lines="$(( num_target_lines-total_num ))"
-  total_num="$num_target_lines"
-  num_invalid="$(( num_lines-num_correct_lines ))"
-  if [[ "${num_invalid}" -eq 0 ]]; then
-    echo "  ${INFO} Analyzed ${num_lines} domains"
-  else
-    echo "  ${INFO} Analyzed ${num_lines} domains, ${num_invalid} domains invalid!"
-  fi
-
-  # Display sample of invalid lines if we found some
-  if [[ -n "${incorrect_lines}" ]]; then
-    echo "      Sample of invalid domains:"
-    while IFS= read -r line; do
-      echo "      - ${line}"
-    done <<< "${incorrect_lines}"
-  fi
+    local adlistID="${1}" src="${2}" target="${3}" incorrect_lines
+    # This sed does the following things:
+    # 1. Remove all domains containing invalid characters. Valid are: a-z, A-Z, 0-9, dot (.), minus (-), underscore (_)
+    # 2. Append ,adlistID to every line
+    # 3. Ensures there is a newline on the last line
+    sed -e "/[^a-zA-Z0-9.\_-]/d;s/$/,${adlistID}/;/.$/a\\" "${src}" >> "${target}"
+    # Find (up to) five domains containing invalid characters (see above)
+    incorrect_lines="$(sed -e "/[^a-zA-Z0-9.\_-]/!d" "${src}" | head -n 5)"
+
+    local num_target_lines num_correct_lines num_invalid
+    # Get number of lines in source file
+    num_lines="$(grep -c "^" "${src}")"
+    # Get number of lines in destination file
+    num_target_lines="$(grep -c "^" "${target}")"
+    num_correct_lines="$((num_target_lines - total_num))"
+    total_num="$num_target_lines"
+    num_invalid="$((num_lines - num_correct_lines))"
+    if [[ ${num_invalid} -eq 0 ]]; then
+        echo "  ${INFO} Analyzed ${num_lines} domains"
+    else
+        echo "  ${INFO} Analyzed ${num_lines} domains, ${num_invalid} domains invalid!"
+    fi
+
+    # Display sample of invalid lines if we found some
+    if [[ -n ${incorrect_lines} ]]; then
+        echo "      Sample of invalid domains:"
+        while IFS= read -r line; do
+            echo "      - ${line}"
+        done <<< "${incorrect_lines}"
+    fi
 }
 compareLists() {
-  local adlistID="${1}" target="${2}"
-
-  # Verify checksum when an older checksum exists
-  if [[ -s "${target}.sha1" ]]; then
-    if ! sha1sum --check --status --strict "${target}.sha1"; then
-      # The list changed upstream, we need to update the checksum
-      sha1sum "${target}" > "${target}.sha1"
-      echo "  ${INFO} List has been updated"
-      database_adlist_status "${adlistID}" "1"
-      database_adlist_updated "${adlistID}"
+    local adlistID="${1}" target="${2}"
+
+    # Verify checksum when an older checksum exists
+    if [[ -s "${target}.sha1" ]]; then
+        if ! sha1sum --check --status --strict "${target}.sha1"; then
+            # The list changed upstream, we need to update the checksum
+            sha1sum "${target}" > "${target}.sha1"
+            echo "  ${INFO} List has been updated"
+            database_adlist_status "${adlistID}" "1"
+            database_adlist_updated "${adlistID}"
+        else
+            echo "  ${INFO} List stayed unchanged"
+            database_adlist_status "${adlistID}" "2"
+        fi
     else
-      echo "  ${INFO} List stayed unchanged"
-      database_adlist_status "${adlistID}" "2"
-    fi
-  else
-    # No checksum available, create one for comparing on the next run
-    sha1sum "${target}" > "${target}.sha1"
-    # We assume here it was changed upstream
-    database_adlist_status "${adlistID}" "1"
-    database_adlist_updated "${adlistID}"
-  fi
+        # No checksum available, create one for comparing on the next run
+        sha1sum "${target}" > "${target}.sha1"
+        # We assume here it was changed upstream
+        database_adlist_status "${adlistID}" "1"
+        database_adlist_updated "${adlistID}"
+    fi
 }
 
 # Download specified URL and perform checks on HTTP status and file content
 gravity_DownloadBlocklistFromUrl() {
-  local url="${1}" cmd_ext="${2}" agent="${3}" adlistID="${4}" saveLocation="${5}" target="${6}" compression="${7}"
-  local heisenbergCompensator="" patternBuffer str httpCode success=""
-
-  # Create temp file to store content on disk instead of RAM
-  patternBuffer=$(mktemp -p "/tmp" --suffix=".phgpb")
-
-  # Determine if $saveLocation has read permission
-  if [[ -r "${saveLocation}" && $url != "file"* ]]; then
-    # Have curl determine if a remote file has been modified since last retrieval
-    # Uses "Last-Modified" header, which certain web servers do not provide (e.g: raw github urls)
-    # Note: Don't do this for local files, always download them
-    heisenbergCompensator="-z ${saveLocation}"
-  fi
-
-  str="Status:"
-  echo -ne "  ${INFO} ${str} Pending..."
-  blocked=false
-  case $BLOCKINGMODE in
-    "IP-NODATA-AAAA"|"IP")
-        if [[ $(dig "${domain}" +short | grep "${IPV4_ADDRESS}" -c) -ge 1 ]]; then
-          blocked=true
-        fi;;
-    "NXDOMAIN")
-        if [[ $(dig "${domain}" | grep "NXDOMAIN" -c) -ge 1 ]]; then
-          blocked=true
-        fi;;
-    "NULL"|*)
-        if [[ $(dig "${domain}" +short | grep "0.0.0.0" -c) -ge 1 ]]; then
-          blocked=true
-        fi;;
-   esac
-
-  if [[ "${blocked}" == true ]]; then
-    printf -v ip_addr "%s" "${PIHOLE_DNS_1%#*}"
-    if [[ ${PIHOLE_DNS_1} != *"#"* ]]; then
-        port=53
-    else
-        printf -v port "%s" "${PIHOLE_DNS_1#*#}"
-    fi
-    ip=$(dig "@${ip_addr}" -p "${port}" +short "${domain}" | tail -1)
-    if [[ $(echo "${url}" | awk -F '://' '{print $1}') = "https" ]]; then
-      port=443;
-    else port=80
+    local url="${1}" cmd_ext="${2}" agent="${3}" adlistID="${4}" saveLocation="${5}" target="${6}" compression="${7}"
+    local heisenbergCompensator="" patternBuffer str httpCode success=""
+
+    # Create temp file to store content on disk instead of RAM
+    patternBuffer=$(mktemp -p "/tmp" --suffix=".phgpb")
+
+    # Determine if $saveLocation has read permission
+    if [[ -r ${saveLocation} && $url != "file"* ]]; then
+        # Have curl determine if a remote file has been modified since last retrieval
+        # Uses "Last-Modified" header, which certain web servers do not provide (e.g: raw github urls)
+        # Note: Don't do this for local files, always download them
+        heisenbergCompensator="-z ${saveLocation}"
     fi
-    bad_list=$(pihole -q -adlist "${domain}" | head -n1 | awk -F 'Match found in ' '{print $2}')
-    echo -e "${OVER}  ${CROSS} ${str} ${domain} is blocked by ${bad_list%:}. Using DNS on ${PIHOLE_DNS_1} to download ${url}";
+
+    str="Status:"
     echo -ne "  ${INFO} ${str} Pending..."
-    cmd_ext="--resolve $domain:$port:$ip $cmd_ext"
-  fi
+    blocked=false
+    case $BLOCKINGMODE in
+        "IP-NODATA-AAAA" | "IP")
+            if [[ $(dig "${domain}" +short | grep "${IPV4_ADDRESS}" -c) -ge 1 ]]; then
+                blocked=true
+            fi
+            ;;
+        "NXDOMAIN")
+            if [[ $(dig "${domain}" | grep "NXDOMAIN" -c) -ge 1 ]]; then
+                blocked=true
+            fi
+            ;;
+        "NULL" | *)
+            if [[ $(dig "${domain}" +short | grep "0.0.0.0" -c) -ge 1 ]]; then
+                blocked=true
+            fi
+            ;;
+    esac
 
-  # shellcheck disable=SC2086
-  httpCode=$(curl -s -L ${compression} ${cmd_ext} ${heisenbergCompensator} -w "%{http_code}" -A "${agent}" "${url}" -o "${patternBuffer}" 2> /dev/null)
+    if [[ ${blocked} == true ]]; then
+        printf -v ip_addr "%s" "${PIHOLE_DNS_1%#*}"
+        if [[ ${PIHOLE_DNS_1} != *"#"* ]]; then
+            port=53
+        else
+            printf -v port "%s" "${PIHOLE_DNS_1#*#}"
+        fi
+        ip=$(dig "@${ip_addr}" -p "${port}" +short "${domain}" | tail -1)
+        if [[ $(echo "${url}" | awk -F '://' '{print $1}') == "https" ]]; then
+            port=443
+        else
+            port=80
+        fi
+        bad_list=$(pihole -q -adlist "${domain}" | head -n1 | awk -F 'Match found in ' '{print $2}')
+        echo -e "${OVER}  ${CROSS} ${str} ${domain} is blocked by ${bad_list%:}. Using DNS on ${PIHOLE_DNS_1} to download ${url}"
+        echo -ne "  ${INFO} ${str} Pending..."
+        cmd_ext="--resolve $domain:$port:$ip $cmd_ext"
+    fi
 
-  case $url in
-    # Did we "download" a local file?
-    "file"*)
-        if [[ -s "${patternBuffer}" ]]; then
-          echo -e "${OVER}  ${TICK} ${str} Retrieval successful"; success=true
+    # shellcheck disable=SC2086
+    httpCode=$(curl -s -L ${compression} ${cmd_ext} ${heisenbergCompensator} -w "%{http_code}" -A "${agent}" "${url}" -o "${patternBuffer}" 2> /dev/null)
+
+    case $url in
+        # Did we "download" a local file?
+        "file"*)
+            if [[ -s ${patternBuffer} ]]; then
+                echo -e "${OVER}  ${TICK} ${str} Retrieval successful"
+                success=true
+            else
+                echo -e "${OVER}  ${CROSS} ${str} Not found / empty list"
+            fi
+            ;;
+        # Did we "download" a remote file?
+        *)
+            # Determine "Status:" output based on HTTP response
+            case "${httpCode}" in
+                "200")
+                    echo -e "${OVER}  ${TICK} ${str} Retrieval successful"
+                    success=true
+                    ;;
+                "304")
+                    echo -e "${OVER}  ${TICK} ${str} No changes detected"
+                    success=true
+                    ;;
+                "000") echo -e "${OVER}  ${CROSS} ${str} Connection Refused" ;;
+                "403") echo -e "${OVER}  ${CROSS} ${str} Forbidden" ;;
+                "404") echo -e "${OVER}  ${CROSS} ${str} Not found" ;;
+                "408") echo -e "${OVER}  ${CROSS} ${str} Time-out" ;;
+                "451") echo -e "${OVER}  ${CROSS} ${str} Unavailable For Legal Reasons" ;;
+                "500") echo -e "${OVER}  ${CROSS} ${str} Internal Server Error" ;;
+                "504") echo -e "${OVER}  ${CROSS} ${str} Connection Timed Out (Gateway)" ;;
+                "521") echo -e "${OVER}  ${CROSS} ${str} Web Server Is Down (Cloudflare)" ;;
+                "522") echo -e "${OVER}  ${CROSS} ${str} Connection Timed Out (Cloudflare)" ;;
+                *) echo -e "${OVER}  ${CROSS} ${str} ${url} (${httpCode})" ;;
+            esac
+            ;;
+    esac
+
+    local done="false"
+    # Determine if the blocklist was downloaded and saved correctly
+    if [[ ${success} == true ]]; then
+        if [[ ${httpCode} == "304" ]]; then
+            # Add domains to database table file
+            parseList "${adlistID}" "${saveLocation}" "${target}"
+            database_adlist_status "${adlistID}" "2"
+            database_adlist_number "${adlistID}"
+            done="true"
+        # Check if $patternbuffer is a non-zero length file
+        elif [[ -s ${patternBuffer} ]]; then
+            # Determine if blocklist is non-standard and parse as appropriate
+            gravity_ParseFileIntoDomains "${patternBuffer}" "${saveLocation}"
+            # Add domains to database table file
+            parseList "${adlistID}" "${saveLocation}" "${target}"
+            # Compare lists, are they identical?
+            compareLists "${adlistID}" "${saveLocation}"
+            # Update gravity database table (status and updated timestamp are set in
+            # compareLists)
+            database_adlist_number "${adlistID}"
+            done="true"
         else
-          echo -e "${OVER}  ${CROSS} ${str} Not found / empty list"
-        fi;;
-    # Did we "download" a remote file?
-    *)
-      # Determine "Status:" output based on HTTP response
-      case "${httpCode}" in
-        "200") echo -e "${OVER}  ${TICK} ${str} Retrieval successful"; success=true;;
-        "304") echo -e "${OVER}  ${TICK} ${str} No changes detected"; success=true;;
-        "000") echo -e "${OVER}  ${CROSS} ${str} Connection Refused";;
-        "403") echo -e "${OVER}  ${CROSS} ${str} Forbidden";;
-        "404") echo -e "${OVER}  ${CROSS} ${str} Not found";;
-        "408") echo -e "${OVER}  ${CROSS} ${str} Time-out";;
-        "451") echo -e "${OVER}  ${CROSS} ${str} Unavailable For Legal Reasons";;
-        "500") echo -e "${OVER}  ${CROSS} ${str} Internal Server Error";;
-        "504") echo -e "${OVER}  ${CROSS} ${str} Connection Timed Out (Gateway)";;
-        "521") echo -e "${OVER}  ${CROSS} ${str} Web Server Is Down (Cloudflare)";;
-        "522") echo -e "${OVER}  ${CROSS} ${str} Connection Timed Out (Cloudflare)";;
-        *    ) echo -e "${OVER}  ${CROSS} ${str} ${url} (${httpCode})";;
-      esac;;
-  esac
-
-  local done="false"
-  # Determine if the blocklist was downloaded and saved correctly
-  if [[ "${success}" == true ]]; then
-    if [[ "${httpCode}" == "304" ]]; then
-      # Add domains to database table file
-      parseList "${adlistID}" "${saveLocation}" "${target}"
-      database_adlist_status "${adlistID}" "2"
-      database_adlist_number "${adlistID}"
-      done="true"
-    # Check if $patternbuffer is a non-zero length file
-    elif [[ -s "${patternBuffer}" ]]; then
-      # Determine if blocklist is non-standard and parse as appropriate
-      gravity_ParseFileIntoDomains "${patternBuffer}" "${saveLocation}"
-      # Add domains to database table file
-      parseList "${adlistID}" "${saveLocation}" "${target}"
-      # Compare lists, are they identical?
-      compareLists "${adlistID}" "${saveLocation}"
-      # Update gravity database table (status and updated timestamp are set in
-      # compareLists)
-      database_adlist_number "${adlistID}"
-      done="true"
-    else
-      # Fall back to previously cached list if $patternBuffer is empty
-      echo -e "  ${INFO} Received empty file"
-    fi
-  fi
-
-  # Do we need to fall back to a cached list (if available)?
-  if [[ "${done}" != "true" ]]; then
-    # Determine if cached list has read permission
-    if [[ -r "${saveLocation}" ]]; then
-      echo -e "  ${CROSS} List download failed: ${COL_LIGHT_GREEN}using previously cached list${COL_NC}"
-      # Add domains to database table file
-      parseList "${adlistID}" "${saveLocation}" "${target}"
-      database_adlist_number "${adlistID}"
-      database_adlist_status "${adlistID}" "3"
-    else
-      echo -e "  ${CROSS} List download failed: ${COL_LIGHT_RED}no cached list available${COL_NC}"
-      # Manually reset these two numbers because we do not call parseList here
-      num_lines=0
-      num_invalid=0
-      database_adlist_number "${adlistID}"
-      database_adlist_status "${adlistID}" "4"
-    fi
-  fi
+            # Fall back to previously cached list if $patternBuffer is empty
+            echo -e "  ${INFO} Received empty file"
+        fi
+    fi
+
+    # Do we need to fall back to a cached list (if available)?
+    if [[ ${done} != "true" ]]; then
+        # Determine if cached list has read permission
+        if [[ -r ${saveLocation} ]]; then
+            echo -e "  ${CROSS} List download failed: ${COL_LIGHT_GREEN}using previously cached list${COL_NC}"
+            # Add domains to database table file
+            parseList "${adlistID}" "${saveLocation}" "${target}"
+            database_adlist_number "${adlistID}"
+            database_adlist_status "${adlistID}" "3"
+        else
+            echo -e "  ${CROSS} List download failed: ${COL_LIGHT_RED}no cached list available${COL_NC}"
+            # Manually reset these two numbers because we do not call parseList here
+            num_lines=0
+            num_invalid=0
+            database_adlist_number "${adlistID}"
+            database_adlist_status "${adlistID}" "4"
+        fi
+    fi
 }
 
 # Parse source files into domains format
 gravity_ParseFileIntoDomains() {
-  local source="${1}" destination="${2}" firstLine
+    local source="${1}" destination="${2}" firstLine
 
-  # Determine if we are parsing a consolidated list
-  #if [[ "${source}" == "${piholeDir}/${matterAndLight}" ]]; then
+    # Determine if we are parsing a consolidated list
+    #if [[ "${source}" == "${piholeDir}/${matterAndLight}" ]]; then
     # Remove comments and print only the domain name
     # Most of the lists downloaded are already in hosts file format but the spacing/formatting is not contiguous
     # This helps with that and makes it easier to read
@@ -706,33 +718,33 @@ gravity_ParseFileIntoDomains() {
     # 4) Remove lines containing "/"
     # 5) Remove leading tabs, spaces, etc.
     # 6) Delete lines not matching domain names
-    < "${source}" tr -d '\r' | \
-    tr '[:upper:]' '[:lower:]' | \
-    sed 's/\s*#.*//g' | \
-    sed -r '/(\/).*$/d' | \
-    sed -r 's/^.*\s+//g' | \
-    sed -r '/([^\.]+\.)+[^\.]{2,}/!d' >  "${destination}"
+    tr < "${source}" -d '\r' |
+        tr '[:upper:]' '[:lower:]' |
+        sed 's/\s*#.*//g' |
+        sed -r '/(\/).*$/d' |
+        sed -r 's/^.*\s+//g' |
+        sed -r '/([^\.]+\.)+[^\.]{2,}/!d' > "${destination}"
     chmod 644 "${destination}"
     return 0
-  #fi
-
-  # Individual file parsing: Keep comments, while parsing domains from each line
-  # We keep comments to respect the list maintainer's licensing
-  read -r firstLine < "${source}"
-
-  # Determine how to parse individual source file formats
-  if [[ "${firstLine,,}" =~ (adblock|ublock|^!) ]]; then
-    # Compare $firstLine against lower case words found in Adblock lists
-    echo -e "  ${CROSS} Format: Adblock (list type not supported)"
-  elif grep -q "^address=/" "${source}" &> /dev/null; then
-    # Parse Dnsmasq format lists
-    echo -e "  ${CROSS} Format: Dnsmasq (list type not supported)"
-  elif grep -q -E "^https?://" "${source}" &> /dev/null; then
-    # Parse URL list if source file contains "http://" or "https://"
-    # Scanning for "^IPv4$" is too slow with large (1M) lists on low-end hardware
-    echo -ne "  ${INFO} Format: URL"
-
-    awk '
+    #fi
+
+    # Individual file parsing: Keep comments, while parsing domains from each line
+    # We keep comments to respect the list maintainer's licensing
+    read -r firstLine < "${source}"
+
+    # Determine how to parse individual source file formats
+    if [[ ${firstLine,,} =~ (adblock|ublock|^!) ]]; then
+        # Compare $firstLine against lower case words found in Adblock lists
+        echo -e "  ${CROSS} Format: Adblock (list type not supported)"
+    elif grep -q "^address=/" "${source}" &> /dev/null; then
+        # Parse Dnsmasq format lists
+        echo -e "  ${CROSS} Format: Dnsmasq (list type not supported)"
+    elif grep -q -E "^https?://" "${source}" &> /dev/null; then
+        # Parse URL list if source file contains "http://" or "https://"
+        # Scanning for "^IPv4$" is too slow with large (1M) lists on low-end hardware
+        echo -ne "  ${INFO} Format: URL"
+
+        awk '
       # Remove URL scheme, optional "username:password@", and ":?/;"
       # The scheme must be matched carefully to avoid blocking the wrong URL
       # in cases like:
@@ -744,50 +756,50 @@ gravity_ParseFileIntoDomains() {
       # Print if nonempty
       length { print }
     ' "${source}" 2> /dev/null > "${destination}"
-    chmod 644 "${destination}"
+        chmod 644 "${destination}"
 
-    echo -e "${OVER}  ${TICK} Format: URL"
-  else
-    # Default: Keep hosts/domains file in same format as it was downloaded
-    output=$( { mv "${source}" "${destination}"; } 2>&1 )
-    chmod 644 "${destination}"
+        echo -e "${OVER}  ${TICK} Format: URL"
+    else
+        # Default: Keep hosts/domains file in same format as it was downloaded
+        output=$({ mv "${source}" "${destination}"; } 2>&1)
+        chmod 644 "${destination}"
 
-    if [[ ! -e "${destination}" ]]; then
-      echo -e "\\n  ${CROSS} Unable to move tmp file to ${piholeDir}
+        if [[ ! -e ${destination} ]]; then
+            echo -e "\\n  ${CROSS} Unable to move tmp file to ${piholeDir}
     ${output}"
-      gravity_Cleanup "error"
+            gravity_Cleanup "error"
+        fi
     fi
-  fi
 }
 
 # Report number of entries in a table
 gravity_Table_Count() {
-  local table="${1}"
-  local str="${2}"
-  local num
-  num="$(sqlite3 "${gravityDBfile}" "SELECT COUNT(*) FROM ${table};")"
-  if [[ "${table}" == "vw_gravity" ]]; then
-    local unique
-    unique="$(sqlite3 "${gravityDBfile}" "SELECT COUNT(DISTINCT domain) FROM ${table};")"
-    echo -e "  ${INFO} Number of ${str}: ${num} (${COL_BOLD}${unique} unique domains${COL_NC})"
-    sqlite3 "${gravityDBfile}" "INSERT OR REPLACE INTO info (property,value) VALUES ('gravity_count',${unique});"
-  else
-    echo -e "  ${INFO} Number of ${str}: ${num}"
-  fi
+    local table="${1}"
+    local str="${2}"
+    local num
+    num="$(sqlite3 "${gravityDBfile}" "SELECT COUNT(*) FROM ${table};")"
+    if [[ ${table} == "vw_gravity" ]]; then
+        local unique
+        unique="$(sqlite3 "${gravityDBfile}" "SELECT COUNT(DISTINCT domain) FROM ${table};")"
+        echo -e "  ${INFO} Number of ${str}: ${num} (${COL_BOLD}${unique} unique domains${COL_NC})"
+        sqlite3 "${gravityDBfile}" "INSERT OR REPLACE INTO info (property,value) VALUES ('gravity_count',${unique});"
+    else
+        echo -e "  ${INFO} Number of ${str}: ${num}"
+    fi
 }
 
 # Output count of blacklisted domains and regex filters
 gravity_ShowCount() {
-  gravity_Table_Count "vw_gravity" "gravity domains" ""
-  gravity_Table_Count "vw_blacklist" "exact blacklisted domains"
-  gravity_Table_Count "vw_regex_blacklist" "regex blacklist filters"
-  gravity_Table_Count "vw_whitelist" "exact whitelisted domains"
-  gravity_Table_Count "vw_regex_whitelist" "regex whitelist filters"
+    gravity_Table_Count "vw_gravity" "gravity domains" ""
+    gravity_Table_Count "vw_blacklist" "exact blacklisted domains"
+    gravity_Table_Count "vw_regex_blacklist" "regex blacklist filters"
+    gravity_Table_Count "vw_whitelist" "exact whitelisted domains"
+    gravity_Table_Count "vw_regex_whitelist" "regex whitelist filters"
 }
 
 # Parse list of domains into hosts format
 gravity_ParseDomainsIntoHosts() {
-  awk -v ipv4="$IPV4_ADDRESS" -v ipv6="$IPV6_ADDRESS" '{
+    awk -v ipv4="$IPV4_ADDRESS" -v ipv6="$IPV6_ADDRESS" '{
     # Remove windows CR line endings
     sub(/\r$/, "")
     # Parse each line as "ipaddr domain"
@@ -803,115 +815,115 @@ gravity_ParseDomainsIntoHosts() {
 
 # Create "localhost" entries into hosts format
 gravity_generateLocalList() {
-  local hostname
-
-  if [[ -s "/etc/hostname" ]]; then
-    hostname=$(< "/etc/hostname")
-  elif command -v hostname &> /dev/null; then
-    hostname=$(hostname -f)
-  else
-    echo -e "  ${CROSS} Unable to determine fully qualified domain name of host"
-    return 0
-  fi
+    local hostname
 
-  echo -e "${hostname}\\npi.hole" > "${localList}.tmp"
+    if [[ -s "/etc/hostname" ]]; then
+        hostname=$(< "/etc/hostname")
+    elif command -v hostname &> /dev/null; then
+        hostname=$(hostname -f)
+    else
+        echo -e "  ${CROSS} Unable to determine fully qualified domain name of host"
+        return 0
+    fi
 
-  # Empty $localList if it already exists, otherwise, create it
-  : > "${localList}"
-  chmod 644 "${localList}"
+    echo -e "${hostname}\\npi.hole" > "${localList}.tmp"
 
-  gravity_ParseDomainsIntoHosts "${localList}.tmp" "${localList}"
+    # Empty $localList if it already exists, otherwise, create it
+    : > "${localList}"
+    chmod 644 "${localList}"
 
-  # Add additional LAN hosts provided by OpenVPN (if available)
-  if [[ -f "${VPNList}" ]]; then
-    awk -F, '{printf $2"\t"$1".vpn\n"}' "${VPNList}" >> "${localList}"
-  fi
+    gravity_ParseDomainsIntoHosts "${localList}.tmp" "${localList}"
+
+    # Add additional LAN hosts provided by OpenVPN (if available)
+    if [[ -f ${VPNList} ]]; then
+        awk -F, '{printf $2"\t"$1".vpn\n"}' "${VPNList}" >> "${localList}"
+    fi
 }
 
 # Trap Ctrl-C
 gravity_Trap() {
-  trap '{ echo -e "\\n\\n  ${INFO} ${COL_LIGHT_RED}User-abort detected${COL_NC}"; gravity_Cleanup "error"; }' INT
+    trap '{ echo -e "\\n\\n  ${INFO} ${COL_LIGHT_RED}User-abort detected${COL_NC}"; gravity_Cleanup "error"; }' INT
 }
 
 # Clean up after Gravity upon exit or cancellation
 gravity_Cleanup() {
-  local error="${1:-}"
-
-  str="Cleaning up stray matter"
-  echo -ne "  ${INFO} ${str}..."
-
-  # Delete tmp content generated by Gravity
-  rm ${piholeDir}/pihole.*.txt 2> /dev/null
-  rm ${piholeDir}/*.tmp 2> /dev/null
-  rm /tmp/*.phgpb 2> /dev/null
-
-  # Ensure this function only runs when gravity_SetDownloadOptions() has completed
-  if [[ "${gravity_Blackbody:-}" == true ]]; then
-    # Remove any unused .domains files
-    for file in "${piholeDir}"/*."${domainsExtension}"; do
-      # If list is not in active array, then remove it
-      if [[ ! "${activeDomains[*]}" == *"${file}"* ]]; then
-        rm -f "${file}" 2> /dev/null || \
-          echo -e "  ${CROSS} Failed to remove ${file##*/}"
-      fi
-    done
-  fi
+    local error="${1:-}"
+
+    str="Cleaning up stray matter"
+    echo -ne "  ${INFO} ${str}..."
+
+    # Delete tmp content generated by Gravity
+    rm ${piholeDir}/pihole.*.txt 2> /dev/null
+    rm ${piholeDir}/*.tmp 2> /dev/null
+    rm /tmp/*.phgpb 2> /dev/null
+
+    # Ensure this function only runs when gravity_SetDownloadOptions() has completed
+    if [[ ${gravity_Blackbody:-} == true ]]; then
+        # Remove any unused .domains files
+        for file in "${piholeDir}"/*."${domainsExtension}"; do
+            # If list is not in active array, then remove it
+            if [[ ${activeDomains[*]} != *"${file}"* ]]; then
+                rm -f "${file}" 2> /dev/null ||
+                    echo -e "  ${CROSS} Failed to remove ${file##*/}"
+            fi
+        done
+    fi
 
-  echo -e "${OVER}  ${TICK} ${str}"
+    echo -e "${OVER}  ${TICK} ${str}"
 
-  # Only restart DNS service if offline
-  if ! pgrep pihole-FTL &> /dev/null; then
-    "${PIHOLE_COMMAND}" restartdns
-    dnsWasOffline=true
-  fi
+    # Only restart DNS service if offline
+    if ! pgrep pihole-FTL &> /dev/null; then
+        "${PIHOLE_COMMAND}" restartdns
+        dnsWasOffline=true
+    fi
 
-  # Print Pi-hole status if an error occurred
-  if [[ -n "${error}" ]]; then
-    "${PIHOLE_COMMAND}" status
-    exit 1
-  fi
+    # Print Pi-hole status if an error occurred
+    if [[ -n ${error} ]]; then
+        "${PIHOLE_COMMAND}" status
+        exit 1
+    fi
 }
 
 helpFunc() {
-  echo "Usage: pihole -g
+    echo "Usage: pihole -g
 Update domains from blocklists specified in adlists.list
 
 Options:
   -f, --force          Force the download of all specified blocklists
   -h, --help           Show this help dialog"
-  exit 0
+    exit 0
 }
 
 for var in "$@"; do
-  case "${var}" in
-    "-f" | "--force" ) forceDelete=true;;
-    "-r" | "--recreate" ) recreate_database=true;;
-    "-h" | "--help" ) helpFunc;;
-  esac
+    case "${var}" in
+        "-f" | "--force") forceDelete=true ;;
+        "-r" | "--recreate") recreate_database=true ;;
+        "-h" | "--help") helpFunc ;;
+    esac
 done
 
 # Trap Ctrl-C
 gravity_Trap
 
-if [[ "${recreate_database:-}" == true ]]; then
-  str="Restoring from migration backup"
-  echo -ne "${INFO} ${str}..."
-  rm "${gravityDBfile}"
-  pushd "${piholeDir}" > /dev/null || exit
-  cp migration_backup/* .
-  popd > /dev/null || exit
-  echo -e "${OVER}  ${TICK} ${str}"
+if [[ ${recreate_database:-} == true ]]; then
+    str="Restoring from migration backup"
+    echo -ne "${INFO} ${str}..."
+    rm "${gravityDBfile}"
+    pushd "${piholeDir}" > /dev/null || exit
+    cp migration_backup/* .
+    popd > /dev/null || exit
+    echo -e "${OVER}  ${TICK} ${str}"
 fi
 
 # Move possibly existing legacy files to the gravity database
 migrate_to_database
 
-if [[ "${forceDelete:-}" == true ]]; then
-  str="Deleting existing list cache"
-  echo -ne "${INFO} ${str}..."
+if [[ ${forceDelete:-} == true ]]; then
+    str="Deleting existing list cache"
+    echo -ne "${INFO} ${str}..."
 
-  rm /etc/pihole/list.* 2> /dev/null || true
-  echo -e "${OVER}  ${TICK} ${str}"
+    rm /etc/pihole/list.* 2> /dev/null || true
+    echo -e "${OVER}  ${TICK} ${str}"
 fi
 
 # Gravity downloads blocklists next
@@ -935,8 +947,8 @@ chmod g+w "${piholeDir}" "${gravityDBfile}"
 gravity_ShowCount
 
 # Determine if DNS has been restarted by this instance of gravity
-if [[ -z "${dnsWasOffline:-}" ]]; then
-  "${PIHOLE_COMMAND}" restartdns reload
+if [[ -z ${dnsWasOffline:-} ]]; then
+    "${PIHOLE_COMMAND}" restartdns reload
 fi
 
 gravity_Cleanup
diff --git a/pihole b/pihole
index f8085c8e..c328ae98 100755
--- a/pihole
+++ b/pihole
@@ -9,248 +9,231 @@
 # This file is copyright under the latest version of the EUPL.
 # Please see LICENSE file for your rights under this license.
 
-readonly PI_HOLE_SCRIPT_DIR="/opt/pihole"
+readonly PI_HOLE_SCRIPT_DIR="@EPREFIX@/usr/@LIBDIR@/pihole"
 
 # setupVars and PI_HOLE_BIN_DIR are not readonly here because in some functions (checkout),
 # they might get set again when the installer is sourced. This causes an
 # error due to modifying a readonly variable.
-setupVars="/etc/pihole/setupVars.conf"
-PI_HOLE_BIN_DIR="/usr/local/bin"
-readonly FTL_PID_FILE="/run/pihole-FTL.pid"
+setupVars="@EPREFIX@/etc/pihole/setupVars.conf"
+PI_HOLE_BIN_DIR="@EPREFIX@/usr/bin"
+readonly FTL_PID_FILE="@EPREFIX@/run/pihole/FTL.pid"
 
-readonly colfile="${PI_HOLE_SCRIPT_DIR}/COL_TABLE"
+readonly colfile="@EPREFIX@/usr@LIBDIR@/pihole/COL_TABLE"
 source "${colfile}"
 
 webpageFunc() {
-  source "${PI_HOLE_SCRIPT_DIR}/webpage.sh"
-  main "$@"
-  exit 0
+    source "${PI_HOLE_SCRIPT_DIR}/webpage.sh"
+    main "$@"
+    exit 0
 }
 
 listFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/list.sh "$@"
-  exit 0
+    "${PI_HOLE_SCRIPT_DIR}"/list.sh "$@"
+    exit 0
 }
 
 debugFunc() {
-  local automated
-  local web
-
-  # Pull off the `debug` leaving passed call augmentation flags in $1
-  shift
-  if [[ "$@" == *"-a"* ]]; then
-    automated="true"
-  fi
-  if [[ "$@" == *"-w"* ]]; then
-    web="true"
-  fi
-
-  AUTOMATED=${automated:-} WEBCALL=${web:-} "${PI_HOLE_SCRIPT_DIR}"/piholeDebug.sh
-  exit 0
-}
+    local automated
+    local web
 
-flushFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/piholeLogFlush.sh "$@"
-  exit 0
-}
+    # Pull off the `debug` leaving passed call augmentation flags in $1
+    shift
+    if [[ $@ == *"-a"* ]]; then
+        automated="true"
+    fi
+    if [[ $@ == *"-w"* ]]; then
+        web="true"
+    fi
 
-arpFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/piholeARPTable.sh "$@"
-  exit 0
+    AUTOMATED=${automated:-} WEBCALL=${web:-} "${PI_HOLE_SCRIPT_DIR}"/piholeDebug.sh
+    exit 0
 }
 
-updatePiholeFunc() {
-  shift
-  "${PI_HOLE_SCRIPT_DIR}"/update.sh "$@"
-  exit 0
+flushFunc() {
+    "${PI_HOLE_SCRIPT_DIR}"/piholeLogFlush.sh "$@"
+    exit 0
 }
 
-reconfigurePiholeFunc() {
-  /etc/.pihole/automated\ install/basic-install.sh --reconfigure
-  exit 0;
+arpFunc() {
+    "${PI_HOLE_SCRIPT_DIR}"/piholeARPTable.sh "$@"
+    exit 0
 }
 
 updateGravityFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/gravity.sh "$@"
-  exit $?
+    "${PI_HOLE_SCRIPT_DIR}"/gravity.sh "$@"
+    exit $?
 }
 
 queryFunc() {
-  shift
-  "${PI_HOLE_SCRIPT_DIR}"/query.sh "$@"
-  exit 0
+    shift
+    "${PI_HOLE_SCRIPT_DIR}"/query.sh "$@"
+    exit 0
 }
 
 chronometerFunc() {
-  shift
-  "${PI_HOLE_SCRIPT_DIR}"/chronometer.sh "$@"
-  exit 0
-}
-
-
-uninstallFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/uninstall.sh
-  exit 0
+    shift
+    "${PI_HOLE_SCRIPT_DIR}"/chronometer.sh "$@"
+    exit 0
 }
 
 versionFunc() {
-  shift
-  "${PI_HOLE_SCRIPT_DIR}"/version.sh "$@"
-  exit 0
+    shift
+    "${PI_HOLE_SCRIPT_DIR}"/version.sh "$@"
+    exit 0
 }
 
 # Get PID of main pihole-FTL process
 getFTLPID() {
-  local pid
-
-  if [ -s "${FTL_PID_FILE}" ]; then
-    # -s: FILE exists and has a size greater than zero
-    pid="$(<"$FTL_PID_FILE")"
-    # Exploit prevention: unset the variable if there is malicious content
-    # Verify that the value read from the file is numeric
-    [[ "$pid" =~ [^[:digit:]] ]] && unset pid
-  fi
-
-  # If FTL is not running, or the PID file contains malicious stuff, substitute
-  # negative PID to signal this to the caller
-  echo "${pid:=-1}"
+    local pid
+
+    if [ -s "${FTL_PID_FILE}" ]; then
+        # -s: FILE exists and has a size greater than zero
+        pid="$(< "$FTL_PID_FILE")"
+        # Exploit prevention: unset the variable if there is malicious content
+        # Verify that the value read from the file is numeric
+        [[ $pid =~ [^[:digit:]] ]] && unset pid
+    fi
+
+    # If FTL is not running, or the PID file contains malicious stuff, substitute
+    # negative PID to signal this to the caller
+    echo "${pid:=-1}"
 }
 
 restartDNS() {
-  local svcOption svc str output status pid icon
-  svcOption="${1:-restart}"
-
-  # Determine if we should reload or restart
-  if [[ "${svcOption}" =~ "reload-lists" ]]; then
-    # Reloading of the lists has been requested
-    # Note 1: This will NOT re-read any *.conf files
-    # Note 2: We cannot use killall here as it does
-    #         not know about real-time signals
-    pid="$(getFTLPID)"
-    if [[ "$pid" -eq "-1" ]]; then
-      svc="true"
-      str="FTL is not running"
-      icon="${INFO}"
+    local svcOption svc str output status pid icon
+    svcOption="${1:-restart}"
+
+    # Determine if we should reload or restart
+    if [[ ${svcOption} =~ "reload-lists" ]]; then
+        # Reloading of the lists has been requested
+        # Note 1: This will NOT re-read any *.conf files
+        # Note 2: We cannot use killall here as it does
+        #         not know about real-time signals
+        pid="$(getFTLPID)"
+        if [[ $pid -eq "-1" ]]; then
+            svc="true"
+            str="FTL is not running"
+            icon="${INFO}"
+        else
+            svc="kill -RTMIN ${pid}"
+            str="Reloading DNS lists"
+            icon="${TICK}"
+        fi
+    elif [[ ${svcOption} =~ "reload" ]]; then
+        # Reloading of the DNS cache has been requested
+        # Note: This will NOT re-read any *.conf files
+        pid="$(getFTLPID)"
+        if [[ $pid -eq "-1" ]]; then
+            svc="true"
+            str="FTL is not running"
+            icon="${INFO}"
+        else
+            svc="kill -HUP ${pid}"
+            str="Flushing DNS cache"
+            icon="${TICK}"
+        fi
     else
-      svc="kill -RTMIN ${pid}"
-      str="Reloading DNS lists"
-      icon="${TICK}"
+        # A full restart has been requested
+        svc="service pihole-FTL restart"
+        str="Restarting DNS server"
+        icon="${TICK}"
     fi
-  elif [[ "${svcOption}" =~ "reload" ]]; then
-    # Reloading of the DNS cache has been requested
-    # Note: This will NOT re-read any *.conf files
-    pid="$(getFTLPID)"
-    if [[ "$pid" -eq "-1" ]]; then
-      svc="true"
-      str="FTL is not running"
-      icon="${INFO}"
+
+    # Print output to Terminal, but not to Web Admin
+    [[ -t 1 ]] && echo -ne "  ${INFO} ${str}..."
+
+    output=$({ ${svc}; } 2>&1)
+    status="$?"
+
+    if [[ ${status} -eq 0 ]]; then
+        [[ -t 1 ]] && echo -e "${OVER}  ${icon} ${str}"
+        return 0
     else
-      svc="kill -HUP ${pid}"
-      str="Flushing DNS cache"
-      icon="${TICK}"
+        [[ ! -t 1 ]] && local OVER=""
+        echo -e "${OVER}  ${CROSS} ${output}"
+        return 1
     fi
-  else
-    # A full restart has been requested
-    svc="service pihole-FTL restart"
-    str="Restarting DNS server"
-    icon="${TICK}"
-  fi
-
-  # Print output to Terminal, but not to Web Admin
-  [[ -t 1 ]] && echo -ne "  ${INFO} ${str}..."
-
-  output=$( { ${svc}; } 2>&1 )
-  status="$?"
-
-  if [[ "${status}" -eq 0 ]]; then
-    [[ -t 1 ]] && echo -e "${OVER}  ${icon} ${str}"
-    return 0
-  else
-    [[ ! -t 1 ]] && local OVER=""
-    echo -e "${OVER}  ${CROSS} ${output}"
-    return 1
-  fi
 }
 
 piholeEnable() {
-  if [[ "${2}" == "-h" ]] || [[ "${2}" == "--help" ]]; then
-    echo "Usage: pihole disable [time]
+    if [[ ${2} == "-h" ]] || [[ ${2} == "--help" ]]; then
+        echo "Usage: pihole disable [time]
 Example: 'pihole disable', or 'pihole disable 5m'
 Disable Pi-hole subsystems
 
 Time:
   #s                  Disable Pi-hole functionality for # second(s)
   #m                  Disable Pi-hole functionality for # minute(s)"
-    exit 0
+        exit 0
 
-  elif [[ "${1}" == "0" ]]; then
-    # Disable Pi-hole
-    if grep -cq "BLOCKING_ENABLED=false" "${setupVars}"; then
-      echo -e "  ${INFO} Blocking already disabled, nothing to do"
-      exit 0
-    fi
-    if [[ $# > 1 ]]; then
-      local error=false
-      if [[ "${2}" == *"s" ]]; then
-        tt=${2%"s"}
-        if [[ "${tt}" =~ ^-?[0-9]+$ ]];then
-          local str="Disabling blocking for ${tt} seconds"
-          echo -e "  ${INFO} ${str}..."
-          local str="Blocking will be re-enabled in ${tt} seconds"
-          nohup "${PI_HOLE_SCRIPT_DIR}"/pihole-reenable.sh ${tt} </dev/null &>/dev/null &
-        else
-          local error=true
+    elif [[ ${1} == "0" ]]; then
+        # Disable Pi-hole
+        if grep -cq "BLOCKING_ENABLED=false" "${setupVars}"; then
+            echo -e "  ${INFO} Blocking already disabled, nothing to do"
+            exit 0
         fi
-      elif [[ "${2}" == *"m" ]]; then
-        tt=${2%"m"}
-          if [[ "${tt}" =~ ^-?[0-9]+$ ]];then
-          local str="Disabling blocking for ${tt} minutes"
-          echo -e "  ${INFO} ${str}..."
-          local str="Blocking will be re-enabled in ${tt} minutes"
-          tt=$((${tt}*60))
-          nohup "${PI_HOLE_SCRIPT_DIR}"/pihole-reenable.sh ${tt} </dev/null &>/dev/null &
-        else
-          local error=true
+        if [[ $# > 1 ]]; then
+            local error=false
+            if [[ ${2} == *"s" ]]; then
+                tt=${2%"s"}
+                if [[ ${tt} =~ ^-?[0-9]+$ ]]; then
+                    local str="Disabling blocking for ${tt} seconds"
+                    echo -e "  ${INFO} ${str}..."
+                    local str="Blocking will be re-enabled in ${tt} seconds"
+                    nohup "${PI_HOLE_SCRIPT_DIR}"/pihole-reenable.sh ${tt} < /dev/null &> /dev/null &
+                else
+                    local error=true
+                fi
+            elif [[ ${2} == *"m" ]]; then
+                tt=${2%"m"}
+                if [[ ${tt} =~ ^-?[0-9]+$ ]]; then
+                    local str="Disabling blocking for ${tt} minutes"
+                    echo -e "  ${INFO} ${str}..."
+                    local str="Blocking will be re-enabled in ${tt} minutes"
+                    tt=$((tt * 60))
+                    nohup "${PI_HOLE_SCRIPT_DIR}"/pihole-reenable.sh ${tt} < /dev/null &> /dev/null &
+                else
+                    local error=true
+                fi
+            elif [[ -n ${2} ]]; then
+                local error=true
+            else
+                echo -e "  ${INFO} Disabling blocking"
+            fi
+
+            if [[ ${error} == true ]]; then
+                echo -e "  ${COL_LIGHT_RED}Unknown format for delayed reactivation of the blocking!${COL_NC}"
+                echo -e "  Try 'pihole disable --help' for more information."
+                exit 1
+            fi
+
+            local str="Pi-hole Disabled"
+            sed -i "/BLOCKING_ENABLED=/d" "${setupVars}"
+            echo "BLOCKING_ENABLED=false" >> "${setupVars}"
         fi
-      elif [[ -n "${2}" ]]; then
-        local error=true
-      else
-        echo -e "  ${INFO} Disabling blocking"
-      fi
-
-      if [[ ${error} == true ]];then
-        echo -e "  ${COL_LIGHT_RED}Unknown format for delayed reactivation of the blocking!${COL_NC}"
-        echo -e "  Try 'pihole disable --help' for more information."
-        exit 1
-      fi
+    else
+        # Enable Pi-hole
+        killall -q pihole-reenable
+        if grep -cq "BLOCKING_ENABLED=true" "${setupVars}"; then
+            echo -e "  ${INFO} Blocking already enabled, nothing to do"
+            exit 0
+        fi
+        echo -e "  ${INFO} Enabling blocking"
+        local str="Pi-hole Enabled"
 
-      local str="Pi-hole Disabled"
-      sed -i "/BLOCKING_ENABLED=/d" "${setupVars}"
-      echo "BLOCKING_ENABLED=false" >> "${setupVars}"
+        sed -i "/BLOCKING_ENABLED=/d" "${setupVars}"
+        echo "BLOCKING_ENABLED=true" >> "${setupVars}"
     fi
-  else
-    # Enable Pi-hole
-    killall -q pihole-reenable
-    if grep -cq "BLOCKING_ENABLED=true" "${setupVars}"; then
-      echo -e "  ${INFO} Blocking already enabled, nothing to do"
-      exit 0
-    fi
-    echo -e "  ${INFO} Enabling blocking"
-    local str="Pi-hole Enabled"
-
-    sed -i "/BLOCKING_ENABLED=/d" "${setupVars}"
-    echo "BLOCKING_ENABLED=true" >> "${setupVars}"
-  fi
 
-  restartDNS reload
+    restartDNS reload
 
-  echo -e "${OVER}  ${TICK} ${str}"
+    echo -e "${OVER}  ${TICK} ${str}"
 }
 
 piholeLogging() {
-  shift
-  if [[ "${1}" == "-h" ]] || [[ "${1}" == "--help" ]]; then
-    echo "Usage: pihole logging [options]
+    shift
+    if [[ ${1} == "-h" ]] || [[ ${1} == "--help" ]]; then
+        echo "Usage: pihole logging [options]
 Example: 'pihole logging on'
 Specify whether the Pi-hole log should be used
 
@@ -258,187 +241,159 @@ Options:
   on                  Enable the Pi-hole log at /var/log/pihole.log
   off                 Disable and flush the Pi-hole log at /var/log/pihole.log
   off noflush         Disable the Pi-hole log at /var/log/pihole.log"
-    exit 0
-  elif [[ "${1}" == "off" ]]; then
-    # Disable logging
-    sed -i 's/^log-queries/#log-queries/' /etc/dnsmasq.d/01-pihole.conf
-    sed -i 's/^QUERY_LOGGING=true/QUERY_LOGGING=false/' /etc/pihole/setupVars.conf
-    if [[ "${2}" != "noflush" ]]; then
-      # Flush logs
-      "${PI_HOLE_BIN_DIR}"/pihole -f
-    fi
-    echo -e "  ${INFO} Disabling logging..."
-    local str="Logging has been disabled!"
-  elif [[ "${1}" == "on" ]]; then
-    # Enable logging
-    sed -i 's/^#log-queries/log-queries/' /etc/dnsmasq.d/01-pihole.conf
-    sed -i 's/^QUERY_LOGGING=false/QUERY_LOGGING=true/' /etc/pihole/setupVars.conf
-    echo -e "  ${INFO} Enabling logging..."
-    local str="Logging has been enabled!"
-  else
-    echo -e "  ${COL_LIGHT_RED}Invalid option${COL_NC}
+        exit 0
+    elif [[ ${1} == "off" ]]; then
+        # Disable logging
+        sed -i 's/^log-queries/#log-queries/' "@EPREFIX@/etc/pihole/dnsmasq.d/01-pihole.conf"
+        sed -i 's/^QUERY_LOGGING=true/QUERY_LOGGING=false/' "@EPREFIX@/etc/pihole/setupVars.conf"
+        if [[ ${2} != "noflush" ]]; then
+            # Flush logs
+            "${PI_HOLE_BIN_DIR}"/pihole -f
+        fi
+        echo -e "  ${INFO} Disabling logging..."
+        local str="Logging has been disabled!"
+    elif [[ ${1} == "on" ]]; then
+        # Enable logging
+        sed -i 's/^#log-queries/log-queries/' "@EPREFIX@/etc/pihole/dnsmasq.d/01-pihole.conf"
+        sed -i 's/^QUERY_LOGGING=false/QUERY_LOGGING=true/' "@EPREFIX@/etc/pihole/setupVars.conf"
+        echo -e "  ${INFO} Enabling logging..."
+        local str="Logging has been enabled!"
+    else
+        echo -e "  ${COL_LIGHT_RED}Invalid option${COL_NC}
   Try 'pihole logging --help' for more information."
-    exit 1
-  fi
-  restartDNS
-  echo -e "${OVER}  ${TICK} ${str}"
+        exit 1
+    fi
+    restartDNS
+    echo -e "${OVER}  ${TICK} ${str}"
 }
 
 analyze_ports() {
-  # FTL is listening at least on at least one port when this
-  # function is getting called
-  echo -e "  ${TICK} DNS service is listening"
-  # Check individual address family/protocol combinations
-  # For a healthy Pi-hole, they should all be up (nothing printed)
-  if grep -q "IPv4.*UDP" <<< "${1}"; then
-      echo -e "     ${TICK} UDP (IPv4)"
-  else
-      echo -e "     ${CROSS} UDP (IPv4)"
-  fi
-  if grep -q "IPv4.*TCP" <<< "${1}"; then
-      echo -e "     ${TICK} TCP (IPv4)"
-  else
-      echo -e "     ${CROSS} TCP (IPv4)"
-  fi
-  if grep -q "IPv6.*UDP" <<< "${1}"; then
-      echo -e "     ${TICK} UDP (IPv6)"
-  else
-      echo -e "     ${CROSS} UDP (IPv6)"
-  fi
-  if grep -q "IPv6.*TCP" <<< "${1}"; then
-      echo -e "     ${TICK} TCP (IPv6)"
-  else
-      echo -e "     ${CROSS} TCP (IPv6)"
-  fi
-  echo ""
+    # FTL is listening at least on at least one port when this
+    # function is getting called
+    echo -e "  ${TICK} DNS service is listening"
+    # Check individual address family/protocol combinations
+    # For a healthy Pi-hole, they should all be up (nothing printed)
+    if grep -q "IPv4.*UDP" <<< "${1}"; then
+        echo -e "     ${TICK} UDP (IPv4)"
+    else
+        echo -e "     ${CROSS} UDP (IPv4)"
+    fi
+    if grep -q "IPv4.*TCP" <<< "${1}"; then
+        echo -e "     ${TICK} TCP (IPv4)"
+    else
+        echo -e "     ${CROSS} TCP (IPv4)"
+    fi
+    if grep -q "IPv6.*UDP" <<< "${1}"; then
+        echo -e "     ${TICK} UDP (IPv6)"
+    else
+        echo -e "     ${CROSS} UDP (IPv6)"
+    fi
+    if grep -q "IPv6.*TCP" <<< "${1}"; then
+        echo -e "     ${TICK} TCP (IPv6)"
+    else
+        echo -e "     ${CROSS} TCP (IPv6)"
+    fi
+    echo ""
 }
 
 statusFunc() {
-  # Determine if there is a pihole service is listening on port 53
-  local listening
-  listening="$(lsof -Pni:53)"
-  if grep -q "pihole" <<< "${listening}"; then
-    if [[ "${1}" != "web" ]]; then
-      analyze_ports "${listening}"
+    # Determine if there is a pihole service is listening on port 53
+    local listening
+    listening="$(lsof -Pni:53)"
+    if grep -q "pihole" <<< "${listening}"; then
+        if [[ ${1} != "web" ]]; then
+            analyze_ports "${listening}"
+        fi
+    else
+        case "${1}" in
+            "web") echo "-1" ;;
+            *) echo -e "  ${CROSS} DNS service is NOT listening" ;;
+        esac
+        return 0
     fi
-  else
-    case "${1}" in
-      "web") echo "-1";;
-      *) echo -e "  ${CROSS} DNS service is NOT listening";;
-    esac
-    return 0
-  fi
-
-  # Determine if Pi-hole's blocking is enabled
-  if grep -q "BLOCKING_ENABLED=false" /etc/pihole/setupVars.conf; then
-    # A config is commented out
-    case "${1}" in
-      "web") echo 0;;
-      *) echo -e "  ${CROSS} Pi-hole blocking is disabled";;
-    esac
-  elif grep -q "BLOCKING_ENABLED=true" /etc/pihole/setupVars.conf;  then
-    # Configs are set
-    case "${1}" in
-      "web") echo 1;;
-      *) echo -e "  ${TICK} Pi-hole blocking is enabled";;
-    esac
-  else
-    # No configs were found
-    case "${1}" in
-      "web") echo 99;;
-      *) echo -e "  ${INFO} Pi-hole blocking will be enabled";;
-    esac
-    # Enable blocking
-    "${PI_HOLE_BIN_DIR}"/pihole enable
-  fi
-}
 
-tailFunc() {
-  # Warn user if Pi-hole's logging is disabled
-  local logging_enabled=$(grep -c "^log-queries" /etc/dnsmasq.d/01-pihole.conf)
-  if [[ "${logging_enabled}" == "0" ]]; then
-    # No "log-queries" lines are found.
-    # Commented out lines (such as "#log-queries") are ignored
-    echo "  ${CROSS} Warning: Query logging is disabled"
-  fi
-  echo -e "  ${INFO} Press Ctrl-C to exit"
-
-  # Retrieve IPv4/6 addresses
-  source /etc/pihole/setupVars.conf
-
-  # Strip date from each line
-  # Color blocklist/blacklist/wildcard entries as red
-  # Color A/AAAA/DHCP strings as white
-  # Color everything else as gray
-  tail -f /var/log/pihole.log | sed -E \
-    -e "s,($(date +'%b %d ')| dnsmasq\[[0-9]*\]),,g" \
-    -e "s,(.*(blacklisted |gravity blocked ).* is (0.0.0.0|::|NXDOMAIN|${IPV4_ADDRESS%/*}|${IPV6_ADDRESS:-NULL}).*),${COL_RED}&${COL_NC}," \
-    -e "s,.*(query\\[A|DHCP).*,${COL_NC}&${COL_NC}," \
-    -e "s,.*,${COL_GRAY}&${COL_NC},"
-  exit 0
+    # Determine if Pi-hole's blocking is enabled
+    if grep -q "BLOCKING_ENABLED=false" /etc/pihole/setupVars.conf; then
+        # A config is commented out
+        case "${1}" in
+            "web") echo 0 ;;
+            *) echo -e "  ${CROSS} Pi-hole blocking is disabled" ;;
+        esac
+    elif grep -q "BLOCKING_ENABLED=true" /etc/pihole/setupVars.conf; then
+        # Configs are set
+        case "${1}" in
+            "web") echo 1 ;;
+            *) echo -e "  ${TICK} Pi-hole blocking is enabled" ;;
+        esac
+    else
+        # No configs were found
+        case "${1}" in
+            "web") echo 99 ;;
+            *) echo -e "  ${INFO} Pi-hole blocking will be enabled" ;;
+        esac
+        # Enable blocking
+        "${PI_HOLE_BIN_DIR}"/pihole enable
+    fi
 }
 
-piholeCheckoutFunc() {
-  if [[ "$2" == "-h" ]] || [[ "$2" == "--help" ]]; then
-    echo "Usage: pihole checkout [repo] [branch]
-Example: 'pihole checkout master' or 'pihole checkout core dev'
-Switch Pi-hole subsystems to a different GitHub branch
-
-Repositories:
-  core [branch]       Change the branch of Pi-hole's core subsystem
-  web [branch]        Change the branch of Web Interface subsystem
-  ftl [branch]        Change the branch of Pi-hole's FTL subsystem
-
-Branches:
-  master              Update subsystems to the latest stable release
-  dev                 Update subsystems to the latest development release
-  branchname          Update subsystems to the specified branchname"
+tailFunc() {
+    # Warn user if Pi-hole's logging is disabled
+    local logging_enabled=$(grep -c "^log-queries" /etc/dnsmasq.d/01-pihole.conf)
+    if [[ ${logging_enabled} == "0" ]]; then
+        # No "log-queries" lines are found.
+        # Commented out lines (such as "#log-queries") are ignored
+        echo "  ${CROSS} Warning: Query logging is disabled"
+    fi
+    echo -e "  ${INFO} Press Ctrl-C to exit"
+
+    # Retrieve IPv4/6 addresses
+    source /etc/pihole/setupVars.conf
+
+    # Strip date from each line
+    # Color blocklist/blacklist/wildcard entries as red
+    # Color A/AAAA/DHCP strings as white
+    # Color everything else as gray
+    tail -f /var/log/pihole.log | sed -E \
+        -e "s,($(date +'%b %d ')| dnsmasq\[[0-9]*\]),,g" \
+        -e "s,(.*(blacklisted |gravity blocked ).* is (0.0.0.0|::|NXDOMAIN|${IPV4_ADDRESS%/*}|${IPV6_ADDRESS:-NULL}).*),${COL_RED}&${COL_NC}," \
+        -e "s,.*(query\\[A|DHCP).*,${COL_NC}&${COL_NC}," \
+        -e "s,.*,${COL_GRAY}&${COL_NC},"
     exit 0
-  fi
-
-  source "${PI_HOLE_SCRIPT_DIR}"/piholeCheckout.sh
-  shift
-  checkout "$@"
 }
 
 tricorderFunc() {
-  if [[ ! -p "/dev/stdin" ]]; then
-    echo -e "  ${INFO} Please do not call Tricorder directly"
-    exit 1
-  fi
-
-  if ! (echo > /dev/tcp/tricorder.pi-hole.net/9998) >/dev/null 2>&1; then
-    echo -e "  ${CROSS} Unable to connect to Pi-hole's Tricorder server"
-    exit 1
-  fi
-
-  if command -v openssl &> /dev/null; then
-    openssl s_client -quiet -connect tricorder.pi-hole.net:9998 2> /dev/null < /dev/stdin
-    exit "$?"
-  else
-    echo -e "  ${INFO} ${COL_YELLOW}Security Notice${COL_NC}: ${COL_WHITE}openssl${COL_NC} is not installed
+    if [[ ! -p "/dev/stdin" ]]; then
+        echo -e "  ${INFO} Please do not call Tricorder directly"
+        exit 1
+    fi
+
+    if ! (echo > /dev/tcp/tricorder.pi-hole.net/9998) > /dev/null 2>&1; then
+        echo -e "  ${CROSS} Unable to connect to Pi-hole's Tricorder server"
+        exit 1
+    fi
+
+    if command -v openssl &> /dev/null; then
+        openssl s_client -quiet -connect tricorder.pi-hole.net:9998 2> /dev/null < /dev/stdin
+        exit "$?"
+    else
+        echo -e "  ${INFO} ${COL_YELLOW}Security Notice${COL_NC}: ${COL_WHITE}openssl${COL_NC} is not installed
        Your debug log will be transmitted unencrypted via plain-text
        There is a possibility that this could be intercepted by a third party
        If you wish to cancel, press Ctrl-C to exit within 10 seconds"
-    secs="10"
-    while [[ "$secs" -gt "0" ]]; do
-       echo -ne "."
-       sleep 1
-       : $((secs--))
-    done
-    echo " "
-    nc tricorder.pi-hole.net 9999 < /dev/stdin
-    exit "$?"
-  fi
-}
-
-updateCheckFunc() {
-  "${PI_HOLE_SCRIPT_DIR}"/updatecheck.sh "$@"
-  exit 0
+        secs="10"
+        while [[ $secs -gt "0" ]]; do
+            echo -ne "."
+            sleep 1
+            : $((secs--))
+        done
+        echo " "
+        nc tricorder.pi-hole.net 9999 < /dev/stdin
+        exit "$?"
+    fi
 }
 
 helpFunc() {
-  echo "Usage: pihole [options]
+    echo "Usage: pihole [options]
 Example: 'pihole -w -h'
 Add '-h' after specific commands for more information on usage
 
@@ -455,7 +410,6 @@ Debugging Options:
   -d, debug           Start a debugging session
                         Add '-a' to automatically upload the log to tricorder.pi-hole.net
   -f, flush           Flush the Pi-hole log
-  -r, reconfigure     Reconfigure or Repair Pi-hole subsystems
   -t, tail            View the live output of the Pi-hole log
 
 Options:
@@ -469,11 +423,8 @@ Options:
                         Add '-h' for more info on logging usage
   -q, query           Query the adlists for a specified domain
                         Add '-h' for more info on query usage
-  -up, updatePihole   Update Pi-hole subsystems
-                        Add '--check-only' to exit script before update is performed.
   -v, version         Show installed versions of Pi-hole, Web Interface & FTL
                         Add '-h' for more info on version usage
-  uninstall           Uninstall Pi-hole from your system
   status              Display the running status of Pi-hole subsystems
   enable              Enable Pi-hole subsystems
   disable             Disable Pi-hole subsystems
@@ -481,59 +432,53 @@ Options:
   restartdns          Full restart Pi-hole subsystems
                         Add 'reload' to update the lists and flush the cache without restarting the DNS server
                         Add 'reload-lists' to only update the lists WITHOUT flushing the cache or restarting the DNS server
-  checkout            Switch Pi-hole subsystems to a different GitHub branch
-                        Add '-h' for more info on checkout usage
-  arpflush            Flush information stored in Pi-hole's network tables";
-  exit 0
+  arpflush            Flush information stored in Pi-hole's network tables"
+    exit 0
 }
 
-if [[ $# = 0 ]]; then
-  helpFunc
+if [[ $# == 0 ]]; then
+    helpFunc
 fi
 
 case "${1}" in
-  "-h" | "help" | "--help"      ) helpFunc;;
+    "-h" | "help" | "--help") helpFunc ;;
 esac
 
 # Must be root to use this tool
-if [[ ! $EUID -eq 0 ]];then
-  if [[ -x "$(command -v sudo)" ]]; then
-    exec sudo bash "$0" "$@"
-    exit $?
-  else
-    echo -e "  ${CROSS} sudo is needed to run pihole commands.  Please run this script as root or install sudo."
-    exit 1
-  fi
+if [[ ! $EUID -eq 0 ]]; then
+    if [[ -x "$(command -v sudo)" ]]; then
+        exec sudo bash "$0" "$@"
+        exit $?
+    else
+        echo -e "  ${CROSS} sudo is needed to run pihole commands.  Please run this script as root or install sudo."
+        exit 1
+    fi
 fi
 
 # Handle redirecting to specific functions based on arguments
 case "${1}" in
-  "-w" | "whitelist"            ) listFunc "$@";;
-  "-b" | "blacklist"            ) listFunc "$@";;
-  "--wild" | "wildcard"         ) listFunc "$@";;
-  "--regex" | "regex"           ) listFunc "$@";;
-  "--white-regex" | "white-regex" ) listFunc "$@";;
-  "--white-wild" | "white-wild"   ) listFunc "$@";;
-  "-d" | "debug"                ) debugFunc "$@";;
-  "-f" | "flush"                ) flushFunc "$@";;
-  "-up" | "updatePihole"        ) updatePiholeFunc "$@";;
-  "-r"  | "reconfigure"         ) reconfigurePiholeFunc;;
-  "-g" | "updateGravity"        ) updateGravityFunc "$@";;
-  "-c" | "chronometer"          ) chronometerFunc "$@";;
-  "-h" | "help"                 ) helpFunc;;
-  "-v" | "version"              ) versionFunc "$@";;
-  "-q" | "query"                ) queryFunc "$@";;
-  "-l" | "logging"              ) piholeLogging "$@";;
-  "uninstall"                   ) uninstallFunc;;
-  "enable"                      ) piholeEnable 1;;
-  "disable"                     ) piholeEnable 0 "$2";;
-  "status"                      ) statusFunc "$2";;
-  "restartdns"                  ) restartDNS "$2";;
-  "-a" | "admin"                ) webpageFunc "$@";;
-  "-t" | "tail"                 ) tailFunc;;
-  "checkout"                    ) piholeCheckoutFunc "$@";;
-  "tricorder"                   ) tricorderFunc;;
-  "updatechecker"               ) updateCheckFunc "$@";;
-  "arpflush"                    ) arpFunc "$@";;
-  *                             ) helpFunc;;
+    "-w" | "whitelist") listFunc "$@" ;;
+    "-b" | "blacklist") listFunc "$@" ;;
+    "--wild" | "wildcard") listFunc "$@" ;;
+    "--regex" | "regex") listFunc "$@" ;;
+    "--white-regex" | "white-regex") listFunc "$@" ;;
+    "--white-wild" | "white-wild") listFunc "$@" ;;
+    "-d" | "debug") debugFunc "$@" ;;
+    "-f" | "flush") flushFunc "$@" ;;
+    "-g" | "updateGravity") updateGravityFunc "$@" ;;
+    "-c" | "chronometer") chronometerFunc "$@" ;;
+    "-h" | "help") helpFunc ;;
+    "-v" | "version") versionFunc "$@" ;;
+    "-q" | "query") queryFunc "$@" ;;
+    "-l" | "logging") piholeLogging "$@" ;;
+    "uninstall") uninstallFunc ;;
+    "enable") piholeEnable 1 ;;
+    "disable") piholeEnable 0 "$2" ;;
+    "status") statusFunc "$2" ;;
+    "restartdns") restartDNS "$2" ;;
+    "-a" | "admin") webpageFunc "$@" ;;
+    "-t" | "tail") tailFunc ;;
+    "tricorder") tricorderFunc ;;
+    "arpflush") arpFunc "$@" ;;
+    *) helpFunc ;;
 esac
